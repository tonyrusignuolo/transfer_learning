{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_wav_file_name = tf.keras.utils.get_file(\n",
    "    'miaow_16k.wav',\n",
    "    'https://storage.googleapis.com/audioset/miaow_16k.wav',                                                cache_dir='./',                                                cache_subdir='datasets/test_data'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "        file_contents,\n",
    "        desired_channels=1\n",
    "    )\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "@tf.function\n",
    "def frame_16k_mono(filename):\n",
    "    wav = load_wav_16k_mono(filename)\n",
    "    frames = tf.signal.frame(wav, 15600, 15600)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# testing_wav_data = load_wav_16k_mono(testing_wav_file_name)\n",
    "frames = frame_16k_mono(testing_wav_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: waveform_binary\n",
      "shape: [15600]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "name: tower0/network/layer32/final_output\n",
      "shape: [  1 521]\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "\n",
      "name: waveform_binary,\n",
      "index: 0,\n",
      "shape: [15600],\n",
      "shape_signature: [15600],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/zeros_like,\n",
      "index: 1,\n",
      "shape: [1],\n",
      "shape_signature: [1],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/concat,\n",
      "index: 2,\n",
      "shape: [1],\n",
      "shape_signature: [1],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/ones_like,\n",
      "index: 3,\n",
      "shape: [1],\n",
      "shape_signature: [1],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/StridedSlice,\n",
      "index: 4,\n",
      "shape: [15600],\n",
      "shape_signature: [15600],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/concat_1,\n",
      "index: 5,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/Reshape,\n",
      "index: 6,\n",
      "shape: [195  80],\n",
      "shape_signature: [195  80],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/add_1,\n",
      "index: 7,\n",
      "shape: [96  5],\n",
      "shape_signature: [96  5],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/GatherV2;stft/frame/GatherV2/axis,\n",
      "index: 8,\n",
      "shape: [96  5 80],\n",
      "shape_signature: [96  5 80],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/concat_2/values_1,\n",
      "index: 9,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/frame/Reshape_3,\n",
      "index: 10,\n",
      "shape: [ 96 400],\n",
      "shape_signature: [ 96 400],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/hann_window/sub_2,\n",
      "index: 11,\n",
      "shape: [400],\n",
      "shape_signature: [400],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/mul,\n",
      "index: 12,\n",
      "shape: [ 96 400],\n",
      "shape_signature: [ 96 400],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft/Pad/paddings,\n",
      "index: 13,\n",
      "shape: [2 2],\n",
      "shape_signature: [2 2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft/Pad,\n",
      "index: 14,\n",
      "shape: [ 96 512],\n",
      "shape_signature: [ 96 512],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft1,\n",
      "index: 15,\n",
      "shape: [3],\n",
      "shape_signature: [3],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft3,\n",
      "index: 16,\n",
      "shape: [ 96   1 512],\n",
      "shape_signature: [ 96   1 512],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft,\n",
      "index: 17,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft4,\n",
      "index: 18,\n",
      "shape: [ 96   1 257],\n",
      "shape_signature: [ 96   1 257],\n",
      "dtype: <class 'numpy.complex64'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft2,\n",
      "index: 19,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: stft/rfft5,\n",
      "index: 20,\n",
      "shape: [ 96 257],\n",
      "shape_signature: [ 96 257],\n",
      "dtype: <class 'numpy.complex64'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: magnitude_spectrogram,\n",
      "index: 21,\n",
      "shape: [ 96 257],\n",
      "shape_signature: [ 96 257],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: mel_spectrogram,\n",
      "index: 22,\n",
      "shape: [ 64 257],\n",
      "shape_signature: [ 64 257],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: add,\n",
      "index: 23,\n",
      "shape: [64],\n",
      "shape_signature: [64],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: mel_spectrogram;add,\n",
      "index: 24,\n",
      "shape: [96 64],\n",
      "shape_signature: [96 64],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: log_mel_spectrogram,\n",
      "index: 25,\n",
      "shape: [96 64],\n",
      "shape_signature: [96 64],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: Reshape/shape,\n",
      "index: 26,\n",
      "shape: [3],\n",
      "shape_signature: [3],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: feature_patch,\n",
      "index: 27,\n",
      "shape: [ 1 96 64],\n",
      "shape_signature: [ 1 96 64],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tfl.quantize,\n",
      "index: 28,\n",
      "shape: [ 1 96 64],\n",
      "shape_signature: [ 1 96 64],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.048020608723163605, 16),\n",
      "quantization_parameters: {'scales': array([0.04802061], dtype=float32), 'zero_points': array([16]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ExpandDims,\n",
      "index: 29,\n",
      "shape: [4],\n",
      "shape_signature: [4],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ExpandDims1,\n",
      "index: 30,\n",
      "shape: [ 1 96 64  1],\n",
      "shape_signature: [ 1 96 64  1],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.048020608723163605, 16),\n",
      "quantization_parameters: {'scales': array([0.04802061], dtype=float32), 'zero_points': array([16]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: pre_tower/split/split_dim,\n",
      "index: 31,\n",
      "shape: [],\n",
      "shape_signature: [],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: pre_tower/split,\n",
      "index: 32,\n",
      "shape: [ 1 96 64  1],\n",
      "shape_signature: [ 1 96 64  1],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.048020608723163605, 16),\n",
      "quantization_parameters: {'scales': array([0.04802061], dtype=float32), 'zero_points': array([16]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer1/conv/Conv2D,\n",
      "index: 33,\n",
      "shape: [32  3  3  1],\n",
      "shape_signature: [32  3  3  1],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00175687, 0.001559  , 0.00858876, 0.0047561 , 0.00771149,\n",
      "       0.00840162, 0.01443524, 0.01273701, 0.00180895, 0.007811  ,\n",
      "       0.01569788, 0.00560685, 0.00151642, 0.01534083, 0.00435829,\n",
      "       0.00158785, 0.00634343, 0.00178232, 0.00619695, 0.00121414,\n",
      "       0.0027266 , 0.00159462, 0.00434031, 0.00426887, 0.00694113,\n",
      "       0.00813503, 0.00804377, 0.00751698, 0.00409165, 0.00360306,\n",
      "       0.01424306, 0.00460075], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer1/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 34,\n",
      "shape: [32],\n",
      "shape_signature: [32],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([8.4365733e-05, 7.4864205e-05, 4.1243763e-04, 2.2839062e-04,\n",
      "       3.7031053e-04, 4.0345077e-04, 6.9318915e-04, 6.1163894e-04,\n",
      "       8.6866763e-05, 3.7508877e-04, 7.5382181e-04, 2.6924425e-04,\n",
      "       7.2819617e-05, 7.3667598e-04, 2.0928794e-04, 7.6249475e-05,\n",
      "       3.0461550e-04, 8.5588261e-05, 2.9758128e-04, 5.8303762e-05,\n",
      "       1.3093281e-04, 7.6574601e-05, 2.0842432e-04, 2.0499367e-04,\n",
      "       3.3331718e-04, 3.9064919e-04, 3.8626650e-04, 3.6096975e-04,\n",
      "       1.9648334e-04, 1.7302130e-04, 6.8396027e-04, 2.2093083e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer1/conv/Relu6;tower0/network/layer1/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer2/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer2/sepconv/depthwise;tower0/network/layer1/conv/Conv2D,\n",
      "index: 35,\n",
      "shape: [ 1 48 32 32],\n",
      "shape_signature: [ 1 48 32 32],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer2/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer2/sepconv/depthwise,\n",
      "index: 36,\n",
      "shape: [ 1  3  3 32],\n",
      "shape_signature: [ 1  3  3 32],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.0162089 , 0.01431269, 0.01381488, 0.00581825, 0.01535442,\n",
      "       0.00616808, 0.01212896, 0.01009261, 0.01130291, 0.00578969,\n",
      "       0.0145896 , 0.01531339, 0.01021459, 0.01244579, 0.0147387 ,\n",
      "       0.02031176, 0.00652614, 0.02201092, 0.00934513, 0.01376003,\n",
      "       0.00759459, 0.01891373, 0.01293259, 0.0139344 , 0.0111432 ,\n",
      "       0.00549533, 0.00826232, 0.01156052, 0.01873855, 0.01612467,\n",
      "       0.01236208, 0.00863672], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer2/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 37,\n",
      "shape: [32],\n",
      "shape_signature: [32],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00038139, 0.00033677, 0.00032506, 0.0001369 , 0.00036128,\n",
      "       0.00014513, 0.00028539, 0.00023747, 0.00026595, 0.00013623,\n",
      "       0.00034328, 0.00036031, 0.00024034, 0.00029284, 0.00034679,\n",
      "       0.00047792, 0.00015356, 0.0005179 , 0.00021989, 0.00032377,\n",
      "       0.0001787 , 0.00044503, 0.0003043 , 0.00032787, 0.00026219,\n",
      "       0.0001293 , 0.00019441, 0.00027201, 0.00044091, 0.0003794 ,\n",
      "       0.00029087, 0.00020322], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer2/sepconv/Relu6;tower0/network/layer2/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer2/sepconv/depthwise,\n",
      "index: 38,\n",
      "shape: [ 1 48 32 32],\n",
      "shape_signature: [ 1 48 32 32],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer3/conv/Conv2D,\n",
      "index: 39,\n",
      "shape: [64  1  1 32],\n",
      "shape_signature: [64  1  1 32],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00663203, 0.00597601, 0.00491875, 0.00533937, 0.00304063,\n",
      "       0.00399323, 0.00363168, 0.00706256, 0.00537507, 0.00642141,\n",
      "       0.00442649, 0.00943761, 0.00484624, 0.00687086, 0.00512186,\n",
      "       0.00489912, 0.00468076, 0.00496663, 0.00373816, 0.00460076,\n",
      "       0.00543735, 0.00757915, 0.0042574 , 0.00412934, 0.00559939,\n",
      "       0.00416671, 0.00376303, 0.00716701, 0.00608335, 0.00566867,\n",
      "       0.00409581, 0.00400501, 0.00610715, 0.00465744, 0.00588598,\n",
      "       0.003882  , 0.00406854, 0.00547837, 0.00750254, 0.00404874,\n",
      "       0.00642028, 0.00438216, 0.00649862, 0.00427902, 0.00597419,\n",
      "       0.00773517, 0.00447977, 0.00639905, 0.00476037, 0.00486884,\n",
      "       0.00438848, 0.00753836, 0.0056087 , 0.00519263, 0.00391347,\n",
      "       0.00772715, 0.00369594, 0.00540497, 0.00364944, 0.00407877,\n",
      "       0.00404869, 0.00369012, 0.00710422, 0.00547942], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer3/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 40,\n",
      "shape: [64],\n",
      "shape_signature: [64],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.56047725e-04, 1.40611926e-04, 1.15735325e-04, 1.25632272e-04,\n",
      "       7.15443166e-05, 9.39582897e-05, 8.54512400e-05, 1.66177822e-04,\n",
      "       1.26472267e-04, 1.51092041e-04, 1.04152772e-04, 2.22061513e-04,\n",
      "       1.14029222e-04, 1.61667296e-04, 1.20514436e-04, 1.15273477e-04,\n",
      "       1.10135501e-04, 1.16861898e-04, 8.79567451e-05, 1.08253145e-04,\n",
      "       1.27937674e-04, 1.78332877e-04, 1.00174184e-04, 9.71608752e-05,\n",
      "       1.31750377e-04, 9.80402619e-05, 8.85418121e-05, 1.68635554e-04,\n",
      "       1.43137571e-04, 1.33380439e-04, 9.63720668e-05, 9.42355182e-05,\n",
      "       1.43697689e-04, 1.09586726e-04, 1.38493560e-04, 9.13412805e-05,\n",
      "       9.57302909e-05, 1.28902902e-04, 1.76530331e-04, 9.52644477e-05,\n",
      "       1.51065338e-04, 1.03109582e-04, 1.52908731e-04, 1.00682875e-04,\n",
      "       1.40569275e-04, 1.82004063e-04, 1.05406267e-04, 1.50565917e-04,\n",
      "       1.12008624e-04, 1.14561037e-04, 1.03258324e-04, 1.77373164e-04,\n",
      "       1.31969398e-04, 1.22179554e-04, 9.20815946e-05, 1.81815398e-04,\n",
      "       8.69633732e-05, 1.27175808e-04, 8.58691346e-05, 9.59710815e-05,\n",
      "       9.52632472e-05, 8.68264688e-05, 1.67158141e-04, 1.28927466e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer3/conv/Relu6;tower0/network/layer3/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer4/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer4/sepconv/depthwise;tower0/network/layer3/conv/Conv2D,\n",
      "index: 41,\n",
      "shape: [ 1 48 32 64],\n",
      "shape_signature: [ 1 48 32 64],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer4/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer4/sepconv/depthwise,\n",
      "index: 42,\n",
      "shape: [ 1  3  3 64],\n",
      "shape_signature: [ 1  3  3 64],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00478907, 0.00388605, 0.00582564, 0.00549784, 0.00505667,\n",
      "       0.00504918, 0.00432221, 0.00348147, 0.00499112, 0.00641103,\n",
      "       0.00646605, 0.00644948, 0.00494531, 0.00493603, 0.0086938 ,\n",
      "       0.00749697, 0.009773  , 0.00559875, 0.00429378, 0.00422483,\n",
      "       0.00503811, 0.00613245, 0.00485166, 0.0043794 , 0.00675678,\n",
      "       0.00439763, 0.00393217, 0.005804  , 0.00933999, 0.0045823 ,\n",
      "       0.00555538, 0.00780276, 0.00635015, 0.00550758, 0.0074868 ,\n",
      "       0.00412959, 0.00598794, 0.00669517, 0.00581876, 0.00326537,\n",
      "       0.00295437, 0.00558653, 0.00739282, 0.0058096 , 0.00777618,\n",
      "       0.00669002, 0.00314004, 0.00446661, 0.00858305, 0.00409047,\n",
      "       0.00542126, 0.00278188, 0.00442651, 0.00669378, 0.00444694,\n",
      "       0.00511423, 0.00485447, 0.00641559, 0.0049935 , 0.00556462,\n",
      "       0.00635319, 0.00629107, 0.00544707, 0.00680618], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer4/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 43,\n",
      "shape: [64],\n",
      "shape_signature: [64],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.12684029e-04, 9.14364500e-05, 1.37073817e-04, 1.29360968e-04,\n",
      "       1.18980395e-04, 1.18804266e-04, 1.01699094e-04, 8.19169509e-05,\n",
      "       1.17438220e-04, 1.50847758e-04, 1.52142355e-04, 1.51752582e-04,\n",
      "       1.16360170e-04, 1.16141797e-04, 2.04559939e-04, 1.76399320e-04,\n",
      "       2.29952973e-04, 1.31735404e-04, 1.01030222e-04, 9.94077054e-05,\n",
      "       1.18543721e-04, 1.44293037e-04, 1.14156690e-04, 1.03044607e-04,\n",
      "       1.58983152e-04, 1.03473685e-04, 9.25216082e-05, 1.36564602e-04,\n",
      "       2.19764581e-04, 1.07818880e-04, 1.30714790e-04, 1.83594471e-04,\n",
      "       1.49415384e-04, 1.29590131e-04, 1.76159941e-04, 9.71668560e-05,\n",
      "       1.40892793e-04, 1.57533432e-04, 1.36911985e-04, 7.68321261e-05,\n",
      "       6.95146591e-05, 1.31447712e-04, 1.73948647e-04, 1.36696370e-04,\n",
      "       1.82968884e-04, 1.57412258e-04, 7.38832314e-05, 1.05096609e-04,\n",
      "       2.01954215e-04, 9.62462873e-05, 1.27559164e-04, 6.54560426e-05,\n",
      "       1.04153260e-04, 1.57500719e-04, 1.04633873e-04, 1.20334931e-04,\n",
      "       1.14222785e-04, 1.50955093e-04, 1.17494179e-04, 1.30932123e-04,\n",
      "       1.49486805e-04, 1.48025225e-04, 1.28166328e-04, 1.60145428e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer4/sepconv/Relu6;tower0/network/layer4/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer4/sepconv/depthwise,\n",
      "index: 44,\n",
      "shape: [ 1 24 16 64],\n",
      "shape_signature: [ 1 24 16 64],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer5/conv/Conv2D,\n",
      "index: 45,\n",
      "shape: [128   1   1  64],\n",
      "shape_signature: [128   1   1  64],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00309723, 0.0037516 , 0.00242018, 0.00269133, 0.00285034,\n",
      "       0.00300769, 0.00389704, 0.00427205, 0.00301471, 0.00271377,\n",
      "       0.00338567, 0.00334862, 0.00354808, 0.00333088, 0.00463594,\n",
      "       0.00325564, 0.0030542 , 0.00641048, 0.00267521, 0.00286404,\n",
      "       0.00498736, 0.00432003, 0.00248545, 0.0070593 , 0.00367378,\n",
      "       0.00552972, 0.0021046 , 0.00502341, 0.00316299, 0.0039848 ,\n",
      "       0.00280777, 0.00382971, 0.00436084, 0.00287884, 0.00395564,\n",
      "       0.00322416, 0.00364414, 0.00334185, 0.00407993, 0.0044514 ,\n",
      "       0.00325301, 0.00551228, 0.00325882, 0.00283223, 0.00496718,\n",
      "       0.00719634, 0.00412713, 0.00285692, 0.00382855, 0.00388779,\n",
      "       0.00266335, 0.00334274, 0.00461607, 0.00355892, 0.00373518,\n",
      "       0.00552775, 0.00623431, 0.00459703, 0.00509702, 0.00311759,\n",
      "       0.00489352, 0.00320918, 0.00574725, 0.00384877, 0.00649913,\n",
      "       0.00317421, 0.00441281, 0.00286354, 0.00393359, 0.0029545 ,\n",
      "       0.00328119, 0.0038021 , 0.00490047, 0.00584146, 0.00343203,\n",
      "       0.00407489, 0.00337159, 0.00230116, 0.00390019, 0.00386047,\n",
      "       0.00339674, 0.00467082, 0.00332832, 0.00297192, 0.00685318,\n",
      "       0.00341817, 0.0087463 , 0.00335227, 0.00428061, 0.00302373,\n",
      "       0.00404801, 0.00352157, 0.00457048, 0.00190879, 0.00360183,\n",
      "       0.00293925, 0.00358485, 0.0028422 , 0.00269092, 0.00561571,\n",
      "       0.00483683, 0.00503779, 0.00431751, 0.00299752, 0.00365199,\n",
      "       0.00280516, 0.0064481 , 0.00455425, 0.00359315, 0.00370681,\n",
      "       0.00232005, 0.003204  , 0.00504925, 0.00395436, 0.0050345 ,\n",
      "       0.00550159, 0.00509134, 0.00324113, 0.00451557, 0.00397737,\n",
      "       0.00303991, 0.0052939 , 0.00372212, 0.00283113, 0.00414035,\n",
      "       0.00672516, 0.00441996, 0.00321897], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer5/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 46,\n",
      "shape: [128],\n",
      "shape_signature: [128],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([7.28760278e-05, 8.82730528e-05, 5.69454787e-05, 6.33255258e-05,\n",
      "       6.70668742e-05, 7.07692234e-05, 9.16949575e-05, 1.00518744e-04,\n",
      "       7.09344095e-05, 6.38533893e-05, 7.96629174e-05, 7.87911049e-05,\n",
      "       8.34842576e-05, 7.83737050e-05, 1.09080851e-04, 7.66033772e-05,\n",
      "       7.18634692e-05, 1.50834720e-04, 6.29460992e-05, 6.73891846e-05,\n",
      "       1.17349678e-04, 1.01647704e-04, 5.84811969e-05, 1.66101163e-04,\n",
      "       8.64419708e-05, 1.30111046e-04, 4.95199893e-05, 1.18197939e-04,\n",
      "       7.44232457e-05, 9.37599252e-05, 6.60652368e-05, 9.01108215e-05,\n",
      "       1.02607948e-04, 6.77374555e-05, 9.30738024e-05, 7.58625392e-05,\n",
      "       8.57445048e-05, 7.86318051e-05, 9.59983736e-05, 1.04738916e-04,\n",
      "       7.65413424e-05, 1.29700798e-04, 7.66780067e-05, 6.66407068e-05,\n",
      "       1.16874842e-04, 1.69325649e-04, 9.71089175e-05, 6.72216629e-05,\n",
      "       9.00836458e-05, 9.14774864e-05, 6.26671390e-05, 7.86526070e-05,\n",
      "       1.08613494e-04, 8.37392799e-05, 8.78866049e-05, 1.30064655e-04,\n",
      "       1.46689694e-04, 1.08165441e-04, 1.19929951e-04, 7.33551642e-05,\n",
      "       1.15141549e-04, 7.55101428e-05, 1.35229435e-04, 9.05593479e-05,\n",
      "       1.52920780e-04, 7.46872975e-05, 1.03830869e-04, 6.73775139e-05,\n",
      "       9.25551212e-05, 6.95176568e-05, 7.72044004e-05, 8.94610712e-05,\n",
      "       1.15305113e-04, 1.37446084e-04, 8.07535762e-05, 9.58797682e-05,\n",
      "       7.93314975e-05, 5.41449299e-05, 9.17692523e-05, 9.08344955e-05,\n",
      "       7.99232803e-05, 1.09901732e-04, 7.83135183e-05, 6.99274897e-05,\n",
      "       1.61251228e-04, 8.04274969e-05, 2.05795281e-04, 7.88769175e-05,\n",
      "       1.00720172e-04, 7.11465254e-05, 9.52472255e-05, 8.28604316e-05,\n",
      "       1.07540814e-04, 4.49126637e-05, 8.47489937e-05, 6.91588648e-05,\n",
      "       8.43494345e-05, 6.68752546e-05, 6.33158779e-05, 1.32134257e-04,\n",
      "       1.13807771e-04, 1.18536140e-04, 1.01588383e-04, 7.05298735e-05,\n",
      "       8.59292559e-05, 6.60038277e-05, 1.51719927e-04, 1.07158812e-04,\n",
      "       8.45446848e-05, 8.72190212e-05, 5.45893636e-05, 7.53881468e-05,\n",
      "       1.18805823e-04, 9.30438036e-05, 1.18458876e-04, 1.29449298e-04,\n",
      "       1.19796350e-04, 7.62619820e-05, 1.06248808e-04, 9.35852440e-05,\n",
      "       7.15273345e-05, 1.24562270e-04, 8.75792030e-05, 6.66147826e-05,\n",
      "       9.74199793e-05, 1.58238996e-04, 1.03999075e-04, 7.57405578e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer5/conv/Relu6;tower0/network/layer5/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/depthwise;tower0/network/layer5/conv/Conv2D,\n",
      "index: 47,\n",
      "shape: [  1  24  16 128],\n",
      "shape_signature: [  1  24  16 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer6/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer6/sepconv/depthwise;tower0/network/layer8/sepconv/depthwise,\n",
      "index: 48,\n",
      "shape: [  1   3   3 128],\n",
      "shape_signature: [  1   3   3 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.01039129, 0.01302949, 0.00945546, 0.00753629, 0.00676907,\n",
      "       0.01313499, 0.00965301, 0.00891206, 0.00921115, 0.0110148 ,\n",
      "       0.01036127, 0.0046167 , 0.0133748 , 0.00730449, 0.01249675,\n",
      "       0.01127336, 0.00994427, 0.00518989, 0.00848597, 0.00949506,\n",
      "       0.00579466, 0.00604248, 0.01228719, 0.00720574, 0.01169756,\n",
      "       0.00775409, 0.0114567 , 0.00810858, 0.01024511, 0.01108091,\n",
      "       0.0071912 , 0.00931764, 0.00502602, 0.0072953 , 0.00541328,\n",
      "       0.01302257, 0.00888238, 0.01093112, 0.00999359, 0.00864289,\n",
      "       0.01194069, 0.00516699, 0.00563546, 0.01001107, 0.01000138,\n",
      "       0.00504691, 0.00745746, 0.00723866, 0.00481237, 0.01018713,\n",
      "       0.01249721, 0.00726023, 0.00717636, 0.00871777, 0.01073   ,\n",
      "       0.00666594, 0.0120213 , 0.00870983, 0.00855664, 0.00887128,\n",
      "       0.0073205 , 0.01142733, 0.00687935, 0.005457  , 0.00907577,\n",
      "       0.00872022, 0.00339242, 0.00556189, 0.00376404, 0.0113314 ,\n",
      "       0.0061907 , 0.00744723, 0.01151462, 0.01218002, 0.01407161,\n",
      "       0.00588079, 0.0068561 , 0.01050831, 0.00639974, 0.00580621,\n",
      "       0.01063396, 0.00858757, 0.01026397, 0.00966244, 0.00549864,\n",
      "       0.01069286, 0.00925799, 0.00357459, 0.0077974 , 0.00704778,\n",
      "       0.00679371, 0.00968731, 0.00421391, 0.01187913, 0.00474108,\n",
      "       0.00516855, 0.00900975, 0.00944028, 0.00853713, 0.00656375,\n",
      "       0.0072597 , 0.00759333, 0.00871774, 0.00959139, 0.00960871,\n",
      "       0.01261065, 0.00629738, 0.00739118, 0.01061296, 0.00881121,\n",
      "       0.00919108, 0.01066905, 0.00791597, 0.01145664, 0.00662328,\n",
      "       0.01228836, 0.01141116, 0.00590026, 0.00942969, 0.004572  ,\n",
      "       0.01078292, 0.0092967 , 0.00933808, 0.0070607 , 0.00867617,\n",
      "       0.00598937, 0.00650824, 0.00533553], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer6/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 49,\n",
      "shape: [128],\n",
      "shape_signature: [128],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.44500960e-04, 3.06576258e-04, 2.22481525e-04, 1.77324429e-04,\n",
      "       1.59272255e-04, 3.09058494e-04, 2.27129654e-04, 2.09695500e-04,\n",
      "       2.16732908e-04, 2.59171706e-04, 2.43794610e-04, 1.08628272e-04,\n",
      "       3.14701087e-04, 1.71870299e-04, 2.94041209e-04, 2.65255541e-04,\n",
      "       2.33982777e-04, 1.22115132e-04, 1.99669928e-04, 2.23413270e-04,\n",
      "       1.36344941e-04, 1.42175966e-04, 2.89110380e-04, 1.69546736e-04,\n",
      "       2.75236671e-04, 1.82449236e-04, 2.69569515e-04, 1.90790088e-04,\n",
      "       2.41061309e-04, 2.60727335e-04, 1.69204723e-04, 2.19238558e-04,\n",
      "       1.18259246e-04, 1.71654130e-04, 1.27371328e-04, 3.06413393e-04,\n",
      "       2.08997270e-04, 2.57202832e-04, 2.35143292e-04, 2.03362113e-04,\n",
      "       2.80957291e-04, 1.21576333e-04, 1.32598943e-04, 2.35554588e-04,\n",
      "       2.35326632e-04, 1.18750831e-04, 1.75469686e-04, 1.70321451e-04,\n",
      "       1.13232214e-04, 2.39697212e-04, 2.94052094e-04, 1.70828906e-04,\n",
      "       1.68855608e-04, 2.05124088e-04, 2.52470520e-04, 1.56845708e-04,\n",
      "       2.82854104e-04, 2.04937256e-04, 2.01332747e-04, 2.08736106e-04,\n",
      "       1.72247106e-04, 2.68878415e-04, 1.61867138e-04, 1.28400090e-04,\n",
      "       2.13547537e-04, 2.05181757e-04, 7.98215333e-05, 1.30868022e-04,\n",
      "       8.85656191e-05, 2.66621151e-04, 1.45663624e-04, 1.75228968e-04,\n",
      "       2.70932156e-04, 2.86588795e-04, 3.31096642e-04, 1.38371455e-04,\n",
      "       1.61319971e-04, 2.47254269e-04, 1.50582069e-04, 1.36616800e-04,\n",
      "       2.50210869e-04, 2.02060532e-04, 2.41505200e-04, 2.27351557e-04,\n",
      "       1.29379696e-04, 2.51596590e-04, 2.17835041e-04, 8.41080182e-05,\n",
      "       1.83468161e-04, 1.65830032e-04, 1.59852105e-04, 2.27936674e-04,\n",
      "       9.91508932e-05, 2.79508851e-04, 1.11554808e-04, 1.21612895e-04,\n",
      "       2.11994207e-04, 2.22124188e-04, 2.00873663e-04, 1.54441164e-04,\n",
      "       1.70816420e-04, 1.78666509e-04, 2.05123259e-04, 2.25679803e-04,\n",
      "       2.26087388e-04, 2.96721148e-04, 1.48173727e-04, 1.73910172e-04,\n",
      "       2.49716715e-04, 2.07322533e-04, 2.16260640e-04, 2.51036370e-04,\n",
      "       1.86258083e-04, 2.69568089e-04, 1.55841975e-04, 2.89137912e-04,\n",
      "       2.68497941e-04, 1.38829768e-04, 2.21874958e-04, 1.07576525e-04,\n",
      "       2.53715756e-04, 2.18745787e-04, 2.19719645e-04, 1.66134152e-04,\n",
      "       2.04145210e-04, 1.40926393e-04, 1.53135014e-04, 1.25541788e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer6/sepconv/Relu6;tower0/network/layer6/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/depthwise;tower0/network/layer6/sepconv/depthwise,\n",
      "index: 50,\n",
      "shape: [  1  24  16 128],\n",
      "shape_signature: [  1  24  16 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer7/conv/Conv2D,\n",
      "index: 51,\n",
      "shape: [128   1   1 128],\n",
      "shape_signature: [128   1   1 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00217522, 0.00205196, 0.00338497, 0.00334902, 0.00294739,\n",
      "       0.00266475, 0.00230729, 0.00299532, 0.0024267 , 0.00354791,\n",
      "       0.00301968, 0.00375197, 0.00287602, 0.00586541, 0.00318433,\n",
      "       0.00287568, 0.00331165, 0.00304475, 0.00309263, 0.0047788 ,\n",
      "       0.00272995, 0.00220026, 0.00182721, 0.00443553, 0.0019279 ,\n",
      "       0.00394982, 0.00320585, 0.00469996, 0.00339265, 0.00279257,\n",
      "       0.00355797, 0.00202149, 0.0040368 , 0.00422992, 0.00343172,\n",
      "       0.00433246, 0.00308856, 0.00525892, 0.00273133, 0.0025006 ,\n",
      "       0.00240914, 0.00529759, 0.00368256, 0.00240389, 0.00281928,\n",
      "       0.00280361, 0.00319791, 0.00338851, 0.00237153, 0.00435047,\n",
      "       0.00234864, 0.00270508, 0.0040434 , 0.0033796 , 0.00292048,\n",
      "       0.00315377, 0.00257608, 0.00351976, 0.00220951, 0.00362792,\n",
      "       0.00429619, 0.00360471, 0.00402196, 0.00261616, 0.0042581 ,\n",
      "       0.00526399, 0.00381709, 0.00398022, 0.00221946, 0.00214713,\n",
      "       0.00349834, 0.00301059, 0.00320035, 0.00209096, 0.00276707,\n",
      "       0.00279395, 0.00285091, 0.0052782 , 0.00307857, 0.00307517,\n",
      "       0.00277296, 0.00345424, 0.00286263, 0.0060217 , 0.00452084,\n",
      "       0.00245111, 0.00295227, 0.00321396, 0.00326034, 0.00321856,\n",
      "       0.00303731, 0.00247013, 0.00184039, 0.00307631, 0.00440535,\n",
      "       0.00548959, 0.00266972, 0.00345742, 0.00282305, 0.00367447,\n",
      "       0.00241917, 0.00320244, 0.00252418, 0.00264764, 0.00247364,\n",
      "       0.00301219, 0.00290898, 0.00282114, 0.00267065, 0.0023297 ,\n",
      "       0.00444261, 0.00421516, 0.00342369, 0.00230351, 0.00174572,\n",
      "       0.00286489, 0.00290609, 0.00413146, 0.00540908, 0.00199103,\n",
      "       0.00334979, 0.0059789 , 0.00368982, 0.00191414, 0.00328459,\n",
      "       0.00321643, 0.00339339, 0.00228034], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer7/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 52,\n",
      "shape: [128],\n",
      "shape_signature: [128],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([5.11816761e-05, 4.82815049e-05, 7.96463501e-05, 7.88004181e-05,\n",
      "       6.93503098e-05, 6.26999536e-05, 5.42892485e-05, 7.04781414e-05,\n",
      "       5.70989214e-05, 8.34801904e-05, 7.10512613e-05, 8.82816312e-05,\n",
      "       6.76710260e-05, 1.38009549e-04, 7.49255196e-05, 6.76630516e-05,\n",
      "       7.79211477e-05, 7.16410941e-05, 7.27677107e-05, 1.12442300e-04,\n",
      "       6.42341329e-05, 5.17707158e-05, 4.29931206e-05, 1.04365303e-04,\n",
      "       4.53623143e-05, 9.29369126e-05, 7.54317371e-05, 1.10587338e-04,\n",
      "       7.98270703e-05, 6.57076162e-05, 8.37170519e-05, 4.75643938e-05,\n",
      "       9.49835448e-05, 9.95274968e-05, 8.07464603e-05, 1.01940328e-04,\n",
      "       7.26721119e-05, 1.23739272e-04, 6.42666564e-05, 5.88377006e-05,\n",
      "       5.66857234e-05, 1.24649261e-04, 8.66483824e-05, 5.65620576e-05,\n",
      "       6.63359242e-05, 6.59672805e-05, 7.52449487e-05, 7.97295506e-05,\n",
      "       5.58006686e-05, 1.02364102e-04, 5.52622223e-05, 6.36489058e-05,\n",
      "       9.51389229e-05, 7.95199521e-05, 6.87172942e-05, 7.42063930e-05,\n",
      "       6.06136309e-05, 8.28179473e-05, 5.19884379e-05, 8.53629317e-05,\n",
      "       1.01086858e-04, 8.48166746e-05, 9.46343716e-05, 6.15567697e-05,\n",
      "       1.00190526e-04, 1.23858670e-04, 8.98139842e-05, 9.36521537e-05,\n",
      "       5.22225382e-05, 5.05206881e-05, 8.23139562e-05, 7.08375010e-05,\n",
      "       7.53023123e-05, 4.91989449e-05, 6.51076334e-05, 6.57399287e-05,\n",
      "       6.70801892e-05, 1.24192855e-04, 7.24369966e-05, 7.23569974e-05,\n",
      "       6.52461022e-05, 8.12762373e-05, 6.73560135e-05, 1.41687095e-04,\n",
      "       1.06372718e-04, 5.76732236e-05, 6.94651899e-05, 7.56225054e-05,\n",
      "       7.67139209e-05, 7.57307134e-05, 7.14660418e-05, 5.81207314e-05,\n",
      "       4.33032765e-05, 7.23838166e-05, 1.03655380e-04, 1.29166743e-04,\n",
      "       6.28169073e-05, 8.13510342e-05, 6.64246909e-05, 8.64581743e-05,\n",
      "       5.69217627e-05, 7.53515633e-05, 5.93925615e-05, 6.22974694e-05,\n",
      "       5.82032080e-05, 7.08751031e-05, 6.84465922e-05, 6.63796745e-05,\n",
      "       6.28387133e-05, 5.48164135e-05, 1.04532111e-04, 9.91802153e-05,\n",
      "       8.05575110e-05, 5.42002563e-05, 4.10758694e-05, 6.74092662e-05,\n",
      "       6.83786566e-05, 9.72107955e-05, 1.27272375e-04, 4.68477447e-05,\n",
      "       7.88187026e-05, 1.40679942e-04, 8.68191928e-05, 4.50386433e-05,\n",
      "       7.72845815e-05, 7.56808222e-05, 7.98445690e-05, 5.36550942e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer7/conv/Relu6;tower0/network/layer7/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/depthwise;tower0/network/layer7/conv/Conv2D,\n",
      "index: 53,\n",
      "shape: [  1  24  16 128],\n",
      "shape_signature: [  1  24  16 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/depthwise,\n",
      "index: 54,\n",
      "shape: [  1   3   3 128],\n",
      "shape_signature: [  1   3   3 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00490898, 0.0059158 , 0.00463094, 0.00602755, 0.00632094,\n",
      "       0.00534756, 0.00509664, 0.00454824, 0.00554163, 0.00488272,\n",
      "       0.00581803, 0.00411961, 0.00316081, 0.00736857, 0.00350012,\n",
      "       0.0053113 , 0.00520141, 0.00403073, 0.00478913, 0.00550333,\n",
      "       0.00530597, 0.00608813, 0.00509492, 0.00503384, 0.00320262,\n",
      "       0.00668806, 0.00325679, 0.00428995, 0.00616883, 0.00560349,\n",
      "       0.0049613 , 0.00459324, 0.00613713, 0.00618864, 0.00467907,\n",
      "       0.0052089 , 0.0043815 , 0.0040734 , 0.00612234, 0.00520582,\n",
      "       0.00337127, 0.00450086, 0.00546669, 0.00551238, 0.00618024,\n",
      "       0.00636822, 0.00751683, 0.00469143, 0.00396017, 0.0044821 ,\n",
      "       0.00477536, 0.00852918, 0.00489328, 0.00520816, 0.00560325,\n",
      "       0.00577798, 0.00509606, 0.00579266, 0.0056209 , 0.00387802,\n",
      "       0.00733823, 0.00546327, 0.0066846 , 0.00296849, 0.00460254,\n",
      "       0.00554061, 0.00389789, 0.00584016, 0.00388581, 0.00561022,\n",
      "       0.00472309, 0.005031  , 0.00393315, 0.00421611, 0.0047144 ,\n",
      "       0.00415591, 0.00406686, 0.0047741 , 0.00437999, 0.00442253,\n",
      "       0.00517778, 0.00436759, 0.00437704, 0.00521002, 0.00390212,\n",
      "       0.0041087 , 0.00629463, 0.0068363 , 0.00478858, 0.00335939,\n",
      "       0.00359637, 0.00727401, 0.00524689, 0.00539806, 0.00361262,\n",
      "       0.00671925, 0.00602155, 0.00289251, 0.00528399, 0.00461998,\n",
      "       0.00412455, 0.00691321, 0.0037346 , 0.00589759, 0.00467768,\n",
      "       0.00518013, 0.00494924, 0.00516644, 0.00530373, 0.00654077,\n",
      "       0.00516245, 0.00552377, 0.00578608, 0.00557527, 0.00541084,\n",
      "       0.00395701, 0.00695331, 0.00450787, 0.00568326, 0.00433388,\n",
      "       0.00531033, 0.00431725, 0.00360478, 0.00382171, 0.00403604,\n",
      "       0.00570807, 0.00553932, 0.00619767], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 55,\n",
      "shape: [128],\n",
      "shape_signature: [128],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.15505522e-04, 1.39195283e-04, 1.08963388e-04, 1.41824756e-04,\n",
      "       1.48728126e-04, 1.25824969e-04, 1.19920907e-04, 1.07017448e-04,\n",
      "       1.30391345e-04, 1.14887531e-04, 1.36894712e-04, 9.69320026e-05,\n",
      "       7.43721030e-05, 1.73378066e-04, 8.23558075e-05, 1.24971702e-04,\n",
      "       1.22386016e-04, 9.48407105e-05, 1.12685419e-04, 1.29490058e-04,\n",
      "       1.24846294e-04, 1.43250174e-04, 1.19880482e-04, 1.18443240e-04,\n",
      "       7.53557470e-05, 1.57366187e-04, 7.66302473e-05, 1.00940044e-04,\n",
      "       1.45148966e-04, 1.31846769e-04, 1.16736468e-04, 1.08076340e-04,\n",
      "       1.44403137e-04, 1.45615020e-04, 1.10095876e-04, 1.22562473e-04,\n",
      "       1.03094200e-04, 9.58445962e-05, 1.44055011e-04, 1.22489932e-04,\n",
      "       7.93239160e-05, 1.05902509e-04, 1.28627958e-04, 1.29703025e-04,\n",
      "       1.45417449e-04, 1.49840460e-04, 1.76866568e-04, 1.10386623e-04,\n",
      "       9.31804243e-05, 1.05461229e-04, 1.12361464e-04, 2.00686700e-04,\n",
      "       1.15136027e-04, 1.22544850e-04, 1.31841211e-04, 1.35952490e-04,\n",
      "       1.19907294e-04, 1.36297880e-04, 1.32256522e-04, 9.12474934e-05,\n",
      "       1.72664179e-04, 1.28547559e-04, 1.57284623e-04, 6.98468066e-05,\n",
      "       1.08295011e-04, 1.30367189e-04, 9.17149810e-05, 1.37415554e-04,\n",
      "       9.14307238e-05, 1.32005269e-04, 1.11131594e-04, 1.18376534e-04,\n",
      "       9.25447894e-05, 9.92025671e-05, 1.10927009e-04, 9.77860691e-05,\n",
      "       9.56907679e-05, 1.12331756e-04, 1.03058548e-04, 1.04059465e-04,\n",
      "       1.21830220e-04, 1.02766913e-04, 1.02989281e-04, 1.22588768e-04,\n",
      "       9.18146397e-05, 9.66753068e-05, 1.48108942e-04, 1.60854135e-04,\n",
      "       1.12672402e-04, 7.90444246e-05, 8.46204275e-05, 1.71153079e-04,\n",
      "       1.23456179e-04, 1.27013060e-04, 8.50029028e-05, 1.58099923e-04,\n",
      "       1.41683602e-04, 6.80589801e-05, 1.24329279e-04, 1.08705441e-04,\n",
      "       9.70481415e-05, 1.62663768e-04, 8.78730134e-05, 1.38766904e-04,\n",
      "       1.10062982e-04, 1.21885510e-04, 1.16452786e-04, 1.21563338e-04,\n",
      "       1.24793587e-04, 1.53900430e-04, 1.21469413e-04, 1.29971173e-04,\n",
      "       1.36143019e-04, 1.31182765e-04, 1.27313833e-04, 9.31062168e-05,\n",
      "       1.63607328e-04, 1.06067455e-04, 1.33723850e-04, 1.01973535e-04,\n",
      "       1.24948914e-04, 1.01582293e-04, 8.48182826e-05, 8.99226579e-05,\n",
      "       9.49657187e-05, 1.34307527e-04, 1.30336834e-04, 1.45827638e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer8/sepconv/Relu6;tower0/network/layer8/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer8/sepconv/depthwise,\n",
      "index: 56,\n",
      "shape: [  1  12   8 128],\n",
      "shape_signature: [  1  12   8 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer9/conv/Conv2D,\n",
      "index: 57,\n",
      "shape: [256   1   1 128],\n",
      "shape_signature: [256   1   1 128],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00247579, 0.00366727, 0.00264686, 0.00345195, 0.00304783,\n",
      "       0.00323336, 0.00361659, 0.00245561, 0.00291994, 0.00189138,\n",
      "       0.00328047, 0.00245256, 0.00169327, 0.00253718, 0.00725346,\n",
      "       0.0021282 , 0.00202032, 0.00244585, 0.00184418, 0.00387072,\n",
      "       0.00352925, 0.00401018, 0.00217843, 0.00228757, 0.00289753,\n",
      "       0.00261064, 0.00261479, 0.00344239, 0.00248621, 0.0031917 ,\n",
      "       0.00280619, 0.00273336, 0.00385785, 0.00496206, 0.00437591,\n",
      "       0.00264272, 0.002959  , 0.00267437, 0.00178725, 0.00193781,\n",
      "       0.00305434, 0.00346545, 0.00180437, 0.00394038, 0.0026931 ,\n",
      "       0.00223022, 0.00612987, 0.00207266, 0.00216622, 0.00157733,\n",
      "       0.00167153, 0.00218741, 0.00176592, 0.00169388, 0.00523643,\n",
      "       0.00435687, 0.00240047, 0.00455657, 0.00246976, 0.00160098,\n",
      "       0.00237773, 0.00280966, 0.00245042, 0.00279871, 0.00224329,\n",
      "       0.00202313, 0.00472962, 0.00221508, 0.00319715, 0.00197869,\n",
      "       0.00268292, 0.00314822, 0.00392102, 0.00400003, 0.00526215,\n",
      "       0.00373561, 0.00257189, 0.0028399 , 0.00195536, 0.00285007,\n",
      "       0.00270191, 0.00367122, 0.00174973, 0.003241  , 0.00392739,\n",
      "       0.00280918, 0.00341958, 0.00242386, 0.00412173, 0.00296509,\n",
      "       0.00341128, 0.00258646, 0.00316136, 0.00306441, 0.00243587,\n",
      "       0.0023142 , 0.00271837, 0.00366155, 0.00278983, 0.0023286 ,\n",
      "       0.00295272, 0.00394534, 0.00228192, 0.0018927 , 0.00245878,\n",
      "       0.00221635, 0.00306701, 0.00203821, 0.00304089, 0.00255812,\n",
      "       0.00486444, 0.00389748, 0.00257795, 0.00287278, 0.0023399 ,\n",
      "       0.00230643, 0.00185833, 0.00394017, 0.00270532, 0.00252062,\n",
      "       0.00259236, 0.00281792, 0.00329881, 0.00206965, 0.00168957,\n",
      "       0.0025942 , 0.00324288, 0.00384215, 0.00210275, 0.00241415,\n",
      "       0.00166181, 0.00199371, 0.00243385, 0.00271805, 0.00168709,\n",
      "       0.0028104 , 0.0025084 , 0.00286197, 0.00269877, 0.00247694,\n",
      "       0.00183304, 0.00183141, 0.00299698, 0.00245249, 0.00280375,\n",
      "       0.0027975 , 0.00174423, 0.00394165, 0.00210297, 0.00253335,\n",
      "       0.00373314, 0.00211072, 0.00243025, 0.00380482, 0.0017343 ,\n",
      "       0.00201589, 0.00331289, 0.0024527 , 0.00257555, 0.0033247 ,\n",
      "       0.00281212, 0.00187263, 0.00237381, 0.00233001, 0.00187671,\n",
      "       0.00219797, 0.00321449, 0.00250215, 0.00320066, 0.00207286,\n",
      "       0.0024923 , 0.00262713, 0.00352854, 0.00243908, 0.00248591,\n",
      "       0.00370005, 0.00302274, 0.0027921 , 0.00283504, 0.0025314 ,\n",
      "       0.00271102, 0.00243435, 0.00343227, 0.00351648, 0.00181151,\n",
      "       0.00169462, 0.00278444, 0.00204372, 0.00278021, 0.0026979 ,\n",
      "       0.00324777, 0.00297989, 0.00243808, 0.00166243, 0.00357703,\n",
      "       0.00236704, 0.00416186, 0.00437242, 0.00483722, 0.0028135 ,\n",
      "       0.00186746, 0.00214003, 0.00226788, 0.00220902, 0.00216354,\n",
      "       0.00241022, 0.00209376, 0.00300398, 0.002438  , 0.00222529,\n",
      "       0.00245082, 0.00287098, 0.00407486, 0.00401557, 0.00267039,\n",
      "       0.0019645 , 0.00289385, 0.00360173, 0.00214663, 0.00258395,\n",
      "       0.00250465, 0.00385772, 0.00237328, 0.00239983, 0.00200968,\n",
      "       0.00335506, 0.00239601, 0.00192072, 0.00616493, 0.00211918,\n",
      "       0.0026537 , 0.00296506, 0.002194  , 0.00243905, 0.00443834,\n",
      "       0.00224887, 0.00207081, 0.00201733, 0.00332276, 0.00300518,\n",
      "       0.00207783, 0.00298096, 0.00171811, 0.00305948, 0.00185862,\n",
      "       0.00209745, 0.00351423, 0.00412403, 0.00552386, 0.00250482,\n",
      "       0.00181908, 0.00300572, 0.00318641, 0.00392959, 0.00312775,\n",
      "       0.00227382], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer9/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 58,\n",
      "shape: [256],\n",
      "shape_signature: [256],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([5.82538996e-05, 8.62886882e-05, 6.22790394e-05, 8.12222934e-05,\n",
      "       7.17136645e-05, 7.60790572e-05, 8.50962097e-05, 5.77789760e-05,\n",
      "       6.87045103e-05, 4.45031219e-05, 7.71875566e-05, 5.77073442e-05,\n",
      "       3.98416014e-05, 5.96983045e-05, 1.70669635e-04, 5.00752431e-05,\n",
      "       4.75369634e-05, 5.75493104e-05, 4.33923815e-05, 9.10757153e-05,\n",
      "       8.30412610e-05, 9.43571649e-05, 5.12572951e-05, 5.38251370e-05,\n",
      "       6.81770834e-05, 6.14268356e-05, 6.15243625e-05, 8.09974517e-05,\n",
      "       5.84989684e-05, 7.50987529e-05, 6.60278893e-05, 6.43144085e-05,\n",
      "       9.07729118e-05, 1.16754389e-04, 1.02962498e-04, 6.21817380e-05,\n",
      "       6.96235220e-05, 6.29264323e-05, 4.20529759e-05, 4.55955669e-05,\n",
      "       7.18667579e-05, 8.15400781e-05, 4.24556638e-05, 9.27149158e-05,\n",
      "       6.33670352e-05, 5.24756724e-05, 1.44232195e-04, 4.87685284e-05,\n",
      "       5.09698548e-05, 3.71135429e-05, 3.93300943e-05, 5.14683998e-05,\n",
      "       4.15510003e-05, 3.98560260e-05, 1.23210062e-04, 1.02514576e-04,\n",
      "       5.64816146e-05, 1.07213498e-04, 5.81119930e-05, 3.76700664e-05,\n",
      "       5.59465079e-05, 6.61096055e-05, 5.76570492e-05, 6.58520948e-05,\n",
      "       5.27832126e-05, 4.76030255e-05, 1.11285262e-04, 5.21196052e-05,\n",
      "       7.52271299e-05, 4.65575249e-05, 6.31275179e-05, 7.40758187e-05,\n",
      "       9.22593390e-05, 9.41184408e-05, 1.23815364e-04, 8.78967840e-05,\n",
      "       6.05150999e-05, 6.68212379e-05, 4.60084957e-05, 6.70605514e-05,\n",
      "       6.35744436e-05, 8.63817550e-05, 4.11701658e-05, 7.62588679e-05,\n",
      "       9.24092383e-05, 6.60984660e-05, 8.04606534e-05, 5.70320590e-05,\n",
      "       9.69819230e-05, 6.97668729e-05, 8.02654977e-05, 6.08577684e-05,\n",
      "       7.43850542e-05, 7.21037359e-05, 5.73146099e-05, 5.44518225e-05,\n",
      "       6.39615464e-05, 8.61540975e-05, 6.56429547e-05, 5.47905947e-05,\n",
      "       6.94757618e-05, 9.28314985e-05, 5.36923435e-05, 4.45340338e-05,\n",
      "       5.78537474e-05, 5.21494803e-05, 7.21648830e-05, 4.79579758e-05,\n",
      "       7.15503556e-05, 6.01910506e-05, 1.14457478e-04, 9.17053112e-05,\n",
      "       6.06576032e-05, 6.75947667e-05, 5.50565273e-05, 5.42689559e-05,\n",
      "       4.37253948e-05, 9.27097790e-05, 6.36545956e-05, 5.93086988e-05,\n",
      "       6.09966592e-05, 6.63039973e-05, 7.76191446e-05, 4.86976642e-05,\n",
      "       3.97546610e-05, 6.10400530e-05, 7.63029821e-05, 9.04034314e-05,\n",
      "       4.94765736e-05, 5.68036048e-05, 3.91014873e-05, 4.69107799e-05,\n",
      "       5.72671415e-05, 6.39540522e-05, 3.96961805e-05, 6.61270678e-05,\n",
      "       5.90212912e-05, 6.73403702e-05, 6.35005708e-05, 5.82809844e-05,\n",
      "       4.31304179e-05, 4.30919754e-05, 7.05171260e-05, 5.77057617e-05,\n",
      "       6.59706930e-05, 6.58235440e-05, 4.10405919e-05, 9.27446308e-05,\n",
      "       4.94816013e-05, 5.96083155e-05, 8.78386636e-05, 4.96640314e-05,\n",
      "       5.71824239e-05, 8.95250632e-05, 4.08071610e-05, 4.74327899e-05,\n",
      "       7.79504189e-05, 5.77105820e-05, 6.06011599e-05, 7.82282514e-05,\n",
      "       6.61674130e-05, 4.40619551e-05, 5.58542379e-05, 5.48237986e-05,\n",
      "       4.41578377e-05, 5.17169392e-05, 7.56350928e-05, 5.88740004e-05,\n",
      "       7.53095301e-05, 4.87731850e-05, 5.86422539e-05, 6.18148842e-05,\n",
      "       8.30244317e-05, 5.73900434e-05, 5.84919253e-05, 8.70599761e-05,\n",
      "       7.11233879e-05, 6.56965785e-05, 6.67069326e-05, 5.95623096e-05,\n",
      "       6.37886478e-05, 5.72787612e-05, 8.07593533e-05, 8.27408003e-05,\n",
      "       4.26237893e-05, 3.98734628e-05, 6.55162439e-05, 4.80875642e-05,\n",
      "       6.54167816e-05, 6.34800526e-05, 7.64180222e-05, 7.01151730e-05,\n",
      "       5.73665966e-05, 3.91159119e-05, 8.41654473e-05, 5.56950945e-05,\n",
      "       9.79262040e-05, 1.02880455e-04, 1.13816925e-04, 6.61999948e-05,\n",
      "       4.39401192e-05, 5.03537085e-05, 5.33619532e-05, 5.19770329e-05,\n",
      "       5.09069105e-05, 5.67110001e-05, 4.92649015e-05, 7.06819046e-05,\n",
      "       5.73647885e-05, 5.23597628e-05, 5.76662896e-05, 6.75525152e-05,\n",
      "       9.58790915e-05, 9.44839048e-05, 6.28326525e-05, 4.62235730e-05,\n",
      "       6.80904996e-05, 8.47465344e-05, 5.05089884e-05, 6.07987204e-05,\n",
      "       5.89330411e-05, 9.07697977e-05, 5.58419342e-05, 5.64665388e-05,\n",
      "       4.72864813e-05, 7.89425103e-05, 5.63767644e-05, 4.51935048e-05,\n",
      "       1.45057289e-04, 4.98629670e-05, 6.24400927e-05, 6.97661817e-05,\n",
      "       5.16236396e-05, 5.73894249e-05, 1.04431529e-04, 5.29146855e-05,\n",
      "       4.87248326e-05, 4.74665103e-05, 7.81825875e-05, 7.07100116e-05,\n",
      "       4.88901533e-05, 7.01401223e-05, 4.04261955e-05, 7.19878662e-05,\n",
      "       4.37322851e-05, 4.93517000e-05, 8.26877949e-05, 9.70359251e-05,\n",
      "       1.29973065e-04, 5.89369047e-05, 4.28018211e-05, 7.07228755e-05,\n",
      "       7.49743776e-05, 9.24610576e-05, 7.35941503e-05, 5.35015788e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer9/conv/Relu6;tower0/network/layer9/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/depthwise;tower0/network/layer9/conv/Conv2D,\n",
      "index: 59,\n",
      "shape: [  1  12   8 256],\n",
      "shape_signature: [  1  12   8 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer10/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer10/sepconv/depthwise;tower0/network/layer12/sepconv/depthwise,\n",
      "index: 60,\n",
      "shape: [  1   3   3 256],\n",
      "shape_signature: [  1   3   3 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.01078955, 0.01062805, 0.00657475, 0.0091349 , 0.0052887 ,\n",
      "       0.00677208, 0.01237084, 0.01349712, 0.00656135, 0.01134517,\n",
      "       0.00709569, 0.00490032, 0.00649978, 0.01049458, 0.00575535,\n",
      "       0.00531634, 0.00497214, 0.00773023, 0.0067343 , 0.00756304,\n",
      "       0.00609733, 0.00728421, 0.00737106, 0.00909402, 0.00481528,\n",
      "       0.00984044, 0.00691309, 0.00777321, 0.00918333, 0.00792599,\n",
      "       0.00838694, 0.00977523, 0.00799655, 0.01001771, 0.0036187 ,\n",
      "       0.00591606, 0.00848973, 0.00987361, 0.00876699, 0.01173928,\n",
      "       0.00479827, 0.0102241 , 0.00873771, 0.0080409 , 0.01035829,\n",
      "       0.00845134, 0.00636215, 0.00492188, 0.00787616, 0.00920066,\n",
      "       0.00804599, 0.00926927, 0.00524774, 0.009839  , 0.00652765,\n",
      "       0.0094328 , 0.00699412, 0.01066759, 0.00694696, 0.00779941,\n",
      "       0.00739497, 0.00604662, 0.00950051, 0.00842768, 0.00616637,\n",
      "       0.01026927, 0.00685406, 0.0062657 , 0.00664031, 0.00678206,\n",
      "       0.00770514, 0.00847044, 0.00544311, 0.00447771, 0.01175193,\n",
      "       0.01198972, 0.00950945, 0.00450864, 0.01074622, 0.00351411,\n",
      "       0.00841759, 0.00543468, 0.00698923, 0.0128179 , 0.00980973,\n",
      "       0.00969648, 0.01096928, 0.00891456, 0.00541288, 0.01054278,\n",
      "       0.00985362, 0.01271095, 0.00366591, 0.00707409, 0.00713978,\n",
      "       0.00742658, 0.00773905, 0.00668965, 0.01189611, 0.00944904,\n",
      "       0.01216337, 0.01065249, 0.00935034, 0.00982439, 0.00643644,\n",
      "       0.00480256, 0.00923896, 0.00562919, 0.00435199, 0.00783321,\n",
      "       0.00459691, 0.00779983, 0.00561481, 0.00879384, 0.00996485,\n",
      "       0.0060585 , 0.00816129, 0.00708805, 0.00961318, 0.00984561,\n",
      "       0.00671406, 0.00519793, 0.00838334, 0.00838956, 0.0065346 ,\n",
      "       0.01045087, 0.00719659, 0.00696563, 0.00575772, 0.00771737,\n",
      "       0.0076403 , 0.00840661, 0.01299498, 0.00731635, 0.00521071,\n",
      "       0.00684012, 0.00716807, 0.00517434, 0.01104217, 0.00668829,\n",
      "       0.00741965, 0.01016581, 0.00511254, 0.00644542, 0.0058279 ,\n",
      "       0.0073862 , 0.00477085, 0.00680207, 0.00698167, 0.00594848,\n",
      "       0.006008  , 0.00538896, 0.01058752, 0.00361437, 0.0043858 ,\n",
      "       0.00728471, 0.00740437, 0.00713183, 0.00573081, 0.00553913,\n",
      "       0.00694518, 0.01101011, 0.00698505, 0.00539128, 0.00679451,\n",
      "       0.00851917, 0.00963972, 0.01002961, 0.00740248, 0.00751802,\n",
      "       0.00422099, 0.01097718, 0.01305694, 0.00768394, 0.00643816,\n",
      "       0.01025801, 0.00545234, 0.00979443, 0.00984577, 0.00543821,\n",
      "       0.00857141, 0.00700395, 0.0063369 , 0.00455247, 0.0086057 ,\n",
      "       0.00843197, 0.01110754, 0.00564075, 0.00263069, 0.00820976,\n",
      "       0.00744096, 0.00761516, 0.00360866, 0.00694887, 0.00355973,\n",
      "       0.01170462, 0.00360581, 0.0055898 , 0.0048994 , 0.00815548,\n",
      "       0.01031564, 0.00659534, 0.01049798, 0.00837444, 0.00853355,\n",
      "       0.00541481, 0.01061849, 0.00798357, 0.00831786, 0.00837623,\n",
      "       0.01106696, 0.00469355, 0.01028202, 0.00808464, 0.00355462,\n",
      "       0.00778919, 0.0066601 , 0.01012177, 0.00865736, 0.00995012,\n",
      "       0.00887855, 0.00541061, 0.00698041, 0.01021989, 0.00646254,\n",
      "       0.00848468, 0.01015573, 0.00768327, 0.00718752, 0.00502766,\n",
      "       0.0095451 , 0.00692057, 0.00565679, 0.00703349, 0.00784309,\n",
      "       0.00834254, 0.00687815, 0.00670777, 0.00625581, 0.00966241,\n",
      "       0.00492475, 0.00850167, 0.01115666, 0.00763862, 0.0109458 ,\n",
      "       0.00646268, 0.00797124, 0.00828371, 0.00672894, 0.0103833 ,\n",
      "       0.00976363, 0.00679591, 0.00559456, 0.00722303, 0.00456922,\n",
      "       0.01102602], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer10/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 61,\n",
      "shape: [256],\n",
      "shape_signature: [256],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.53871840e-04, 2.50071666e-04, 1.54699941e-04, 2.14938918e-04,\n",
      "       1.24440121e-04, 1.59343021e-04, 2.91078701e-04, 3.17579194e-04,\n",
      "       1.54384805e-04, 2.66945077e-04, 1.66957441e-04, 1.15301547e-04,\n",
      "       1.52936045e-04, 2.46931275e-04, 1.35420065e-04, 1.25090359e-04,\n",
      "       1.16991607e-04, 1.81887866e-04, 1.58454044e-04, 1.77953829e-04,\n",
      "       1.43466546e-04, 1.71393185e-04, 1.73436711e-04, 2.13976906e-04,\n",
      "       1.13300797e-04, 2.31539685e-04, 1.62660930e-04, 1.82899137e-04,\n",
      "       2.16078406e-04, 1.86493911e-04, 1.97339716e-04, 2.30005404e-04,\n",
      "       1.88154227e-04, 2.35710861e-04, 8.51459699e-05, 1.39201482e-04,\n",
      "       1.99758346e-04, 2.32320148e-04, 2.06282217e-04, 2.76218459e-04,\n",
      "       1.12900416e-04, 2.40567097e-04, 2.05593169e-04, 1.89197614e-04,\n",
      "       2.43724367e-04, 1.98855021e-04, 1.49697618e-04, 1.15808987e-04,\n",
      "       1.85321522e-04, 2.16486224e-04, 1.89317390e-04, 2.18100584e-04,\n",
      "       1.23476333e-04, 2.31505939e-04, 1.53591754e-04, 2.21948198e-04,\n",
      "       1.64567551e-04, 2.51002057e-04, 1.63457968e-04, 1.83515469e-04,\n",
      "       1.73999390e-04, 1.42273493e-04, 2.23541530e-04, 1.98298367e-04,\n",
      "       1.45091137e-04, 2.41629867e-04, 1.61271892e-04, 1.47428349e-04,\n",
      "       1.56242473e-04, 1.59577801e-04, 1.81297495e-04, 1.99304486e-04,\n",
      "       1.28073283e-04, 1.05357831e-04, 2.76516133e-04, 2.82111054e-04,\n",
      "       2.23751849e-04, 1.06085623e-04, 2.52852129e-04, 8.26848627e-05,\n",
      "       1.98060909e-04, 1.27874853e-04, 1.64452547e-04, 3.01597524e-04,\n",
      "       2.30817284e-04, 2.28152378e-04, 2.58100685e-04, 2.09754377e-04,\n",
      "       1.27361927e-04, 2.48065509e-04, 2.31849961e-04, 2.99081119e-04,\n",
      "       8.62566521e-05, 1.66449157e-04, 1.67994745e-04, 1.74743021e-04,\n",
      "       1.82095246e-04, 1.57403469e-04, 2.79908418e-04, 2.22330287e-04,\n",
      "       2.86196999e-04, 2.50646932e-04, 2.20007918e-04, 2.31162048e-04,\n",
      "       1.51445682e-04, 1.13001326e-04, 2.17387264e-04, 1.32451445e-04,\n",
      "       1.02399783e-04, 1.84310848e-04, 1.08162560e-04, 1.83525437e-04,\n",
      "       1.32113113e-04, 2.06913886e-04, 2.34467065e-04, 1.42552832e-04,\n",
      "       1.92030435e-04, 1.66777740e-04, 2.26192380e-04, 2.31661412e-04,\n",
      "       1.57977847e-04, 1.22304220e-04, 1.97255184e-04, 1.97401401e-04,\n",
      "       1.53755362e-04, 2.45902833e-04, 1.69331426e-04, 1.63897261e-04,\n",
      "       1.35475799e-04, 1.81585259e-04, 1.79771770e-04, 1.97802568e-04,\n",
      "       3.05764348e-04, 1.72149506e-04, 1.22604964e-04, 1.60944110e-04,\n",
      "       1.68660423e-04, 1.21749174e-04, 2.59815832e-04, 1.57371556e-04,\n",
      "       1.74579909e-04, 2.39195593e-04, 1.20295081e-04, 1.51656874e-04,\n",
      "       1.37127106e-04, 1.73793014e-04, 1.12255228e-04, 1.60048614e-04,\n",
      "       1.64274519e-04, 1.39964148e-04, 1.41364610e-04, 1.26799103e-04,\n",
      "       2.49118049e-04, 8.50440192e-05, 1.03195285e-04, 1.71404914e-04,\n",
      "       1.74220404e-04, 1.67807782e-04, 1.34842703e-04, 1.30332584e-04,\n",
      "       1.63416014e-04, 2.59061344e-04, 1.64354031e-04, 1.26853673e-04,\n",
      "       1.59870746e-04, 2.00451075e-04, 2.26816934e-04, 2.35990767e-04,\n",
      "       1.74176064e-04, 1.76894478e-04, 9.93173380e-05, 2.58286542e-04,\n",
      "       3.07222159e-04, 1.80798554e-04, 1.51486063e-04, 2.41364891e-04,\n",
      "       1.28290369e-04, 2.30457270e-04, 2.31665108e-04, 1.27957872e-04,\n",
      "       2.01680334e-04, 1.64798868e-04, 1.49103449e-04, 1.07116997e-04,\n",
      "       2.02487034e-04, 1.98399212e-04, 2.61353911e-04, 1.32723435e-04,\n",
      "       6.18985723e-05, 1.93170796e-04, 1.75081455e-04, 1.79180119e-04,\n",
      "       8.49097414e-05, 1.63502802e-04, 8.37583138e-05, 2.75402796e-04,\n",
      "       8.48425771e-05, 1.31524794e-04, 1.15280076e-04, 1.91893603e-04,\n",
      "       2.42721057e-04, 1.55184476e-04, 2.47011281e-04, 1.97045621e-04,\n",
      "       2.00789465e-04, 1.27407242e-04, 2.49846809e-04, 1.87848826e-04,\n",
      "       1.95714310e-04, 1.97087720e-04, 2.60399043e-04, 1.10436580e-04,\n",
      "       2.41929825e-04, 1.90226827e-04, 8.36381587e-05, 1.83275159e-04,\n",
      "       1.56708222e-04, 2.38159351e-04, 2.03702497e-04, 2.34120540e-04,\n",
      "       2.08907033e-04, 1.27308493e-04, 1.64245008e-04, 2.40468042e-04,\n",
      "       1.52059685e-04, 1.99639559e-04, 2.38958397e-04, 1.80782736e-04,\n",
      "       1.69118241e-04, 1.18297889e-04, 2.24590651e-04, 1.62837052e-04,\n",
      "       1.33100912e-04, 1.65493999e-04, 1.84543373e-04, 1.96295063e-04,\n",
      "       1.61838820e-04, 1.57829811e-04, 1.47195635e-04, 2.27350785e-04,\n",
      "       1.15876508e-04, 2.00039212e-04, 2.62509653e-04, 1.79732349e-04,\n",
      "       2.57548294e-04, 1.52063076e-04, 1.87558690e-04, 1.94910812e-04,\n",
      "       1.58327966e-04, 2.44312949e-04, 2.29732454e-04, 1.59903720e-04,\n",
      "       1.31636698e-04, 1.69953739e-04, 1.07511143e-04, 2.59435794e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer10/sepconv/Relu6;tower0/network/layer10/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/depthwise;tower0/network/layer10/sepconv/depthwise,\n",
      "index: 62,\n",
      "shape: [  1  12   8 256],\n",
      "shape_signature: [  1  12   8 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer11/conv/Conv2D,\n",
      "index: 63,\n",
      "shape: [256   1   1 256],\n",
      "shape_signature: [256   1   1 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00170239, 0.00149788, 0.00251153, 0.00183307, 0.00259598,\n",
      "       0.00169108, 0.0017675 , 0.00243659, 0.00186674, 0.002171  ,\n",
      "       0.00160221, 0.00194364, 0.0017826 , 0.00278085, 0.00579732,\n",
      "       0.00237104, 0.00150807, 0.00231788, 0.00169048, 0.00169434,\n",
      "       0.00160907, 0.0030378 , 0.00253564, 0.00241542, 0.00202608,\n",
      "       0.00328503, 0.00213878, 0.00208218, 0.00200774, 0.00198754,\n",
      "       0.00193463, 0.00167076, 0.00177625, 0.00194353, 0.00377008,\n",
      "       0.00203123, 0.001566  , 0.00188969, 0.00255495, 0.00245108,\n",
      "       0.00202465, 0.00217163, 0.00252098, 0.00176606, 0.00192674,\n",
      "       0.00230113, 0.00184585, 0.00192298, 0.00201714, 0.00184055,\n",
      "       0.00173169, 0.00197921, 0.00209056, 0.00264138, 0.00141052,\n",
      "       0.00375562, 0.00218774, 0.00270783, 0.00193277, 0.00234619,\n",
      "       0.00229499, 0.00161747, 0.00310568, 0.00177176, 0.00180306,\n",
      "       0.00162246, 0.00207372, 0.00184814, 0.00174054, 0.00286069,\n",
      "       0.00176564, 0.00167748, 0.00204433, 0.00193407, 0.00178476,\n",
      "       0.00170448, 0.00178873, 0.00235435, 0.00138091, 0.00253573,\n",
      "       0.00198662, 0.00221176, 0.00174748, 0.00174892, 0.00182967,\n",
      "       0.00227501, 0.00154898, 0.00188445, 0.00339152, 0.00193028,\n",
      "       0.00184395, 0.00181839, 0.00302487, 0.00299188, 0.00253524,\n",
      "       0.00173259, 0.00173864, 0.00179151, 0.00233652, 0.00369077,\n",
      "       0.0015764 , 0.0018314 , 0.00215752, 0.0015066 , 0.00179864,\n",
      "       0.0023487 , 0.00206268, 0.0019249 , 0.00190884, 0.00155733,\n",
      "       0.00171253, 0.0017882 , 0.00164517, 0.00146516, 0.00196721,\n",
      "       0.00162392, 0.00169593, 0.00278331, 0.00345597, 0.00203468,\n",
      "       0.00222548, 0.00192114, 0.00339399, 0.00402665, 0.00183838,\n",
      "       0.00166515, 0.00254024, 0.00193674, 0.00194727, 0.00203597,\n",
      "       0.00253293, 0.00148327, 0.00194989, 0.00280958, 0.00205243,\n",
      "       0.00194789, 0.00164387, 0.00214176, 0.00187835, 0.00253507,\n",
      "       0.00164268, 0.00219846, 0.00187017, 0.0020915 , 0.00194614,\n",
      "       0.00140759, 0.00189263, 0.00231278, 0.00171964, 0.00204751,\n",
      "       0.00179245, 0.00182541, 0.00160789, 0.0038615 , 0.00154343,\n",
      "       0.00230179, 0.00172364, 0.00248284, 0.00194225, 0.00213827,\n",
      "       0.00154514, 0.00280526, 0.00312925, 0.00181523, 0.00237351,\n",
      "       0.00189392, 0.00200848, 0.00179451, 0.00163364, 0.00225879,\n",
      "       0.00243442, 0.00175203, 0.00331047, 0.00158496, 0.00162458,\n",
      "       0.00231749, 0.00344202, 0.00180544, 0.00537644, 0.00120726,\n",
      "       0.00148812, 0.00247431, 0.001842  , 0.00232947, 0.00196352,\n",
      "       0.00204414, 0.00254307, 0.00208032, 0.00204016, 0.00179357,\n",
      "       0.00179419, 0.00226012, 0.00232466, 0.00209555, 0.00155125,\n",
      "       0.00212067, 0.00243385, 0.00411332, 0.00241542, 0.0025707 ,\n",
      "       0.00240135, 0.00186864, 0.0017024 , 0.00244677, 0.00163291,\n",
      "       0.00199307, 0.00171577, 0.00185095, 0.00220144, 0.0025507 ,\n",
      "       0.00237943, 0.00270162, 0.00222532, 0.00162776, 0.00177363,\n",
      "       0.00179735, 0.00206569, 0.00204576, 0.00205315, 0.00182983,\n",
      "       0.0020578 , 0.00167938, 0.00331956, 0.0034671 , 0.00167886,\n",
      "       0.0020079 , 0.00217485, 0.00273091, 0.00200545, 0.00180177,\n",
      "       0.00200268, 0.00233535, 0.0019626 , 0.00161462, 0.00176566,\n",
      "       0.00211211, 0.00195792, 0.00200958, 0.00171286, 0.00211655,\n",
      "       0.00180308, 0.00158982, 0.00202184, 0.00238242, 0.0027335 ,\n",
      "       0.00266084, 0.00192575, 0.0024387 , 0.00209358, 0.001803  ,\n",
      "       0.00201967, 0.00144714, 0.001721  , 0.00161424, 0.00206782,\n",
      "       0.00169225], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer11/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 64,\n",
      "shape: [256],\n",
      "shape_signature: [256],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([4.0056260e-05, 3.5244349e-05, 5.9094866e-05, 4.3130964e-05,\n",
      "       6.1081919e-05, 3.9790233e-05, 4.1588268e-05, 5.7331436e-05,\n",
      "       4.3923399e-05, 5.1082443e-05, 3.7699101e-05, 4.5732741e-05,\n",
      "       4.1943440e-05, 6.5431726e-05, 1.3640760e-04, 5.5789082e-05,\n",
      "       3.5483990e-05, 5.4538461e-05, 3.9776005e-05, 3.9866838e-05,\n",
      "       3.7860522e-05, 7.1477712e-05, 5.9662132e-05, 5.6833527e-05,\n",
      "       4.7672493e-05, 7.7294739e-05, 5.0324237e-05, 4.8992515e-05,\n",
      "       4.7240861e-05, 4.6765606e-05, 4.5520610e-05, 3.9311890e-05,\n",
      "       4.1794119e-05, 4.5730139e-05, 8.8707842e-05, 4.7793739e-05,\n",
      "       3.6847039e-05, 4.4463322e-05, 6.0116527e-05, 5.7672518e-05,\n",
      "       4.7638743e-05, 5.1097260e-05, 5.9317103e-05, 4.1554289e-05,\n",
      "       4.5334993e-05, 5.4144279e-05, 4.3431693e-05, 4.5246517e-05,\n",
      "       4.7462090e-05, 4.3307125e-05, 4.0745585e-05, 4.6569679e-05,\n",
      "       4.9189628e-05, 6.2150008e-05, 3.3188731e-05, 8.8367415e-05,\n",
      "       5.1476247e-05, 6.3713756e-05, 4.5476845e-05, 5.5204466e-05,\n",
      "       5.3999713e-05, 3.8058140e-05, 7.3074851e-05, 4.1688356e-05,\n",
      "       4.2425032e-05, 3.8175414e-05, 4.8793449e-05, 4.3485579e-05,\n",
      "       4.0953779e-05, 6.7310313e-05, 4.1544536e-05, 3.9470142e-05,\n",
      "       4.8101821e-05, 4.5507644e-05, 4.1994317e-05, 4.0105475e-05,\n",
      "       4.2087839e-05, 5.5396387e-05, 3.2491913e-05, 5.9664224e-05,\n",
      "       4.6744073e-05, 5.2041330e-05, 4.1117168e-05, 4.1151143e-05,\n",
      "       4.3051034e-05, 5.3529646e-05, 3.6446563e-05, 4.4339886e-05,\n",
      "       7.9800411e-05, 4.5418361e-05, 4.3387106e-05, 4.2785556e-05,\n",
      "       7.1173410e-05, 7.0397225e-05, 5.9652597e-05, 4.0766845e-05,\n",
      "       4.0909264e-05, 4.2153162e-05, 5.4976903e-05, 8.6841719e-05,\n",
      "       3.7091744e-05, 4.3091870e-05, 5.0765149e-05, 3.5449437e-05,\n",
      "       4.2320920e-05, 5.5263456e-05, 4.8533744e-05, 4.5291665e-05,\n",
      "       4.4913915e-05, 3.6643029e-05, 4.0294901e-05, 4.2075400e-05,\n",
      "       3.8709899e-05, 3.4474273e-05, 4.6287241e-05, 3.8209982e-05,\n",
      "       3.9904207e-05, 6.5489650e-05, 8.1317005e-05, 4.7874884e-05,\n",
      "       5.2364227e-05, 4.5203342e-05, 7.9858692e-05, 9.4744617e-05,\n",
      "       4.3256008e-05, 3.9179973e-05, 5.9770333e-05, 4.5570385e-05,\n",
      "       4.5818051e-05, 4.7905203e-05, 5.9598384e-05, 3.4900462e-05,\n",
      "       4.5879846e-05, 6.6107750e-05, 4.8292572e-05, 4.5832683e-05,\n",
      "       3.8679336e-05, 5.0394341e-05, 4.4196495e-05, 5.9648759e-05,\n",
      "       3.8651269e-05, 5.1728406e-05, 4.4003958e-05, 4.9211794e-05,\n",
      "       4.5791519e-05, 3.3119715e-05, 4.4532524e-05, 5.4418375e-05,\n",
      "       4.0462135e-05, 4.8176797e-05, 4.2175223e-05, 4.2950865e-05,\n",
      "       3.7832811e-05, 9.0858783e-05, 3.6315956e-05, 5.4159817e-05,\n",
      "       4.0556326e-05, 5.8419708e-05, 4.5700017e-05, 5.0312174e-05,\n",
      "       3.6356290e-05, 6.6006163e-05, 7.3629315e-05, 4.2711188e-05,\n",
      "       5.5847202e-05, 4.4562850e-05, 4.7258425e-05, 4.2223877e-05,\n",
      "       3.8438586e-05, 5.3148116e-05, 5.7280537e-05, 4.1224164e-05,\n",
      "       7.7893324e-05, 3.7293266e-05, 3.8225462e-05, 5.4529235e-05,\n",
      "       8.0988808e-05, 4.2480864e-05, 1.2650453e-04, 2.8406213e-05,\n",
      "       3.5014564e-05, 5.8219019e-05, 4.3341101e-05, 5.4810953e-05,\n",
      "       4.6200432e-05, 4.8097307e-05, 5.9836977e-05, 4.8948797e-05,\n",
      "       4.8003687e-05, 4.2201587e-05, 4.2216179e-05, 5.3179287e-05,\n",
      "       5.4697859e-05, 4.9307084e-05, 3.6500092e-05, 4.9898143e-05,\n",
      "       5.7266989e-05, 9.6784010e-05, 5.6833436e-05, 6.0487095e-05,\n",
      "       5.6502373e-05, 4.3968066e-05, 4.0056355e-05, 5.7571033e-05,\n",
      "       3.8421524e-05, 4.6895817e-05, 4.0371029e-05, 4.3551714e-05,\n",
      "       5.1798652e-05, 6.0016580e-05, 5.5986638e-05, 6.3567561e-05,\n",
      "       5.2360505e-05, 3.8300339e-05, 4.1732557e-05, 4.2290532e-05,\n",
      "       4.8604361e-05, 4.8135484e-05, 4.8309477e-05, 4.3054897e-05,\n",
      "       4.8418748e-05, 3.9514729e-05, 7.8107194e-05, 8.1578735e-05,\n",
      "       3.9502695e-05, 4.7244706e-05, 5.1172847e-05, 6.4256739e-05,\n",
      "       4.7186972e-05, 4.2394611e-05, 4.7121932e-05, 5.4949414e-05,\n",
      "       4.6178819e-05, 3.7991031e-05, 4.1544950e-05, 4.9696813e-05,\n",
      "       4.6068650e-05, 4.7284339e-05, 4.0302493e-05, 4.9801063e-05,\n",
      "       4.2425308e-05, 3.7407495e-05, 4.7572670e-05, 5.6056837e-05,\n",
      "       6.4317763e-05, 6.2608102e-05, 4.5311746e-05, 5.7381189e-05,\n",
      "       4.9260703e-05, 4.2423540e-05, 4.7521600e-05, 3.4050445e-05,\n",
      "       4.0494138e-05, 3.7982190e-05, 4.8654507e-05, 3.9817562e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer11/conv/Relu6;tower0/network/layer11/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/depthwise;tower0/network/layer11/conv/Conv2D,\n",
      "index: 65,\n",
      "shape: [  1  12   8 256],\n",
      "shape_signature: [  1  12   8 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/depthwise,\n",
      "index: 66,\n",
      "shape: [  1   3   3 256],\n",
      "shape_signature: [  1   3   3 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00829373, 0.00555345, 0.00464716, 0.00543905, 0.00521009,\n",
      "       0.00596755, 0.00513868, 0.00793326, 0.0046381 , 0.00559828,\n",
      "       0.00743706, 0.00539866, 0.00756404, 0.00418665, 0.00802759,\n",
      "       0.0050727 , 0.00632984, 0.0068962 , 0.00650711, 0.00526853,\n",
      "       0.00459872, 0.00366573, 0.00469761, 0.00493723, 0.00627095,\n",
      "       0.00522813, 0.00488747, 0.00586148, 0.00624679, 0.00615938,\n",
      "       0.00437743, 0.00481475, 0.00605046, 0.00515975, 0.00627402,\n",
      "       0.0044371 , 0.00643875, 0.00702919, 0.00542287, 0.00482893,\n",
      "       0.00422972, 0.00686299, 0.00453739, 0.00596223, 0.00555371,\n",
      "       0.00569652, 0.00483809, 0.00421106, 0.00533764, 0.00355438,\n",
      "       0.0055359 , 0.00430936, 0.00701854, 0.00282264, 0.00548405,\n",
      "       0.0054073 , 0.00652597, 0.00548621, 0.00655441, 0.00496266,\n",
      "       0.00372408, 0.00594215, 0.00774473, 0.00457531, 0.0056803 ,\n",
      "       0.00976921, 0.00419866, 0.0057225 , 0.0089091 , 0.00582164,\n",
      "       0.00452481, 0.00579689, 0.00430862, 0.00445693, 0.0056837 ,\n",
      "       0.00498833, 0.00527948, 0.00527532, 0.00669716, 0.00597816,\n",
      "       0.00447755, 0.00544256, 0.0055918 , 0.00517732, 0.00639844,\n",
      "       0.00607829, 0.00589836, 0.00451318, 0.00506971, 0.00633004,\n",
      "       0.0060497 , 0.00397521, 0.00559391, 0.00676169, 0.004686  ,\n",
      "       0.00429119, 0.00641513, 0.00697454, 0.00604602, 0.00413057,\n",
      "       0.0052011 , 0.00589909, 0.00507472, 0.00627286, 0.00668266,\n",
      "       0.00786605, 0.00390708, 0.00536825, 0.00574145, 0.00514864,\n",
      "       0.00433558, 0.00646529, 0.00508567, 0.00603065, 0.00547065,\n",
      "       0.00337373, 0.00703979, 0.00702982, 0.00497256, 0.00446579,\n",
      "       0.0051906 , 0.00637353, 0.00639437, 0.00575317, 0.0054901 ,\n",
      "       0.00371904, 0.00822434, 0.00485819, 0.00569865, 0.00533429,\n",
      "       0.00337416, 0.00450899, 0.0039555 , 0.00514553, 0.00651367,\n",
      "       0.00367018, 0.0044817 , 0.00661225, 0.00612926, 0.00666619,\n",
      "       0.00758305, 0.00541662, 0.00449171, 0.00397655, 0.00472111,\n",
      "       0.0038402 , 0.00462046, 0.00572657, 0.0044874 , 0.0094816 ,\n",
      "       0.0038489 , 0.00583797, 0.00519871, 0.00624994, 0.0043792 ,\n",
      "       0.00461623, 0.00564309, 0.00264466, 0.00510875, 0.00503576,\n",
      "       0.00436934, 0.00503318, 0.00572058, 0.00531431, 0.00583401,\n",
      "       0.00368683, 0.00367741, 0.00460137, 0.00510333, 0.00529551,\n",
      "       0.0064115 , 0.00541406, 0.00483115, 0.00631944, 0.00877587,\n",
      "       0.00709477, 0.00452754, 0.00399957, 0.00595514, 0.00596099,\n",
      "       0.00501807, 0.00446155, 0.00502671, 0.00599586, 0.00481023,\n",
      "       0.00458856, 0.00453187, 0.00433898, 0.00706218, 0.00622044,\n",
      "       0.00660492, 0.00358876, 0.00313546, 0.00514006, 0.00897525,\n",
      "       0.00476111, 0.00484737, 0.0046856 , 0.00368062, 0.00589417,\n",
      "       0.00389876, 0.00622857, 0.00586404, 0.00345635, 0.00571078,\n",
      "       0.00646971, 0.0056752 , 0.00679051, 0.00540333, 0.00525811,\n",
      "       0.00646482, 0.00416566, 0.00471495, 0.00581226, 0.00533829,\n",
      "       0.00562014, 0.00561366, 0.00327297, 0.00796998, 0.00490581,\n",
      "       0.00614976, 0.00577295, 0.00585155, 0.00471856, 0.00607547,\n",
      "       0.00580942, 0.0046597 , 0.00699719, 0.00591291, 0.00528704,\n",
      "       0.00753786, 0.00647763, 0.0054726 , 0.00589379, 0.004955  ,\n",
      "       0.00702962, 0.0059871 , 0.00549744, 0.00527199, 0.00534579,\n",
      "       0.0049041 , 0.00426734, 0.00537434, 0.00714365, 0.00551876,\n",
      "       0.00356304, 0.00487344, 0.00794704, 0.00456512, 0.00404531,\n",
      "       0.00558815, 0.00597816, 0.00571757, 0.00442538, 0.0069507 ,\n",
      "       0.00331411], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 67,\n",
      "shape: [256],\n",
      "shape_signature: [256],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.95146509e-04, 1.30669432e-04, 1.09344874e-04, 1.27977735e-04,\n",
      "       1.22590398e-04, 1.40412871e-04, 1.20910096e-04, 1.86664838e-04,\n",
      "       1.09131681e-04, 1.31724228e-04, 1.74989560e-04, 1.27027335e-04,\n",
      "       1.77977461e-04, 9.85092993e-05, 1.88884558e-04, 1.19357654e-04,\n",
      "       1.48937368e-04, 1.62263503e-04, 1.53108354e-04, 1.23965307e-04,\n",
      "       1.08205182e-04, 8.62525703e-05, 1.10532019e-04, 1.16170158e-04,\n",
      "       1.47551764e-04, 1.23014877e-04, 1.14999253e-04, 1.37917246e-04,\n",
      "       1.46983410e-04, 1.44926642e-04, 1.02998354e-04, 1.13288224e-04,\n",
      "       1.42363671e-04, 1.21405843e-04, 1.47623912e-04, 1.04402294e-04,\n",
      "       1.51500048e-04, 1.65392819e-04, 1.27597028e-04, 1.13621929e-04,\n",
      "       9.95227456e-05, 1.61482152e-04, 1.06762098e-04, 1.40287710e-04,\n",
      "       1.30675427e-04, 1.34035843e-04, 1.13837312e-04, 9.90838744e-05,\n",
      "       1.25591643e-04, 8.36323889e-05, 1.30256536e-04, 1.01396683e-04,\n",
      "       1.65142075e-04, 6.64149993e-05, 1.29036416e-04, 1.27230611e-04,\n",
      "       1.53552246e-04, 1.29087231e-04, 1.54221329e-04, 1.16768577e-04,\n",
      "       8.76254489e-05, 1.39815282e-04, 1.82229007e-04, 1.07654341e-04,\n",
      "       1.33654059e-04, 2.29863843e-04, 9.87919193e-05, 1.34647096e-04,\n",
      "       2.09625810e-04, 1.36979681e-04, 1.06466170e-04, 1.36397532e-04,\n",
      "       1.01379315e-04, 1.04869025e-04, 1.33734196e-04, 1.17372583e-04,\n",
      "       1.24223065e-04, 1.24125276e-04, 1.57580318e-04, 1.40662538e-04,\n",
      "       1.05354171e-04, 1.28060259e-04, 1.31571825e-04, 1.21819387e-04,\n",
      "       1.50551452e-04, 1.43018711e-04, 1.38784962e-04, 1.06192412e-04,\n",
      "       1.19287390e-04, 1.48942141e-04, 1.42345918e-04, 9.35343487e-05,\n",
      "       1.31621389e-04, 1.59098490e-04, 1.10258748e-04, 1.00969221e-04,\n",
      "       1.50944223e-04, 1.64106910e-04, 1.42259290e-04, 9.71898262e-05,\n",
      "       1.22378842e-04, 1.38802163e-04, 1.19405086e-04, 1.47596787e-04,\n",
      "       1.57239032e-04, 1.85083598e-04, 9.19313461e-05, 1.26311788e-04,\n",
      "       1.35092938e-04, 1.21144469e-04, 1.02013655e-04, 1.52124587e-04,\n",
      "       1.19662756e-04, 1.41897719e-04, 1.28721091e-04, 7.93819636e-05,\n",
      "       1.65642050e-04, 1.65407604e-04, 1.17001488e-04, 1.05077510e-04,\n",
      "       1.22131794e-04, 1.49965519e-04, 1.50455773e-04, 1.35368784e-04,\n",
      "       1.29178909e-04, 8.75067781e-05, 1.93513872e-04, 1.14310242e-04,\n",
      "       1.34085858e-04, 1.25512728e-04, 7.93919535e-05, 1.06093925e-04,\n",
      "       9.30706810e-05, 1.21071309e-04, 1.53262925e-04, 8.63572641e-05,\n",
      "       1.05451749e-04, 1.55582253e-04, 1.44217935e-04, 1.56851485e-04,\n",
      "       1.78424671e-04, 1.27449966e-04, 1.05687330e-04, 9.35658609e-05,\n",
      "       1.11084919e-04, 9.03576583e-05, 1.08716740e-04, 1.34742775e-04,\n",
      "       1.05585961e-04, 2.23096504e-04, 9.05624474e-05, 1.37364099e-04,\n",
      "       1.22322599e-04, 1.47057377e-04, 1.03039907e-04, 1.08617205e-04,\n",
      "       1.32778587e-04, 6.22271982e-05, 1.20205848e-04, 1.18488468e-04,\n",
      "       1.02807964e-04, 1.18427750e-04, 1.34601956e-04, 1.25042527e-04,\n",
      "       1.37270734e-04, 8.67488488e-05, 8.65273323e-05, 1.08267501e-04,\n",
      "       1.20078468e-04, 1.24600308e-04, 1.50858861e-04, 1.27389707e-04,\n",
      "       1.13674090e-04, 1.48692736e-04, 2.06491051e-04, 1.66935875e-04,\n",
      "       1.06530351e-04, 9.41075705e-05, 1.40120916e-04, 1.40258635e-04,\n",
      "       1.18072312e-04, 1.04977727e-04, 1.18275413e-04, 1.41078985e-04,\n",
      "       1.13181828e-04, 1.07966116e-04, 1.06632222e-04, 1.02093720e-04,\n",
      "       1.66169018e-04, 1.46363309e-04, 1.55409842e-04, 8.44414317e-05,\n",
      "       7.37754162e-05, 1.20942481e-04, 2.11182371e-04, 1.12026130e-04,\n",
      "       1.14055816e-04, 1.10249486e-04, 8.66027549e-05, 1.38686461e-04,\n",
      "       9.17356156e-05, 1.46554565e-04, 1.37977418e-04, 8.13259976e-05,\n",
      "       1.34371221e-04, 1.52228575e-04, 1.33534209e-04, 1.59776740e-04,\n",
      "       1.27137144e-04, 1.23720180e-04, 1.52113425e-04, 9.80156474e-05,\n",
      "       1.10939916e-04, 1.36759118e-04, 1.25606821e-04, 1.32238652e-04,\n",
      "       1.32086148e-04, 7.70110200e-05, 1.87528887e-04, 1.15430776e-04,\n",
      "       1.44700243e-04, 1.35834154e-04, 1.37683484e-04, 1.11024841e-04,\n",
      "       1.42952325e-04, 1.36692150e-04, 1.09640016e-04, 1.64639714e-04,\n",
      "       1.39127340e-04, 1.24401035e-04, 1.77361333e-04, 1.52414839e-04,\n",
      "       1.28767046e-04, 1.38677438e-04, 1.16588257e-04, 1.65402860e-04,\n",
      "       1.40872973e-04, 1.29351582e-04, 1.24046870e-04, 1.25783263e-04,\n",
      "       1.15390707e-04, 1.00408004e-04, 1.26455139e-04, 1.68085840e-04,\n",
      "       1.29853288e-04, 8.38363267e-05, 1.14669136e-04, 1.86989200e-04,\n",
      "       1.07414664e-04, 9.51838447e-05, 1.31485795e-04, 1.40662654e-04,\n",
      "       1.34531088e-04, 1.04126651e-04, 1.63545978e-04, 7.79789989e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer12/sepconv/Relu6;tower0/network/layer12/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer12/sepconv/depthwise,\n",
      "index: 68,\n",
      "shape: [  1   6   4 256],\n",
      "shape_signature: [  1   6   4 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer13/conv/Conv2D,\n",
      "index: 69,\n",
      "shape: [512   1   1 256],\n",
      "shape_signature: [512   1   1 256],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00138912, 0.00198287, 0.00325416, 0.00195453, 0.00173961,\n",
      "       0.00269824, 0.0015704 , 0.00191986, 0.00297565, 0.00160782,\n",
      "       0.00141923, 0.00188792, 0.00208733, 0.00157716, 0.00193201,\n",
      "       0.00169087, 0.00201288, 0.00180754, 0.0017721 , 0.00201221,\n",
      "       0.00230961, 0.00245271, 0.0042643 , 0.00167226, 0.00190656,\n",
      "       0.00238298, 0.00178224, 0.00237706, 0.00215735, 0.00269632,\n",
      "       0.00171736, 0.00186991, 0.00161796, 0.00182023, 0.00191145,\n",
      "       0.00156218, 0.00203172, 0.00197638, 0.00138242, 0.00180677,\n",
      "       0.00174914, 0.00204916, 0.00191864, 0.00188375, 0.00149697,\n",
      "       0.0016815 , 0.0017323 , 0.0016126 , 0.00254012, 0.00227905,\n",
      "       0.00196832, 0.00196023, 0.00169386, 0.00280769, 0.00149415,\n",
      "       0.00188774, 0.00205771, 0.00216945, 0.00196909, 0.0012534 ,\n",
      "       0.00166218, 0.00202437, 0.00290174, 0.00379286, 0.00173882,\n",
      "       0.00177866, 0.00207677, 0.00195223, 0.0015718 , 0.00190505,\n",
      "       0.0016266 , 0.00225388, 0.00137997, 0.00153173, 0.00208291,\n",
      "       0.00211351, 0.00265081, 0.00166866, 0.0021594 , 0.00151522,\n",
      "       0.0023803 , 0.00146799, 0.00262182, 0.00218123, 0.00181805,\n",
      "       0.00215615, 0.00187492, 0.00202534, 0.00205039, 0.00154027,\n",
      "       0.00127376, 0.00187623, 0.00150767, 0.00174654, 0.00184131,\n",
      "       0.00474488, 0.00185387, 0.00155041, 0.00186514, 0.00217749,\n",
      "       0.00260876, 0.00185148, 0.00189576, 0.00149147, 0.00149912,\n",
      "       0.00181858, 0.00203191, 0.001998  , 0.00244029, 0.00240516,\n",
      "       0.00149659, 0.00193537, 0.00223684, 0.00137133, 0.00153461,\n",
      "       0.00144893, 0.00223003, 0.00210334, 0.00188873, 0.00281043,\n",
      "       0.00217118, 0.00146601, 0.0016715 , 0.00197636, 0.0020168 ,\n",
      "       0.0027912 , 0.00182563, 0.00141782, 0.00130866, 0.00266341,\n",
      "       0.00356782, 0.0021772 , 0.00179152, 0.00211963, 0.00248985,\n",
      "       0.00174903, 0.00175928, 0.0015568 , 0.00267739, 0.00208949,\n",
      "       0.00182156, 0.00222871, 0.00260544, 0.00151876, 0.00220914,\n",
      "       0.00202964, 0.0019218 , 0.00198889, 0.0015248 , 0.0019013 ,\n",
      "       0.00327613, 0.00110903, 0.00207289, 0.00191356, 0.00163807,\n",
      "       0.00233684, 0.00171384, 0.00200176, 0.00182494, 0.00207888,\n",
      "       0.00156262, 0.00147512, 0.00145928, 0.00162519, 0.001755  ,\n",
      "       0.00215254, 0.00260304, 0.00184281, 0.00171557, 0.00149657,\n",
      "       0.00151738, 0.00193782, 0.00240223, 0.00185069, 0.00157601,\n",
      "       0.00164523, 0.00191606, 0.00198551, 0.00174918, 0.0016027 ,\n",
      "       0.00214954, 0.00216671, 0.00156573, 0.00240215, 0.00175668,\n",
      "       0.00220874, 0.00208542, 0.00233053, 0.00210795, 0.00181916,\n",
      "       0.00460008, 0.00218035, 0.00200605, 0.00211858, 0.00210798,\n",
      "       0.00177782, 0.00153814, 0.00312018, 0.00184716, 0.00228308,\n",
      "       0.00150713, 0.00140158, 0.00225658, 0.0024273 , 0.00242352,\n",
      "       0.00260998, 0.00195107, 0.00176142, 0.00210977, 0.00205349,\n",
      "       0.00178506, 0.00117062, 0.00159391, 0.0021482 , 0.00174974,\n",
      "       0.00186063, 0.00217514, 0.00149924, 0.00176796, 0.00193905,\n",
      "       0.00172301, 0.00150141, 0.00207671, 0.00177673, 0.00158613,\n",
      "       0.00164097, 0.00188505, 0.00181665, 0.00194739, 0.00193178,\n",
      "       0.00181929, 0.00156557, 0.00136937, 0.00178349, 0.00234453,\n",
      "       0.00395219, 0.00218645, 0.00169727, 0.00235982, 0.00200134,\n",
      "       0.00180469, 0.00212614, 0.0021538 , 0.00189535, 0.00202978,\n",
      "       0.0019584 , 0.00143986, 0.00259027, 0.00224549, 0.0019051 ,\n",
      "       0.00149549, 0.00199559, 0.00147632, 0.00179779, 0.0020742 ,\n",
      "       0.00224652, 0.00177478, 0.00138903, 0.00153092, 0.00151992,\n",
      "       0.00190463, 0.00166671, 0.00178428, 0.00153828, 0.00272307,\n",
      "       0.00268166, 0.0014964 , 0.00150686, 0.00246983, 0.00159358,\n",
      "       0.00236017, 0.00156359, 0.00195891, 0.00169726, 0.00210051,\n",
      "       0.00147161, 0.00313503, 0.00200282, 0.0016087 , 0.00169863,\n",
      "       0.00237902, 0.00246162, 0.00145617, 0.0014475 , 0.00160588,\n",
      "       0.00164977, 0.00183581, 0.00228934, 0.0014536 , 0.00192248,\n",
      "       0.00188813, 0.0022053 , 0.00175592, 0.00188103, 0.0011285 ,\n",
      "       0.00119666, 0.00205452, 0.00166541, 0.0019235 , 0.00246416,\n",
      "       0.0015045 , 0.00204169, 0.00155203, 0.00205438, 0.00271156,\n",
      "       0.0019795 , 0.00156916, 0.00203569, 0.00182633, 0.00149586,\n",
      "       0.00225006, 0.00276754, 0.00159363, 0.00243101, 0.00195473,\n",
      "       0.00187581, 0.00232006, 0.00120591, 0.00174166, 0.001666  ,\n",
      "       0.00157981, 0.003211  , 0.00157478, 0.00137834, 0.00195196,\n",
      "       0.00245967, 0.00162137, 0.00191607, 0.00200194, 0.0017138 ,\n",
      "       0.00167564, 0.00131726, 0.00125822, 0.00189946, 0.0020981 ,\n",
      "       0.00115096, 0.00188759, 0.00314799, 0.00160286, 0.00150487,\n",
      "       0.00187187, 0.00153182, 0.00215456, 0.00160236, 0.00205564,\n",
      "       0.0012055 , 0.0018754 , 0.00215747, 0.0050029 , 0.00130974,\n",
      "       0.00148302, 0.00216463, 0.0020242 , 0.00218498, 0.00194129,\n",
      "       0.00182042, 0.0027187 , 0.00182762, 0.00167359, 0.00182248,\n",
      "       0.00154972, 0.00171251, 0.00193537, 0.00194659, 0.00194112,\n",
      "       0.00200704, 0.00115536, 0.00155781, 0.00192683, 0.00202911,\n",
      "       0.00158151, 0.0015431 , 0.00320015, 0.00190233, 0.00205392,\n",
      "       0.00223837, 0.00155553, 0.00146976, 0.00463094, 0.00182055,\n",
      "       0.0018426 , 0.00141631, 0.00305144, 0.00155438, 0.00234291,\n",
      "       0.00209806, 0.00303584, 0.0016015 , 0.00236817, 0.00181442,\n",
      "       0.00181693, 0.00275465, 0.00129312, 0.00226283, 0.00133915,\n",
      "       0.00341945, 0.00217275, 0.00201737, 0.00206867, 0.00198346,\n",
      "       0.00152262, 0.00133573, 0.00137284, 0.00178206, 0.00234158,\n",
      "       0.00198298, 0.00136561, 0.00186337, 0.00155146, 0.001517  ,\n",
      "       0.00159148, 0.00164868, 0.00170205, 0.00227869, 0.00200056,\n",
      "       0.00232517, 0.00182141, 0.00176102, 0.00196921, 0.00120713,\n",
      "       0.00188518, 0.00149477, 0.00222315, 0.00156489, 0.00148613,\n",
      "       0.00262197, 0.00242868, 0.00169719, 0.00204597, 0.00199854,\n",
      "       0.00141913, 0.00188672, 0.00159824, 0.00202382, 0.00136006,\n",
      "       0.00210994, 0.00168918, 0.00213034, 0.00193639, 0.00127408,\n",
      "       0.00177233, 0.00163376, 0.00190324, 0.00166   , 0.00211911,\n",
      "       0.0016096 , 0.00234184, 0.0027745 , 0.00230703, 0.00297873,\n",
      "       0.00333262, 0.00163714, 0.0019352 , 0.00196019, 0.00197265,\n",
      "       0.00244008, 0.00193778, 0.00124399, 0.00220723, 0.00141376,\n",
      "       0.00254997, 0.00254401, 0.0015958 , 0.00213683, 0.0015506 ,\n",
      "       0.00191237, 0.00203198, 0.00178314, 0.00131256, 0.00151844,\n",
      "       0.00214743, 0.00150423, 0.001511  , 0.0013446 , 0.00246485,\n",
      "       0.00158024, 0.00209306, 0.00261484, 0.00180202, 0.00170362,\n",
      "       0.00199796, 0.00155001, 0.00186475, 0.00125594, 0.00179474,\n",
      "       0.00224005, 0.00170998, 0.00174291, 0.00336047, 0.00195772,\n",
      "       0.00167278, 0.00208996, 0.00181152, 0.00193947, 0.00130076,\n",
      "       0.00172117, 0.00146307, 0.00256695, 0.00160327, 0.00168013,\n",
      "       0.00242782, 0.00148005, 0.00236824, 0.00176058, 0.00292591,\n",
      "       0.00174593, 0.00132512, 0.00151237, 0.00214301, 0.00107635,\n",
      "       0.00142752, 0.00211009], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer13/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 70,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([3.2685090e-05, 4.6655834e-05, 7.6568409e-05, 4.5988862e-05,\n",
      "       4.0932002e-05, 6.3488085e-05, 3.6950674e-05, 4.5173212e-05,\n",
      "       7.0015318e-05, 3.7831040e-05, 3.3393575e-05, 4.4421598e-05,\n",
      "       4.9113554e-05, 3.7109665e-05, 4.5458954e-05, 3.9785144e-05,\n",
      "       4.7361940e-05, 4.2530341e-05, 4.1696479e-05, 4.7346097e-05,\n",
      "       5.4343702e-05, 5.7710731e-05, 1.0033638e-04, 3.9347218e-05,\n",
      "       4.4860313e-05, 5.6070046e-05, 4.1935160e-05, 5.5930814e-05,\n",
      "       5.0761126e-05, 6.3442800e-05, 4.0408562e-05, 4.3997807e-05,\n",
      "       3.8069746e-05, 4.2829051e-05, 4.4975350e-05, 3.6757105e-05,\n",
      "       4.7805210e-05, 4.6503101e-05, 3.2527547e-05, 4.2512347e-05,\n",
      "       4.1156316e-05, 4.8215486e-05, 4.5144585e-05, 4.4323580e-05,\n",
      "       3.5222805e-05, 3.9564598e-05, 4.0760064e-05, 3.7943428e-05,\n",
      "       5.9767473e-05, 5.3624721e-05, 4.6313471e-05, 4.6122961e-05,\n",
      "       3.9855546e-05, 6.6063214e-05, 3.5156569e-05, 4.4417298e-05,\n",
      "       4.8416710e-05, 5.1045830e-05, 4.6331574e-05, 2.9491710e-05,\n",
      "       3.9110058e-05, 4.7632286e-05, 6.8276284e-05, 8.9243826e-05,\n",
      "       4.0913452e-05, 4.1850915e-05, 4.8865229e-05, 4.5934710e-05,\n",
      "       3.6983543e-05, 4.4824643e-05, 3.8273036e-05, 5.3032411e-05,\n",
      "       3.2469870e-05, 3.6040808e-05, 4.9009563e-05, 4.9729537e-05,\n",
      "       6.2371990e-05, 3.9262475e-05, 5.0809365e-05, 3.5652298e-05,\n",
      "       5.6006986e-05, 3.4540910e-05, 6.1689992e-05, 5.1323041e-05,\n",
      "       4.2777596e-05, 5.0733015e-05, 4.4115695e-05, 4.7655005e-05,\n",
      "       4.8244488e-05, 3.6241730e-05, 2.9970764e-05, 4.4146607e-05,\n",
      "       3.5474506e-05, 4.1095074e-05, 4.3324882e-05, 1.1164424e-04,\n",
      "       4.3620530e-05, 3.6480345e-05, 4.3885557e-05, 5.1235053e-05,\n",
      "       6.1382700e-05, 4.3564138e-05, 4.4606091e-05, 3.5093417e-05,\n",
      "       3.5273348e-05, 4.2790154e-05, 4.7809597e-05, 4.7011777e-05,\n",
      "       5.7418642e-05, 5.6592085e-05, 3.5213805e-05, 4.5538181e-05,\n",
      "       5.2631538e-05, 3.2266653e-05, 3.6108508e-05, 3.4092423e-05,\n",
      "       5.2471198e-05, 4.9490318e-05, 4.4440749e-05, 6.6127650e-05,\n",
      "       5.1086496e-05, 3.4494289e-05, 3.9329399e-05, 4.6502482e-05,\n",
      "       4.7454145e-05, 6.5675194e-05, 4.2955970e-05, 3.3360480e-05,\n",
      "       3.0791998e-05, 6.2668427e-05, 8.3948769e-05, 5.1228315e-05,\n",
      "       4.2153340e-05, 4.9873601e-05, 5.8584646e-05, 4.1153577e-05,\n",
      "       4.1394924e-05, 3.6630536e-05, 6.2997482e-05, 4.9164581e-05,\n",
      "       4.2860273e-05, 5.2440239e-05, 6.1304483e-05, 3.5735637e-05,\n",
      "       5.1979761e-05, 4.7756206e-05, 4.5218818e-05, 4.6797362e-05,\n",
      "       3.5877671e-05, 4.4736375e-05, 7.7085431e-05, 2.6094942e-05,\n",
      "       4.8773978e-05, 4.5024939e-05, 3.8542858e-05, 5.4984517e-05,\n",
      "       4.0325693e-05, 4.7100129e-05, 4.2939788e-05, 4.8914717e-05,\n",
      "       3.6767426e-05, 3.4708708e-05, 3.4335953e-05, 3.8239657e-05,\n",
      "       4.1294130e-05, 5.0648017e-05, 6.1248043e-05, 4.3360316e-05,\n",
      "       4.0366267e-05, 3.5213412e-05, 3.5703019e-05, 4.5595858e-05,\n",
      "       5.6522942e-05, 4.3545660e-05, 3.7082526e-05, 3.8711361e-05,\n",
      "       4.5083765e-05, 4.6717876e-05, 4.1157244e-05, 3.7710630e-05,\n",
      "       5.0577477e-05, 5.0981427e-05, 3.6840600e-05, 5.6521087e-05,\n",
      "       4.1333682e-05, 5.1970288e-05, 4.9068603e-05, 5.4835884e-05,\n",
      "       4.9598861e-05, 4.2803804e-05, 1.0823716e-04, 5.1302410e-05,\n",
      "       4.7201214e-05, 4.9848939e-05, 4.9599617e-05, 4.1831019e-05,\n",
      "       3.6191439e-05, 7.3415998e-05, 4.3462634e-05, 5.3719607e-05,\n",
      "       3.5461999e-05, 3.2978329e-05, 5.3095911e-05, 5.7112891e-05,\n",
      "       5.7024110e-05, 6.1411301e-05, 4.5907567e-05, 4.1445128e-05,\n",
      "       4.9641541e-05, 4.8317503e-05, 4.2001517e-05, 2.7544085e-05,\n",
      "       3.7503753e-05, 5.0545776e-05, 4.1170271e-05, 4.3779582e-05,\n",
      "       5.1179777e-05, 3.5276345e-05, 4.1599094e-05, 4.5624747e-05,\n",
      "       4.0541505e-05, 3.5327303e-05, 4.8863865e-05, 4.1805528e-05,\n",
      "       3.7320642e-05, 3.8610968e-05, 4.4354205e-05, 4.2744767e-05,\n",
      "       4.5820863e-05, 4.5453682e-05, 4.2806809e-05, 3.6836875e-05,\n",
      "       3.2220552e-05, 4.1964508e-05, 5.5165361e-05, 9.2992661e-05,\n",
      "       5.1445793e-05, 3.9935807e-05, 5.5525263e-05, 4.7090372e-05,\n",
      "       4.2463318e-05, 5.0026800e-05, 5.0677601e-05, 4.4596403e-05,\n",
      "       4.7759506e-05, 4.6079997e-05, 3.3879034e-05, 6.0947619e-05,\n",
      "       5.2835094e-05, 4.4825916e-05, 3.5187892e-05, 4.6955029e-05,\n",
      "       3.4737059e-05, 4.2300911e-05, 4.8804770e-05, 5.2859214e-05,\n",
      "       4.1759529e-05, 3.2683049e-05, 3.6021756e-05, 3.5762896e-05,\n",
      "       4.4814908e-05, 3.9216739e-05, 4.1983130e-05, 3.6194822e-05,\n",
      "       6.4072323e-05, 6.3097948e-05, 3.5209407e-05, 3.5455461e-05,\n",
      "       5.8113681e-05, 3.7496113e-05, 5.5533528e-05, 3.6790236e-05,\n",
      "       4.6092006e-05, 3.9935621e-05, 4.9423837e-05, 3.4626206e-05,\n",
      "       7.3765470e-05, 4.7125286e-05, 3.7851671e-05, 3.9967774e-05,\n",
      "       5.5976943e-05, 5.7920402e-05, 3.4262863e-05, 3.4058856e-05,\n",
      "       3.7785296e-05, 3.8818231e-05, 4.3195538e-05, 5.3866919e-05,\n",
      "       3.4202418e-05, 4.5234723e-05, 4.4426532e-05, 5.1889347e-05,\n",
      "       4.1315870e-05, 4.4259617e-05, 2.6552862e-05, 2.8156610e-05,\n",
      "       4.8341553e-05, 3.9186099e-05, 4.5258766e-05, 5.7980196e-05,\n",
      "       3.5400073e-05, 4.8039714e-05, 3.6518410e-05, 4.8338356e-05,\n",
      "       6.3801490e-05, 4.6576428e-05, 3.6921338e-05, 4.7898513e-05,\n",
      "       4.2972526e-05, 3.5196663e-05, 5.2942480e-05, 6.5118489e-05,\n",
      "       3.7497084e-05, 5.7200283e-05, 4.5993645e-05, 4.4136734e-05,\n",
      "       5.4589611e-05, 2.8374305e-05, 4.0980161e-05, 3.9200058e-05,\n",
      "       3.7171951e-05, 7.5552933e-05, 3.7053676e-05, 3.2431497e-05,\n",
      "       4.5928547e-05, 5.7874502e-05, 3.8149938e-05, 4.5084067e-05,\n",
      "       4.7104419e-05, 4.0324634e-05, 3.9426744e-05, 3.0994244e-05,\n",
      "       2.9605088e-05, 4.4693137e-05, 4.9367169e-05, 2.7081365e-05,\n",
      "       4.4413860e-05, 7.4070245e-05, 3.7714424e-05, 3.5408793e-05,\n",
      "       4.4044104e-05, 3.6042871e-05, 5.0695631e-05, 3.7702619e-05,\n",
      "       4.8367954e-05, 2.8364637e-05, 4.4127097e-05, 5.0763920e-05,\n",
      "       1.1771522e-04, 3.0817493e-05, 3.4894649e-05, 5.0932445e-05,\n",
      "       4.7628160e-05, 5.1411374e-05, 4.5677323e-05, 4.2833395e-05,\n",
      "       6.3969303e-05, 4.3002852e-05, 3.9378599e-05, 4.2881984e-05,\n",
      "       3.6463949e-05, 4.0294362e-05, 4.5538080e-05, 4.5802200e-05,\n",
      "       4.5673416e-05, 4.7224530e-05, 2.7184964e-05, 3.6654448e-05,\n",
      "       4.5337136e-05, 4.7743775e-05, 3.7212045e-05, 3.6308240e-05,\n",
      "       7.5297721e-05, 4.4760702e-05, 4.8327558e-05, 5.2667598e-05,\n",
      "       3.6600752e-05, 3.4582576e-05, 1.0896330e-04, 4.2836484e-05,\n",
      "       4.3355380e-05, 3.3324952e-05, 7.1798597e-05, 3.6573747e-05,\n",
      "       5.5127268e-05, 4.9366074e-05, 7.1431561e-05, 3.7682468e-05,\n",
      "       5.5721761e-05, 4.2692169e-05, 4.2751242e-05, 6.4815329e-05,\n",
      "       3.0426432e-05, 5.3243046e-05, 3.1509415e-05, 8.0457721e-05,\n",
      "       5.1123490e-05, 4.7467569e-05, 4.8674585e-05, 4.6669604e-05,\n",
      "       3.5826444e-05, 3.1429030e-05, 3.2302134e-05, 4.1930802e-05,\n",
      "       5.5095894e-05, 4.6658297e-05, 3.2132059e-05, 4.3843902e-05,\n",
      "       3.6504945e-05, 3.5694131e-05, 3.7446549e-05, 3.8792499e-05,\n",
      "       4.0048199e-05, 5.3616335e-05, 4.7071997e-05, 5.4709766e-05,\n",
      "       4.2856704e-05, 4.1435858e-05, 4.6334248e-05, 2.8403128e-05,\n",
      "       4.4357257e-05, 3.5171106e-05, 5.2309300e-05, 3.6820980e-05,\n",
      "       3.4967772e-05, 6.1693507e-05, 5.7145320e-05, 3.9933977e-05,\n",
      "       4.8140406e-05, 4.7024445e-05, 3.3391396e-05, 4.4393426e-05,\n",
      "       3.7605700e-05, 4.7619214e-05, 3.2001339e-05, 4.9645609e-05,\n",
      "       3.9745486e-05, 5.0125600e-05, 4.5562196e-05, 2.9978424e-05,\n",
      "       4.1701849e-05, 3.8441347e-05, 4.4782209e-05, 3.9058890e-05,\n",
      "       4.9861523e-05, 3.7872986e-05, 5.5102064e-05, 6.5282329e-05,\n",
      "       5.4283100e-05, 7.0087815e-05, 7.8414654e-05, 3.8520855e-05,\n",
      "       4.5534234e-05, 4.6122062e-05, 4.6415375e-05, 5.7413610e-05,\n",
      "       4.5594836e-05, 2.9270381e-05, 5.1934803e-05, 3.3264965e-05,\n",
      "       5.9999304e-05, 5.9859085e-05, 3.7548140e-05, 5.0278326e-05,\n",
      "       3.6484704e-05, 4.4996857e-05, 4.7811358e-05, 4.1956169e-05,\n",
      "       3.0883846e-05, 3.5727924e-05, 5.0527764e-05, 3.5393579e-05,\n",
      "       3.5552832e-05, 3.1637624e-05, 5.7996585e-05, 3.7182221e-05,\n",
      "       4.9248378e-05, 6.1525549e-05, 4.2400421e-05, 4.0085295e-05,\n",
      "       4.7010941e-05, 3.6470916e-05, 4.3876502e-05, 2.9551640e-05,\n",
      "       4.2229123e-05, 5.2707157e-05, 4.0234907e-05, 4.1009644e-05,\n",
      "       7.9069854e-05, 4.6063924e-05, 3.9359562e-05, 4.9175564e-05,\n",
      "       4.2623913e-05, 4.5634610e-05, 3.0606087e-05, 4.0498100e-05,\n",
      "       3.4425164e-05, 6.0398714e-05, 3.7723938e-05, 3.9532424e-05,\n",
      "       5.7125199e-05, 3.4824741e-05, 5.5723325e-05, 4.1425512e-05,\n",
      "       6.8844936e-05, 4.1080664e-05, 3.1179370e-05, 3.5585283e-05,\n",
      "       5.0423874e-05, 2.5325931e-05, 3.3588814e-05, 4.9649076e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer13/conv/Relu6;tower0/network/layer13/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer13/conv/Conv2D,\n",
      "index: 71,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer14/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer14/sepconv/depthwise;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 72,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00977448, 0.0075521 , 0.00483956, 0.00765605, 0.00863635,\n",
      "       0.00877628, 0.00828465, 0.01135984, 0.00762801, 0.01333912,\n",
      "       0.00486963, 0.0093798 , 0.00725084, 0.01071701, 0.00828266,\n",
      "       0.00663811, 0.00593078, 0.00857817, 0.01056118, 0.01134093,\n",
      "       0.00645104, 0.00902583, 0.00740258, 0.00716733, 0.00729215,\n",
      "       0.01329091, 0.00769312, 0.0095289 , 0.00844338, 0.01108455,\n",
      "       0.00470513, 0.01004825, 0.01376696, 0.01070686, 0.00702758,\n",
      "       0.01144071, 0.008694  , 0.00744457, 0.01079838, 0.00386896,\n",
      "       0.01156539, 0.00768842, 0.01005036, 0.00846377, 0.01046266,\n",
      "       0.0085321 , 0.01000594, 0.01090908, 0.01299393, 0.00945239,\n",
      "       0.00818486, 0.00451354, 0.00945218, 0.00923504, 0.00796618,\n",
      "       0.01119896, 0.00506238, 0.00797073, 0.01367309, 0.00991396,\n",
      "       0.00841688, 0.0092602 , 0.00895678, 0.00907421, 0.00904437,\n",
      "       0.00969544, 0.00690175, 0.01179482, 0.01033403, 0.00941709,\n",
      "       0.00788712, 0.0057318 , 0.0066139 , 0.00843609, 0.00996001,\n",
      "       0.00624332, 0.01052498, 0.00953395, 0.01243655, 0.00848482,\n",
      "       0.01124458, 0.01007105, 0.00849766, 0.01042773, 0.00860983,\n",
      "       0.00739592, 0.00648165, 0.0107819 , 0.01144492, 0.00926544,\n",
      "       0.00548764, 0.00984224, 0.00315475, 0.00699554, 0.00802712,\n",
      "       0.00843638, 0.01060141, 0.01230778, 0.00830936, 0.01125495,\n",
      "       0.01031373, 0.0110035 , 0.00600041, 0.01082764, 0.01133179,\n",
      "       0.0083525 , 0.00551665, 0.00906487, 0.00785497, 0.01500749,\n",
      "       0.01031543, 0.00471166, 0.00852573, 0.01040434, 0.00405667,\n",
      "       0.01046147, 0.00476072, 0.00891181, 0.00384258, 0.01054959,\n",
      "       0.00982333, 0.00962054, 0.00769585, 0.00758736, 0.00959856,\n",
      "       0.00571643, 0.00900336, 0.01156809, 0.00659938, 0.0097331 ,\n",
      "       0.00859186, 0.00413268, 0.00604691, 0.00728851, 0.01108033,\n",
      "       0.00899413, 0.00973928, 0.00770122, 0.01140548, 0.00939725,\n",
      "       0.00734958, 0.00915297, 0.01213307, 0.00868201, 0.01026781,\n",
      "       0.01153683, 0.00879352, 0.00980223, 0.01211886, 0.00787418,\n",
      "       0.00869504, 0.01240126, 0.01058815, 0.0078996 , 0.00677847,\n",
      "       0.00460163, 0.01181356, 0.01017742, 0.0081783 , 0.00796567,\n",
      "       0.01124149, 0.0104044 , 0.01077399, 0.00790539, 0.00830827,\n",
      "       0.00801657, 0.01028965, 0.00704705, 0.00774024, 0.00703985,\n",
      "       0.01231904, 0.00735618, 0.00783606, 0.01087847, 0.01018035,\n",
      "       0.00664207, 0.00426194, 0.00705203, 0.01019328, 0.00965138,\n",
      "       0.00898588, 0.01104662, 0.00781623, 0.01003351, 0.00452264,\n",
      "       0.01190343, 0.01281007, 0.00525117, 0.00707444, 0.0063503 ,\n",
      "       0.00783926, 0.00790696, 0.01131463, 0.00340622, 0.01121066,\n",
      "       0.01010877, 0.00613359, 0.00782153, 0.00634082, 0.00955294,\n",
      "       0.00795204, 0.00998417, 0.00568759, 0.00749523, 0.0056916 ,\n",
      "       0.00952101, 0.00845811, 0.00832352, 0.0103707 , 0.00822255,\n",
      "       0.00704626, 0.00721601, 0.00843219, 0.01258182, 0.00873973,\n",
      "       0.01055723, 0.00981823, 0.00778411, 0.0082214 , 0.0094187 ,\n",
      "       0.00617818, 0.00945495, 0.00584689, 0.00707213, 0.01336337,\n",
      "       0.00502321, 0.00899584, 0.01318354, 0.0084434 , 0.01191734,\n",
      "       0.01167346, 0.01056239, 0.01321038, 0.00771319, 0.00888192,\n",
      "       0.0093313 , 0.01116202, 0.0098187 , 0.01047638, 0.00405781,\n",
      "       0.00906915, 0.01076935, 0.00925492, 0.01047031, 0.00833575,\n",
      "       0.01132169, 0.00688701, 0.00322905, 0.00745613, 0.01007194,\n",
      "       0.01177695, 0.01055839, 0.01176245, 0.00817361, 0.0091027 ,\n",
      "       0.00575843, 0.00840199, 0.00746228, 0.010021  , 0.00802096,\n",
      "       0.00694843, 0.00914987, 0.00885085, 0.00881132, 0.00473703,\n",
      "       0.00442196, 0.00990411, 0.00855316, 0.00806495, 0.01147087,\n",
      "       0.00790295, 0.01127983, 0.01278123, 0.00480178, 0.01054934,\n",
      "       0.01604305, 0.00851736, 0.00524106, 0.00978063, 0.00797004,\n",
      "       0.00709247, 0.00803162, 0.0123261 , 0.00926275, 0.00878517,\n",
      "       0.00808523, 0.01001838, 0.01055048, 0.00782545, 0.01269271,\n",
      "       0.0142563 , 0.00398896, 0.00830348, 0.00664579, 0.01009261,\n",
      "       0.01041378, 0.00966941, 0.01447141, 0.00421337, 0.00514188,\n",
      "       0.00925807, 0.0112893 , 0.0102819 , 0.00997674, 0.00830018,\n",
      "       0.010598  , 0.00920928, 0.00741177, 0.00882016, 0.00642814,\n",
      "       0.00872766, 0.01113469, 0.00519017, 0.00704675, 0.00785262,\n",
      "       0.01217374, 0.01017667, 0.00847403, 0.00415568, 0.00686319,\n",
      "       0.00874227, 0.00890992, 0.01019846, 0.00427234, 0.01290126,\n",
      "       0.00589753, 0.01069369, 0.0105984 , 0.00848383, 0.00555541,\n",
      "       0.00784241, 0.00751891, 0.00833194, 0.00912392, 0.01045595,\n",
      "       0.01143727, 0.00796368, 0.00806281, 0.00789428, 0.00888366,\n",
      "       0.00756959, 0.01171752, 0.01017132, 0.00823318, 0.01227518,\n",
      "       0.00513805, 0.00841887, 0.00576717, 0.00860456, 0.01260866,\n",
      "       0.00851639, 0.00853275, 0.00420573, 0.00733702, 0.00783495,\n",
      "       0.00539876, 0.00896293, 0.00915734, 0.00870025, 0.00782062,\n",
      "       0.00845434, 0.0057272 , 0.00456784, 0.00726042, 0.00710263,\n",
      "       0.00714282, 0.01001032, 0.00961989, 0.01157555, 0.01034912,\n",
      "       0.00939234, 0.00831304, 0.01031535, 0.0083309 , 0.00372627,\n",
      "       0.00537615, 0.0101052 , 0.00553021, 0.00757958, 0.00450494,\n",
      "       0.00719579, 0.01266262, 0.01193918, 0.00537338, 0.01147406,\n",
      "       0.00578409, 0.00712428, 0.0098519 , 0.01471248, 0.00840215,\n",
      "       0.00841272, 0.01010705, 0.00860556, 0.00698432, 0.00946094,\n",
      "       0.00953653, 0.01086441, 0.00616391, 0.00571004, 0.01013506,\n",
      "       0.01175983, 0.00986168, 0.00464522, 0.00717527, 0.00793427,\n",
      "       0.00992537, 0.00530466, 0.00702797, 0.00867086, 0.00925779,\n",
      "       0.0107659 , 0.00772321, 0.00575782, 0.00511572, 0.00855532,\n",
      "       0.00976436, 0.00845343, 0.00999604, 0.01048179, 0.00546831,\n",
      "       0.00866991, 0.00898868, 0.00674604, 0.01411167, 0.01207057,\n",
      "       0.0139141 , 0.00554977, 0.00616575, 0.00789614, 0.00983452,\n",
      "       0.00914852, 0.01175969, 0.0096972 , 0.00937264, 0.00484337,\n",
      "       0.00921169, 0.01237369, 0.00849359, 0.01174964, 0.00960241,\n",
      "       0.0098963 , 0.00854399, 0.00804915, 0.00924008, 0.00710069,\n",
      "       0.01044051, 0.00814574, 0.01249835, 0.00876599, 0.01287558,\n",
      "       0.01178175, 0.00826673, 0.00899762, 0.00687758, 0.00928993,\n",
      "       0.00820108, 0.00425988, 0.00738782, 0.0070529 , 0.00815249,\n",
      "       0.00956217, 0.00465296, 0.00416516, 0.00954826, 0.0100083 ,\n",
      "       0.0117298 , 0.00995544, 0.0076737 , 0.00765567, 0.01103417,\n",
      "       0.00687969, 0.00638842, 0.01343966, 0.01202908, 0.00930444,\n",
      "       0.00814775, 0.0078805 , 0.00953695, 0.01219738, 0.00771291,\n",
      "       0.00736322, 0.0046996 , 0.00771936, 0.00724251, 0.00915273,\n",
      "       0.00997563, 0.00840646, 0.00561813, 0.00818246, 0.00966124,\n",
      "       0.00826099, 0.01069122, 0.00383213, 0.00525452, 0.01466108,\n",
      "       0.01008079, 0.01029297, 0.0105728 , 0.00910315, 0.01029793,\n",
      "       0.00773681, 0.01150775, 0.00828879, 0.00819598, 0.01331902,\n",
      "       0.00922875, 0.00610805, 0.01128591, 0.00803365, 0.01252929,\n",
      "       0.00562074, 0.00546024], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer14/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 73,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.29987665e-04, 1.77696420e-04, 1.13872113e-04, 1.80142393e-04,\n",
      "       2.03208241e-04, 2.06500597e-04, 1.94933033e-04, 2.67290336e-04,\n",
      "       1.79482478e-04, 3.13861732e-04, 1.14579547e-04, 2.20701098e-04,\n",
      "       1.70608066e-04, 2.52164871e-04, 1.94886205e-04, 1.56190785e-04,\n",
      "       1.39547818e-04, 2.01839372e-04, 2.48498371e-04, 2.66845454e-04,\n",
      "       1.51789165e-04, 2.12372368e-04, 1.74178465e-04, 1.68642960e-04,\n",
      "       1.71580119e-04, 3.12727381e-04, 1.81014533e-04, 2.24209318e-04,\n",
      "       1.98667723e-04, 2.60812871e-04, 1.10708934e-04, 2.36429478e-04,\n",
      "       3.23928369e-04, 2.51926103e-04, 1.65354941e-04, 2.69193290e-04,\n",
      "       2.04564727e-04, 1.75166351e-04, 2.54079612e-04, 9.10343297e-05,\n",
      "       2.72126927e-04, 1.80904040e-04, 2.36479173e-04, 1.99147544e-04,\n",
      "       2.46180309e-04, 2.00755356e-04, 2.35433778e-04, 2.56684318e-04,\n",
      "       3.05739435e-04, 2.22409275e-04, 1.92585037e-04, 1.06200896e-04,\n",
      "       2.22404284e-04, 2.17294961e-04, 1.87439524e-04, 2.63504917e-04,\n",
      "       1.19114717e-04, 1.87546524e-04, 3.21719854e-04, 2.33269559e-04,\n",
      "       1.98044218e-04, 2.17886976e-04, 2.10747690e-04, 2.13510924e-04,\n",
      "       2.12808663e-04, 2.28128032e-04, 1.62394033e-04, 2.77525134e-04,\n",
      "       2.43153627e-04, 2.21578652e-04, 1.85579192e-04, 1.34865782e-04,\n",
      "       1.55621092e-04, 1.98496156e-04, 2.34353080e-04, 1.46901555e-04,\n",
      "       2.47646589e-04, 2.24328222e-04, 2.92624696e-04, 1.99642716e-04,\n",
      "       2.64578295e-04, 2.36965891e-04, 1.99944858e-04, 2.45358475e-04,\n",
      "       2.02584139e-04, 1.74021727e-04, 1.52509325e-04, 2.53691804e-04,\n",
      "       2.69292330e-04, 2.18010347e-04, 1.29120861e-04, 2.31582220e-04,\n",
      "       7.42294433e-05, 1.64600875e-04, 1.88873411e-04, 1.98503025e-04,\n",
      "       2.49444827e-04, 2.89594784e-04, 1.95514323e-04, 2.64822360e-04,\n",
      "       2.42676047e-04, 2.58905871e-04, 1.41186058e-04, 2.54768092e-04,\n",
      "       2.66630319e-04, 1.96529509e-04, 1.29803593e-04, 2.13291132e-04,\n",
      "       1.84822828e-04, 3.53117386e-04, 2.42715920e-04, 1.10862558e-04,\n",
      "       2.00605442e-04, 2.44808034e-04, 9.54510469e-05, 2.46152224e-04,\n",
      "       1.12016874e-04, 2.09689606e-04, 9.04135668e-05, 2.48225551e-04,\n",
      "       2.31137150e-04, 2.26365650e-04, 1.81078794e-04, 1.78526054e-04,\n",
      "       2.25848562e-04, 1.34504196e-04, 2.11843770e-04, 2.72190431e-04,\n",
      "       1.55279442e-04, 2.29014113e-04, 2.02161522e-04, 9.72396447e-05,\n",
      "       1.42280129e-04, 1.71494365e-04, 2.60713568e-04, 2.11626582e-04,\n",
      "       2.29159443e-04, 1.81205280e-04, 2.68364296e-04, 2.21111812e-04,\n",
      "       1.72931293e-04, 2.15363965e-04, 2.85483955e-04, 2.04282667e-04,\n",
      "       2.41595582e-04, 2.71454774e-04, 2.06906378e-04, 2.30640682e-04,\n",
      "       2.85149756e-04, 1.85274796e-04, 2.04589116e-04, 2.91794451e-04,\n",
      "       2.49132921e-04, 1.85873010e-04, 1.59493444e-04, 1.08273583e-04,\n",
      "       2.77966144e-04, 2.39468791e-04, 1.92430656e-04, 1.87427635e-04,\n",
      "       2.64505710e-04, 2.44809373e-04, 2.53505597e-04, 1.86009245e-04,\n",
      "       1.95488770e-04, 1.88625083e-04, 2.42109498e-04, 1.65813020e-04,\n",
      "       1.82123229e-04, 1.65643476e-04, 2.89859687e-04, 1.73086577e-04,\n",
      "       1.84377961e-04, 2.55964114e-04, 2.39537665e-04, 1.56283917e-04,\n",
      "       1.00280980e-04, 1.65930091e-04, 2.39841771e-04, 2.27091339e-04,\n",
      "       2.11432431e-04, 2.59920489e-04, 1.83911208e-04, 2.36082473e-04,\n",
      "       1.06415129e-04, 2.80080683e-04, 3.01413384e-04, 1.23556878e-04,\n",
      "       1.66457306e-04, 1.49418862e-04, 1.84453180e-04, 1.86046091e-04,\n",
      "       2.66226562e-04, 8.01462666e-05, 2.63780239e-04, 2.37853412e-04,\n",
      "       1.44319725e-04, 1.84035991e-04, 1.49195854e-04, 2.24775009e-04,\n",
      "       1.87106809e-04, 2.34921739e-04, 1.33825757e-04, 1.76358386e-04,\n",
      "       1.33920024e-04, 2.24023694e-04, 1.99014365e-04, 1.95847606e-04,\n",
      "       2.44016439e-04, 1.93471875e-04, 1.65794292e-04, 1.69788429e-04,\n",
      "       1.98404363e-04, 2.96042912e-04, 2.05640827e-04, 2.48405355e-04,\n",
      "       2.31017155e-04, 1.83155615e-04, 1.93444735e-04, 2.21616428e-04,\n",
      "       1.45368904e-04, 2.22469360e-04, 1.37573981e-04, 1.66403086e-04,\n",
      "       3.14432196e-04, 1.18193151e-04, 2.11666789e-04, 3.10200994e-04,\n",
      "       1.98668262e-04, 2.80407985e-04, 2.74669699e-04, 2.48526863e-04,\n",
      "       3.10832518e-04, 1.81486874e-04, 2.08986385e-04, 2.19559908e-04,\n",
      "       2.62635760e-04, 2.31028127e-04, 2.46502983e-04, 9.54777934e-05,\n",
      "       2.13391773e-04, 2.53396516e-04, 2.17762776e-04, 2.46360170e-04,\n",
      "       1.96135356e-04, 2.66392832e-04, 1.62047363e-04, 7.59776740e-05,\n",
      "       1.75438327e-04, 2.36986729e-04, 2.77104758e-04, 2.48432800e-04,\n",
      "       2.76763458e-04, 1.92320222e-04, 2.14181127e-04, 1.35492475e-04,\n",
      "       1.97693778e-04, 1.75583074e-04, 2.35788175e-04, 1.88728402e-04,\n",
      "       1.63492383e-04, 2.15290958e-04, 2.08255209e-04, 2.07325123e-04,\n",
      "       1.11459471e-04, 1.04046070e-04, 2.33037965e-04, 2.01250907e-04,\n",
      "       1.89763421e-04, 2.69902725e-04, 1.85951838e-04, 2.65407725e-04,\n",
      "       3.00734740e-04, 1.12983042e-04, 2.48219847e-04, 3.77483579e-04,\n",
      "       2.00408511e-04, 1.23319172e-04, 2.30132442e-04, 1.87530357e-04,\n",
      "       1.66881611e-04, 1.88979408e-04, 2.90025870e-04, 2.17947061e-04,\n",
      "       2.06709970e-04, 1.90240738e-04, 2.35726562e-04, 2.48246652e-04,\n",
      "       1.84128192e-04, 2.98652041e-04, 3.35442426e-04, 9.38577941e-05,\n",
      "       1.95376124e-04, 1.56371549e-04, 2.37473287e-04, 2.45030184e-04,\n",
      "       2.27515426e-04, 3.40503844e-04, 9.91381312e-05, 1.20985402e-04,\n",
      "       2.17837005e-04, 2.65630631e-04, 2.41927046e-04, 2.34746738e-04,\n",
      "       1.95298257e-04, 2.49364821e-04, 2.16688961e-04, 1.74394561e-04,\n",
      "       2.07533303e-04, 1.51250424e-04, 2.05356802e-04, 2.61992827e-04,\n",
      "       1.22121579e-04, 1.65805846e-04, 1.84767458e-04, 2.86440831e-04,\n",
      "       2.39451168e-04, 1.99389047e-04, 9.77807285e-05, 1.61486780e-04,\n",
      "       2.05700417e-04, 2.09645092e-04, 2.39963862e-04, 1.00525693e-04,\n",
      "       3.03559034e-04, 1.38765434e-04, 2.51616206e-04, 2.49374221e-04,\n",
      "       1.99619506e-04, 1.30715445e-04, 1.84527264e-04, 1.76915521e-04,\n",
      "       1.96045556e-04, 2.14680404e-04, 2.46022420e-04, 2.69112352e-04,\n",
      "       1.87380749e-04, 1.89713144e-04, 1.85747849e-04, 2.09027319e-04,\n",
      "       1.78108065e-04, 2.75706319e-04, 2.39325163e-04, 1.93721979e-04,\n",
      "       2.88827694e-04, 1.20895384e-04, 1.98091177e-04, 1.35698239e-04,\n",
      "       2.02460156e-04, 2.96674407e-04, 2.00385621e-04, 2.00770490e-04,\n",
      "       9.89583423e-05, 1.72635773e-04, 1.84351709e-04, 1.27029591e-04,\n",
      "       2.10892365e-04, 2.15466716e-04, 2.04711745e-04, 1.84014556e-04,\n",
      "       1.98925598e-04, 1.34757749e-04, 1.07478656e-04, 1.70833373e-04,\n",
      "       1.67120714e-04, 1.68066457e-04, 2.35536936e-04, 2.26350268e-04,\n",
      "       2.72365956e-04, 2.43508621e-04, 2.20996328e-04, 1.95600966e-04,\n",
      "       2.42714043e-04, 1.96021210e-04, 8.76770500e-05, 1.26497704e-04,\n",
      "       2.37769331e-04, 1.30122527e-04, 1.78342947e-04, 1.05998653e-04,\n",
      "       1.69312698e-04, 2.97943916e-04, 2.80921842e-04, 1.26432366e-04,\n",
      "       2.69977812e-04, 1.36096176e-04, 1.67630205e-04, 2.31809332e-04,\n",
      "       3.46175948e-04, 1.97697649e-04, 1.97946370e-04, 2.37812987e-04,\n",
      "       2.02483687e-04, 1.64336903e-04, 2.22610266e-04, 2.24388918e-04,\n",
      "       2.55633146e-04, 1.45033104e-04, 1.34353948e-04, 2.38471941e-04,\n",
      "       2.76701932e-04, 2.32039529e-04, 1.09299195e-04, 1.68829793e-04,\n",
      "       1.86688674e-04, 2.33538187e-04, 1.24815488e-04, 1.65363934e-04,\n",
      "       2.04020282e-04, 2.17830311e-04, 2.53315346e-04, 1.81722484e-04,\n",
      "       1.35478069e-04, 1.20369950e-04, 2.01301635e-04, 2.29749770e-04,\n",
      "       1.98904338e-04, 2.35200860e-04, 2.46630283e-04, 1.28666143e-04,\n",
      "       2.03997930e-04, 2.11498293e-04, 1.58730239e-04, 3.32039315e-04,\n",
      "       2.84013309e-04, 3.27390706e-04, 1.30582892e-04, 1.45076439e-04,\n",
      "       1.85791563e-04, 2.31400394e-04, 2.15259221e-04, 2.76698556e-04,\n",
      "       2.28169418e-04, 2.20532747e-04, 1.13961694e-04, 2.16745611e-04,\n",
      "       2.91145669e-04, 1.99849121e-04, 2.76462146e-04, 2.25938973e-04,\n",
      "       2.32854160e-04, 2.01035014e-04, 1.89391882e-04, 2.17413530e-04,\n",
      "       1.67075093e-04, 2.45659001e-04, 1.91664527e-04, 2.94078840e-04,\n",
      "       2.06258701e-04, 3.02954781e-04, 2.77217594e-04, 1.94511347e-04,\n",
      "       2.11708815e-04, 1.61825345e-04, 2.18586516e-04, 1.92966516e-04,\n",
      "       1.00232588e-04, 1.73831169e-04, 1.65950492e-04, 1.91823303e-04,\n",
      "       2.24992196e-04, 1.09481451e-04, 9.80037003e-05, 2.24664924e-04,\n",
      "       2.35489351e-04, 2.75995204e-04, 2.34245585e-04, 1.80557676e-04,\n",
      "       1.80133517e-04, 2.59627617e-04, 1.61875156e-04, 1.50315769e-04,\n",
      "       3.16227262e-04, 2.83037254e-04, 2.18928020e-04, 1.91711661e-04,\n",
      "       1.85423429e-04, 2.24398827e-04, 2.86997209e-04, 1.81480136e-04,\n",
      "       1.73252178e-04, 1.10578847e-04, 1.81631971e-04, 1.70411964e-04,\n",
      "       2.15358334e-04, 2.34720617e-04, 1.97799134e-04, 1.32191388e-04,\n",
      "       1.92528416e-04, 2.27323355e-04, 1.94376189e-04, 2.51558144e-04,\n",
      "       9.01677413e-05, 1.23635735e-04, 3.44966509e-04, 2.37195069e-04,\n",
      "       2.42187467e-04, 2.48771859e-04, 2.14191838e-04, 2.42304173e-04,\n",
      "       1.82042524e-04, 2.70770630e-04, 1.95030283e-04, 1.92846652e-04,\n",
      "       3.13388795e-04, 2.17147113e-04, 1.43718906e-04, 2.65550771e-04,\n",
      "       1.89027036e-04, 2.94806930e-04, 1.32252622e-04, 1.28476255e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer14/sepconv/Relu6;tower0/network/layer14/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer14/sepconv/depthwise,\n",
      "index: 74,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer15/conv/Conv2D,\n",
      "index: 75,\n",
      "shape: [512   1   1 512],\n",
      "shape_signature: [512   1   1 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00103724, 0.00127316, 0.00157847, 0.00129477, 0.00177891,\n",
      "       0.00130852, 0.00156488, 0.00135027, 0.00152521, 0.00185293,\n",
      "       0.00141943, 0.00184911, 0.00130926, 0.00166939, 0.00107645,\n",
      "       0.0012795 , 0.00149473, 0.00131291, 0.00142452, 0.00144596,\n",
      "       0.00151207, 0.00141481, 0.00127132, 0.00145317, 0.0014712 ,\n",
      "       0.00158699, 0.00160264, 0.0017236 , 0.00157898, 0.00116484,\n",
      "       0.00153637, 0.00139825, 0.00123801, 0.00199936, 0.00168621,\n",
      "       0.00229825, 0.00147299, 0.00142181, 0.00132692, 0.00125655,\n",
      "       0.00131689, 0.0012527 , 0.00124312, 0.00125732, 0.00136532,\n",
      "       0.00216702, 0.00164718, 0.00133687, 0.00142384, 0.00118357,\n",
      "       0.00140575, 0.00139593, 0.00194764, 0.00119249, 0.00139572,\n",
      "       0.00144798, 0.00100373, 0.00135437, 0.00203646, 0.00130539,\n",
      "       0.00124909, 0.00094904, 0.00147301, 0.00159558, 0.00128018,\n",
      "       0.00128622, 0.00133129, 0.0014756 , 0.0016304 , 0.0023589 ,\n",
      "       0.00105452, 0.00142945, 0.00173859, 0.00126441, 0.00154074,\n",
      "       0.00280906, 0.00158472, 0.0010421 , 0.00120686, 0.00121873,\n",
      "       0.0012627 , 0.0015954 , 0.00147263, 0.00126433, 0.00104249,\n",
      "       0.00121234, 0.00123441, 0.00138615, 0.00169566, 0.0015286 ,\n",
      "       0.00137196, 0.00131427, 0.00150964, 0.00128526, 0.00179377,\n",
      "       0.00135797, 0.0013855 , 0.00142585, 0.00105423, 0.00178368,\n",
      "       0.00163277, 0.00124101, 0.00117948, 0.00134542, 0.00164297,\n",
      "       0.00110302, 0.00132582, 0.00123212, 0.00122394, 0.00135386,\n",
      "       0.00194226, 0.00154147, 0.00157107, 0.00178299, 0.00202473,\n",
      "       0.00134548, 0.0014793 , 0.00141531, 0.00120236, 0.00187944,\n",
      "       0.00110216, 0.00119296, 0.00170085, 0.00122287, 0.00159715,\n",
      "       0.00144203, 0.00129445, 0.00113481, 0.00167723, 0.0013047 ,\n",
      "       0.00132205, 0.00132322, 0.00139327, 0.00157926, 0.00160771,\n",
      "       0.00163082, 0.0013741 , 0.00223144, 0.00131284, 0.0016321 ,\n",
      "       0.00156437, 0.00161127, 0.00158714, 0.0023922 , 0.00149827,\n",
      "       0.00109882, 0.00139548, 0.00122012, 0.00175595, 0.00127289,\n",
      "       0.00158824, 0.00125477, 0.00131834, 0.00138802, 0.00147436,\n",
      "       0.00142271, 0.00150785, 0.00186282, 0.00138635, 0.00132506,\n",
      "       0.0012003 , 0.0014266 , 0.00126686, 0.00195885, 0.00121223,\n",
      "       0.00156723, 0.00116042, 0.00148168, 0.00171838, 0.00148145,\n",
      "       0.0020565 , 0.00191659, 0.001452  , 0.0013789 , 0.00180796,\n",
      "       0.00125506, 0.00185294, 0.0011798 , 0.00190377, 0.0014072 ,\n",
      "       0.00187537, 0.00132629, 0.0016113 , 0.00170596, 0.00136273,\n",
      "       0.00109136, 0.00119645, 0.0019027 , 0.0015333 , 0.00118204,\n",
      "       0.00243098, 0.00117921, 0.00113862, 0.00147701, 0.0011078 ,\n",
      "       0.00130014, 0.00182493, 0.00194971, 0.00164824, 0.00133625,\n",
      "       0.00129949, 0.0014658 , 0.00123386, 0.0013835 , 0.00097811,\n",
      "       0.00079582, 0.0014229 , 0.00166924, 0.00129799, 0.00124609,\n",
      "       0.00179108, 0.00135918, 0.00134092, 0.0017275 , 0.00133856,\n",
      "       0.00152363, 0.00169261, 0.00137251, 0.00158773, 0.00125393,\n",
      "       0.00137183, 0.00131667, 0.00164722, 0.00173171, 0.00136408,\n",
      "       0.00128325, 0.00145613, 0.00136339, 0.00123562, 0.00154868,\n",
      "       0.00176027, 0.00132481, 0.0016242 , 0.00160565, 0.0009782 ,\n",
      "       0.00156145, 0.00123971, 0.00188387, 0.00143232, 0.00204985,\n",
      "       0.00131838, 0.00202453, 0.00167983, 0.00096142, 0.00163613,\n",
      "       0.00241128, 0.0013847 , 0.00109191, 0.00140563, 0.00144983,\n",
      "       0.0016083 , 0.00147647, 0.00117955, 0.00142806, 0.00149275,\n",
      "       0.00145143, 0.00124323, 0.00180812, 0.00135333, 0.00262696,\n",
      "       0.00141028, 0.00173162, 0.00137813, 0.00181414, 0.00138103,\n",
      "       0.00145799, 0.00129204, 0.00108235, 0.00163577, 0.00158427,\n",
      "       0.00184283, 0.00153544, 0.00158528, 0.00177091, 0.00137811,\n",
      "       0.00203732, 0.00140946, 0.00133662, 0.00139062, 0.00161824,\n",
      "       0.00131484, 0.00131893, 0.00118962, 0.00143939, 0.00164864,\n",
      "       0.00114095, 0.00175945, 0.00108392, 0.00151889, 0.00191384,\n",
      "       0.00168618, 0.00167605, 0.00146382, 0.00152947, 0.00133009,\n",
      "       0.00155638, 0.00126189, 0.00162976, 0.00169529, 0.00159318,\n",
      "       0.00157053, 0.00188811, 0.00135343, 0.00291308, 0.00151143,\n",
      "       0.00154079, 0.00177767, 0.00090498, 0.00180167, 0.0015064 ,\n",
      "       0.00166177, 0.00158156, 0.0014968 , 0.00236141, 0.00129944,\n",
      "       0.00157757, 0.00160283, 0.00162933, 0.00192153, 0.00119602,\n",
      "       0.00138409, 0.00127604, 0.0014181 , 0.00157752, 0.00162515,\n",
      "       0.00222543, 0.00141774, 0.00204134, 0.00090607, 0.00152031,\n",
      "       0.00134258, 0.00095461, 0.00141885, 0.00166699, 0.00177608,\n",
      "       0.00115481, 0.00120578, 0.00134858, 0.00280291, 0.00183112,\n",
      "       0.00144701, 0.0011342 , 0.00121687, 0.00132509, 0.00151287,\n",
      "       0.0017718 , 0.0009906 , 0.00205459, 0.00161779, 0.00130394,\n",
      "       0.00170291, 0.00139301, 0.00155912, 0.0016188 , 0.00147758,\n",
      "       0.00141623, 0.00166802, 0.00129913, 0.00137376, 0.00193659,\n",
      "       0.0015086 , 0.00170799, 0.00132609, 0.00158622, 0.00148895,\n",
      "       0.00173675, 0.00123106, 0.00161851, 0.00180718, 0.00136758,\n",
      "       0.00129657, 0.0015456 , 0.00163041, 0.00170748, 0.00156602,\n",
      "       0.00104369, 0.00125993, 0.00135638, 0.00161819, 0.00158133,\n",
      "       0.00171004, 0.00133184, 0.00122369, 0.00143831, 0.00187245,\n",
      "       0.00124973, 0.00122647, 0.00310353, 0.00141154, 0.00127646,\n",
      "       0.00150713, 0.00136183, 0.00167497, 0.00132892, 0.00127519,\n",
      "       0.00164005, 0.00163885, 0.0014668 , 0.00169431, 0.00198848,\n",
      "       0.00135837, 0.00222373, 0.00167641, 0.00143346, 0.0014528 ,\n",
      "       0.00128742, 0.001516  , 0.00113245, 0.00149694, 0.00137362,\n",
      "       0.0010378 , 0.00145108, 0.00210825, 0.00126203, 0.00129802,\n",
      "       0.00101844, 0.00149446, 0.00118624, 0.00125908, 0.00104709,\n",
      "       0.00126384, 0.00097675, 0.00144314, 0.00134187, 0.0016876 ,\n",
      "       0.00134403, 0.00125733, 0.00129177, 0.00171371, 0.00173144,\n",
      "       0.00152183, 0.00119485, 0.00191294, 0.00176449, 0.00116291,\n",
      "       0.00130194, 0.00133402, 0.00133829, 0.00119772, 0.00160819,\n",
      "       0.0012237 , 0.00133514, 0.00170878, 0.00160162, 0.00149869,\n",
      "       0.00104331, 0.00173478, 0.00152674, 0.00119917, 0.00153146,\n",
      "       0.00134477, 0.00169374, 0.00174743, 0.00133797, 0.00205682,\n",
      "       0.00151613, 0.00127549, 0.00123716, 0.00161812, 0.00137912,\n",
      "       0.00129116, 0.00162095, 0.00134992, 0.00115454, 0.00215189,\n",
      "       0.00106101, 0.0012158 , 0.00146246, 0.00115202, 0.00146226,\n",
      "       0.00135722, 0.00110078, 0.00130844, 0.00278788, 0.00147938,\n",
      "       0.0013157 , 0.0014732 , 0.00141701, 0.00105001, 0.0013027 ,\n",
      "       0.0013462 , 0.00128045, 0.000983  , 0.00184985, 0.00203041,\n",
      "       0.00149825, 0.0010912 , 0.0012857 , 0.00169491, 0.00116525,\n",
      "       0.00131413, 0.00148487, 0.00114936, 0.00131865, 0.00189927,\n",
      "       0.00124152, 0.00141776, 0.00112721, 0.00142387, 0.00182285,\n",
      "       0.00156531, 0.00152998, 0.00118409, 0.0016893 , 0.00156448,\n",
      "       0.00109149, 0.00119784, 0.00155292, 0.00142878, 0.00165856,\n",
      "       0.00154419, 0.00158046], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer15/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 76,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.4405757e-05, 2.9956818e-05, 3.7140435e-05, 3.0465148e-05,\n",
      "       4.1856685e-05, 3.0788691e-05, 3.6820635e-05, 3.1770945e-05,\n",
      "       3.5887249e-05, 4.3598269e-05, 3.3398406e-05, 4.3508371e-05,\n",
      "       3.0806157e-05, 3.9279770e-05, 2.5328165e-05, 3.0105795e-05,\n",
      "       3.5170113e-05, 3.0892061e-05, 3.3518136e-05, 3.4022574e-05,\n",
      "       3.5578203e-05, 3.3289565e-05, 2.9913523e-05, 3.4192202e-05,\n",
      "       3.4616471e-05, 3.7340847e-05, 3.7709236e-05, 4.0555344e-05,\n",
      "       3.7152487e-05, 2.7408014e-05, 3.6149941e-05, 3.2899999e-05,\n",
      "       2.9129549e-05, 4.7043799e-05, 3.9675491e-05, 5.4076452e-05,\n",
      "       3.4658606e-05, 3.3454420e-05, 3.1221600e-05, 2.9565857e-05,\n",
      "       3.0985735e-05, 2.9475361e-05, 2.9249853e-05, 2.9584115e-05,\n",
      "       3.2125270e-05, 5.0988707e-05, 3.8757185e-05, 3.1455827e-05,\n",
      "       3.3502143e-05, 2.7848695e-05, 3.3076358e-05, 3.2845317e-05,\n",
      "       4.5826895e-05, 2.8058554e-05, 3.2840358e-05, 3.4070184e-05,\n",
      "       2.3617176e-05, 3.1867618e-05, 4.7916805e-05, 3.0715059e-05,\n",
      "       2.9390423e-05, 2.2330425e-05, 3.4659057e-05, 3.7543065e-05,\n",
      "       3.0121766e-05, 3.0264042e-05, 3.1324507e-05, 3.4720033e-05,\n",
      "       3.8362290e-05, 5.5503519e-05, 2.4812332e-05, 3.3634224e-05,\n",
      "       4.0908111e-05, 2.9750739e-05, 3.6252663e-05, 6.6095527e-05,\n",
      "       3.7287435e-05, 2.4520099e-05, 2.8396798e-05, 2.8676071e-05,\n",
      "       2.9710647e-05, 3.7538917e-05, 3.4650231e-05, 2.9749021e-05,\n",
      "       2.4529270e-05, 2.8525745e-05, 2.9044832e-05, 3.2615371e-05,\n",
      "       3.9897957e-05, 3.5967056e-05, 3.2281387e-05, 3.0923966e-05,\n",
      "       3.5520959e-05, 3.0241526e-05, 4.2206295e-05, 3.1952331e-05,\n",
      "       3.2599895e-05, 3.3549430e-05, 2.4805413e-05, 4.1968924e-05,\n",
      "       3.8418217e-05, 2.9200351e-05, 2.7752405e-05, 3.1656869e-05,\n",
      "       3.8658054e-05, 2.5953446e-05, 3.1195854e-05, 2.8991097e-05,\n",
      "       2.8798588e-05, 3.1855441e-05, 4.5700352e-05, 3.6269910e-05,\n",
      "       3.6966463e-05, 4.1952728e-05, 4.7640686e-05, 3.1658466e-05,\n",
      "       3.4807021e-05, 3.3301352e-05, 2.8290904e-05, 4.4222201e-05,\n",
      "       2.5933206e-05, 2.8069699e-05, 4.0020059e-05, 2.8773480e-05,\n",
      "       3.7579994e-05, 3.3930162e-05, 3.0457652e-05, 2.6701498e-05,\n",
      "       3.9464252e-05, 3.0698815e-05, 3.1106953e-05, 3.1134510e-05,\n",
      "       3.2782762e-05, 3.7159178e-05, 3.7828526e-05, 3.8372349e-05,\n",
      "       3.2331820e-05, 5.2504445e-05, 3.0890347e-05, 3.8402373e-05,\n",
      "       3.6808615e-05, 3.7912192e-05, 3.7344504e-05, 5.6287008e-05,\n",
      "       3.5253419e-05, 2.5854606e-05, 3.2834829e-05, 2.8708622e-05,\n",
      "       4.1316405e-05, 2.9950270e-05, 3.7370413e-05, 2.9523899e-05,\n",
      "       3.1019670e-05, 3.2659183e-05, 3.4690856e-05, 3.3475550e-05,\n",
      "       3.5478803e-05, 4.3831165e-05, 3.2619948e-05, 3.1177806e-05,\n",
      "       2.8242361e-05, 3.3567016e-05, 2.9808445e-05, 4.6090547e-05,\n",
      "       2.8523154e-05, 3.6876107e-05, 2.7304070e-05, 3.4862995e-05,\n",
      "       4.0432544e-05, 3.4857570e-05, 4.8388159e-05, 4.5096305e-05,\n",
      "       3.4164612e-05, 3.2444597e-05, 4.2540138e-05, 2.9530758e-05,\n",
      "       4.3598488e-05, 2.7760034e-05, 4.4794517e-05, 3.3110638e-05,\n",
      "       4.4126427e-05, 3.1206888e-05, 3.7912905e-05, 4.0140229e-05,\n",
      "       3.2064301e-05, 2.5678979e-05, 2.8151806e-05, 4.4769517e-05,\n",
      "       3.6077712e-05, 2.7812761e-05, 5.7199613e-05, 2.7746015e-05,\n",
      "       2.6791167e-05, 3.4753197e-05, 2.6065878e-05, 3.0591505e-05,\n",
      "       4.2939570e-05, 4.5875640e-05, 3.8782193e-05, 3.1441246e-05,\n",
      "       3.0576193e-05, 3.4489462e-05, 2.9032090e-05, 3.2552958e-05,\n",
      "       2.3014318e-05, 1.8725121e-05, 3.3480002e-05, 3.9276169e-05,\n",
      "       3.0540898e-05, 2.9319714e-05, 4.2143125e-05, 3.1980780e-05,\n",
      "       3.1550990e-05, 4.0646952e-05, 3.1495576e-05, 3.5850204e-05,\n",
      "       3.9826024e-05, 3.2294349e-05, 3.7358430e-05, 2.9504243e-05,\n",
      "       3.2278385e-05, 3.0980384e-05, 3.8758073e-05, 4.0746079e-05,\n",
      "       3.2095890e-05, 3.0194065e-05, 3.4261881e-05, 3.2079846e-05,\n",
      "       2.9073430e-05, 3.6439575e-05, 4.1418203e-05, 3.1171985e-05,\n",
      "       3.8216476e-05, 3.7779926e-05, 2.3016430e-05, 3.6740028e-05,\n",
      "       2.9169531e-05, 4.4326360e-05, 3.3701614e-05, 4.8231821e-05,\n",
      "       3.1020714e-05, 4.7636029e-05, 3.9525454e-05, 2.2621620e-05,\n",
      "       3.8497259e-05, 5.6736008e-05, 3.2581236e-05, 2.5692065e-05,\n",
      "       3.3073669e-05, 3.4113760e-05, 3.7842292e-05, 3.4740588e-05,\n",
      "       2.7754055e-05, 3.3601340e-05, 3.5123463e-05, 3.4151308e-05,\n",
      "       2.9252375e-05, 4.2544099e-05, 3.1843119e-05, 6.1810897e-05,\n",
      "       3.3183147e-05, 4.0743984e-05, 3.2426582e-05, 4.2685733e-05,\n",
      "       3.2494925e-05, 3.4305718e-05, 3.0401010e-05, 2.5467003e-05,\n",
      "       3.8488761e-05, 3.7276943e-05, 4.3360651e-05, 3.6127913e-05,\n",
      "       3.7300699e-05, 4.1668391e-05, 3.2426153e-05, 4.7936959e-05,\n",
      "       3.3163662e-05, 3.1449821e-05, 3.2720556e-05, 3.8076247e-05,\n",
      "       3.0937397e-05, 3.1033673e-05, 2.7991147e-05, 3.3867895e-05,\n",
      "       3.8791532e-05, 2.6845812e-05, 4.1398875e-05, 2.5503936e-05,\n",
      "       3.5738551e-05, 4.5031509e-05, 3.9674738e-05, 3.9436429e-05,\n",
      "       3.4442834e-05, 3.5987534e-05, 3.1296353e-05, 3.6620702e-05,\n",
      "       2.9691490e-05, 3.8347214e-05, 3.9889142e-05, 3.7486625e-05,\n",
      "       3.6953541e-05, 4.4426019e-05, 3.1845429e-05, 6.8543166e-05,\n",
      "       3.5563142e-05, 3.6253910e-05, 4.1827501e-05, 2.1293603e-05,\n",
      "       4.2392305e-05, 3.5444817e-05, 3.9100523e-05, 3.7213285e-05,\n",
      "       3.5218723e-05, 5.5562636e-05, 3.0574964e-05, 3.7119389e-05,\n",
      "       3.7713740e-05, 3.8337250e-05, 4.5212473e-05, 2.8141674e-05,\n",
      "       3.2566732e-05, 3.0024383e-05, 3.3366956e-05, 3.7118145e-05,\n",
      "       3.8238784e-05, 5.2363164e-05, 3.3358650e-05, 4.8031452e-05,\n",
      "       2.1319405e-05, 3.5772064e-05, 3.1590138e-05, 2.2461398e-05,\n",
      "       3.3384695e-05, 3.9223298e-05, 4.1790183e-05, 2.7171931e-05,\n",
      "       2.8371393e-05, 3.1731335e-05, 6.5950895e-05, 4.3085136e-05,\n",
      "       3.4047251e-05, 2.6687156e-05, 2.8632170e-05, 3.1178635e-05,\n",
      "       3.5596902e-05, 4.1689356e-05, 2.3308292e-05, 4.8343405e-05,\n",
      "       3.8065718e-05, 3.0680876e-05, 4.0068498e-05, 3.2776592e-05,\n",
      "       3.6685098e-05, 3.8089445e-05, 3.4766570e-05, 3.3323005e-05,\n",
      "       3.9247621e-05, 3.0567775e-05, 3.2323867e-05, 4.5566831e-05,\n",
      "       3.5496574e-05, 4.0188090e-05, 3.1202111e-05, 3.7322825e-05,\n",
      "       3.5034056e-05, 4.0864608e-05, 2.8966060e-05, 3.8082664e-05,\n",
      "       4.2521915e-05, 3.2178399e-05, 3.0507446e-05, 3.6367059e-05,\n",
      "       3.8362603e-05, 4.0176048e-05, 3.6847552e-05, 2.4557379e-05,\n",
      "       2.9645433e-05, 3.1914835e-05, 3.8075064e-05, 3.7207763e-05,\n",
      "       4.0236286e-05, 3.1337495e-05, 2.8792663e-05, 3.3842531e-05,\n",
      "       4.4057575e-05, 2.9405352e-05, 2.8858210e-05, 7.3024356e-05,\n",
      "       3.3212713e-05, 3.0034329e-05, 3.5461995e-05, 3.2043125e-05,\n",
      "       3.9411094e-05, 3.1268664e-05, 3.0004379e-05, 3.8589496e-05,\n",
      "       3.8561233e-05, 3.4512883e-05, 3.9866161e-05, 4.6787682e-05,\n",
      "       3.1961765e-05, 5.2322954e-05, 3.9445003e-05, 3.3728553e-05,\n",
      "       3.4183468e-05, 3.0292125e-05, 3.5670506e-05, 2.6645808e-05,\n",
      "       3.5222172e-05, 3.2320415e-05, 2.4418801e-05, 3.4143151e-05,\n",
      "       4.9605835e-05, 2.9694744e-05, 3.0541698e-05, 2.3963210e-05,\n",
      "       3.5163823e-05, 2.7911532e-05, 2.9625369e-05, 2.4637337e-05,\n",
      "       2.9737439e-05, 2.2982393e-05, 3.3956148e-05, 3.1573352e-05,\n",
      "       3.9708171e-05, 3.1624299e-05, 2.9584215e-05, 3.0394491e-05,\n",
      "       4.0322633e-05, 4.0739851e-05, 3.5807821e-05, 2.8114202e-05,\n",
      "       4.5010329e-05, 4.1517455e-05, 2.7362636e-05, 3.0633830e-05,\n",
      "       3.1388689e-05, 3.1489126e-05, 2.8181592e-05, 3.7839767e-05,\n",
      "       2.8792829e-05, 3.1415158e-05, 4.0206691e-05, 3.7685229e-05,\n",
      "       3.5263405e-05, 2.4548439e-05, 4.0818431e-05, 3.5923338e-05,\n",
      "       2.8215834e-05, 3.6034337e-05, 3.1641550e-05, 3.9852668e-05,\n",
      "       4.1115916e-05, 3.1481737e-05, 4.8395883e-05, 3.5673616e-05,\n",
      "       3.0011495e-05, 2.9109726e-05, 3.8073405e-05, 3.2449861e-05,\n",
      "       3.0380186e-05, 3.8140101e-05, 3.1762909e-05, 2.7165681e-05,\n",
      "       5.0632694e-05, 2.4964987e-05, 2.8606968e-05, 3.4410834e-05,\n",
      "       2.7106364e-05, 3.4406032e-05, 3.1934615e-05, 2.5900681e-05,\n",
      "       3.0786745e-05, 6.5597073e-05, 3.4808843e-05, 3.0957661e-05,\n",
      "       3.4663444e-05, 3.3341410e-05, 2.4706158e-05, 3.0651852e-05,\n",
      "       3.1675329e-05, 3.0128129e-05, 2.3129334e-05, 4.3525892e-05,\n",
      "       4.7774356e-05, 3.5252877e-05, 2.5675237e-05, 3.0251869e-05,\n",
      "       3.9880182e-05, 2.7417691e-05, 3.0920772e-05, 3.4938210e-05,\n",
      "       2.7043669e-05, 3.1027146e-05, 4.4688706e-05, 2.9212229e-05,\n",
      "       3.3359160e-05, 2.6522604e-05, 3.3502718e-05, 4.2890617e-05,\n",
      "       3.6830887e-05, 3.5999641e-05, 2.7860920e-05, 3.9748134e-05,\n",
      "       3.6811300e-05, 2.5682015e-05, 2.8184544e-05, 3.6539386e-05,\n",
      "       3.3618380e-05, 3.9024962e-05, 3.6333786e-05, 3.7187274e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer15/conv/Relu6;tower0/network/layer15/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer15/conv/Conv2D,\n",
      "index: 77,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer16/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer16/sepconv/depthwise;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 78,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.01127424, 0.00768088, 0.00907373, 0.00671574, 0.00579908,\n",
      "       0.00490481, 0.00709942, 0.0044196 , 0.00750762, 0.01049128,\n",
      "       0.00593343, 0.00319585, 0.01299228, 0.01051232, 0.00989219,\n",
      "       0.00849701, 0.007855  , 0.00701518, 0.00961003, 0.00480077,\n",
      "       0.00647089, 0.01001109, 0.00511175, 0.00604685, 0.00628006,\n",
      "       0.00482957, 0.00580207, 0.00751868, 0.00546206, 0.01063042,\n",
      "       0.00442458, 0.00986093, 0.00899786, 0.00707503, 0.00618971,\n",
      "       0.00369061, 0.00731292, 0.01084241, 0.00657532, 0.01163   ,\n",
      "       0.00777791, 0.00462239, 0.00449031, 0.00679059, 0.00553231,\n",
      "       0.00706013, 0.00609122, 0.0043979 , 0.00927736, 0.00391937,\n",
      "       0.00783892, 0.00635438, 0.0115746 , 0.00648065, 0.00719039,\n",
      "       0.00541761, 0.00535327, 0.0055699 , 0.01289665, 0.00923283,\n",
      "       0.0096832 , 0.0130362 , 0.0113329 , 0.00909031, 0.00837877,\n",
      "       0.01084185, 0.00512666, 0.0062297 , 0.00762479, 0.0089237 ,\n",
      "       0.00813619, 0.00649871, 0.00913741, 0.00664687, 0.00779188,\n",
      "       0.00625961, 0.00696685, 0.0100047 , 0.00441073, 0.00610382,\n",
      "       0.00486122, 0.00918901, 0.00426014, 0.00685985, 0.00716246,\n",
      "       0.00708913, 0.01059605, 0.00634395, 0.00536394, 0.01272199,\n",
      "       0.00524545, 0.00726229, 0.00840865, 0.00492282, 0.00739824,\n",
      "       0.00491529, 0.01006714, 0.00619373, 0.00596999, 0.00491686,\n",
      "       0.00526554, 0.00630221, 0.01002086, 0.00772544, 0.0075732 ,\n",
      "       0.00527011, 0.00886341, 0.00687037, 0.00470727, 0.00838152,\n",
      "       0.00873686, 0.01226244, 0.00486392, 0.00714923, 0.01044696,\n",
      "       0.0117341 , 0.00466493, 0.01040217, 0.00800382, 0.00738481,\n",
      "       0.00399488, 0.00473991, 0.00818972, 0.00497251, 0.0087123 ,\n",
      "       0.01197801, 0.00781513, 0.00513485, 0.00700713, 0.00665882,\n",
      "       0.00811626, 0.00711959, 0.00629152, 0.00715934, 0.00546345,\n",
      "       0.0061107 , 0.00830719, 0.00696546, 0.00792309, 0.01060364,\n",
      "       0.00532721, 0.00788913, 0.00900186, 0.00822217, 0.0039983 ,\n",
      "       0.00384877, 0.01198578, 0.00691695, 0.00934535, 0.01050927,\n",
      "       0.0064121 , 0.0078321 , 0.00467898, 0.00723776, 0.00628494,\n",
      "       0.01260157, 0.00925778, 0.00678329, 0.00590975, 0.0054381 ,\n",
      "       0.00495599, 0.00747743, 0.0074455 , 0.00944596, 0.00708186,\n",
      "       0.00580984, 0.01115777, 0.00713322, 0.00673977, 0.00605099,\n",
      "       0.00583814, 0.0073388 , 0.00922519, 0.00841674, 0.00534238,\n",
      "       0.00942031, 0.00570382, 0.00484815, 0.00420113, 0.00846793,\n",
      "       0.00620404, 0.01096976, 0.0081355 , 0.0097898 , 0.01020362,\n",
      "       0.00909801, 0.01015233, 0.00920948, 0.00409025, 0.00505124,\n",
      "       0.01083706, 0.00516121, 0.01007646, 0.0046357 , 0.00637022,\n",
      "       0.00576804, 0.00730271, 0.01039587, 0.00620031, 0.00699573,\n",
      "       0.00701152, 0.005148  , 0.00971756, 0.00470278, 0.01024071,\n",
      "       0.01481042, 0.00657444, 0.00620921, 0.00567751, 0.00558993,\n",
      "       0.00442334, 0.00783188, 0.01104947, 0.01080022, 0.00766914,\n",
      "       0.00557704, 0.00753822, 0.00967798, 0.00758921, 0.0092504 ,\n",
      "       0.00677265, 0.00776272, 0.00843947, 0.01064644, 0.00584997,\n",
      "       0.00847264, 0.00509227, 0.0080874 , 0.00549567, 0.00954241,\n",
      "       0.00644771, 0.00627183, 0.00811372, 0.00900305, 0.010606  ,\n",
      "       0.00491049, 0.01064781, 0.01200495, 0.00606101, 0.00846716,\n",
      "       0.00972293, 0.00792639, 0.00815416, 0.006585  , 0.00417563,\n",
      "       0.00900913, 0.00633064, 0.00641711, 0.00732115, 0.00608126,\n",
      "       0.00517424, 0.00704749, 0.00613893, 0.00815461, 0.0059197 ,\n",
      "       0.00750192, 0.00618904, 0.00507833, 0.01002426, 0.00571404,\n",
      "       0.00517633, 0.00440324, 0.00786171, 0.00437242, 0.00503863,\n",
      "       0.00832927, 0.00845395, 0.01112329, 0.00387963, 0.00650587,\n",
      "       0.00628924, 0.00814959, 0.00693083, 0.00816107, 0.00762954,\n",
      "       0.00792021, 0.00844445, 0.00576322, 0.00631182, 0.00469054,\n",
      "       0.00385152, 0.00914859, 0.00747718, 0.01121548, 0.00754449,\n",
      "       0.00467498, 0.00876181, 0.00703214, 0.00678792, 0.0065627 ,\n",
      "       0.00846246, 0.01056248, 0.01041064, 0.01501214, 0.01051234,\n",
      "       0.00560821, 0.00494692, 0.00841362, 0.00940817, 0.00818793,\n",
      "       0.00492548, 0.00474607, 0.00652092, 0.00655287, 0.00376776,\n",
      "       0.00648207, 0.00988913, 0.01278917, 0.00461262, 0.01290835,\n",
      "       0.00871737, 0.0059064 , 0.00590016, 0.00497541, 0.00533552,\n",
      "       0.00844629, 0.00783582, 0.00555325, 0.006494  , 0.00860161,\n",
      "       0.00758587, 0.00438181, 0.01072998, 0.00627231, 0.00793914,\n",
      "       0.0088952 , 0.00509752, 0.00718645, 0.00866001, 0.00787982,\n",
      "       0.00440567, 0.0067861 , 0.01068243, 0.00944306, 0.00550793,\n",
      "       0.0062559 , 0.00854317, 0.00729268, 0.00585264, 0.01064594,\n",
      "       0.00499515, 0.00762489, 0.01029203, 0.00611402, 0.00611679,\n",
      "       0.00450922, 0.00704895, 0.00664158, 0.00660009, 0.00590229,\n",
      "       0.00940521, 0.00679783, 0.00710428, 0.0069564 , 0.00692693,\n",
      "       0.00449272, 0.00942571, 0.00654515, 0.01185977, 0.00698094,\n",
      "       0.00386832, 0.00648519, 0.00753688, 0.00624335, 0.00610958,\n",
      "       0.0042589 , 0.00689296, 0.00447819, 0.00798602, 0.00948049,\n",
      "       0.01014007, 0.00815117, 0.00966246, 0.00918689, 0.00615237,\n",
      "       0.00517018, 0.00733941, 0.00861343, 0.00777243, 0.0104211 ,\n",
      "       0.0102826 , 0.00861238, 0.00562716, 0.0055343 , 0.00840499,\n",
      "       0.00495165, 0.00542468, 0.00656659, 0.00764929, 0.00622023,\n",
      "       0.01089236, 0.00950214, 0.00609866, 0.00529281, 0.00799044,\n",
      "       0.00702411, 0.00896618, 0.00500398, 0.00477294, 0.00669391,\n",
      "       0.00742646, 0.00526323, 0.00413433, 0.00755351, 0.00776406,\n",
      "       0.00801882, 0.00525116, 0.00704542, 0.00748778, 0.00614464,\n",
      "       0.00845334, 0.00577428, 0.00631615, 0.00631955, 0.00338571,\n",
      "       0.00770655, 0.00961895, 0.01405325, 0.00448301, 0.00746384,\n",
      "       0.00633927, 0.005586  , 0.0087269 , 0.0071435 , 0.00856513,\n",
      "       0.00480405, 0.00767191, 0.00635043, 0.01008915, 0.00982628,\n",
      "       0.00842896, 0.00441762, 0.00888766, 0.00585743, 0.01118841,\n",
      "       0.00535053, 0.00452911, 0.00896221, 0.01093285, 0.00693845,\n",
      "       0.00582771, 0.00909796, 0.00666084, 0.00878507, 0.00855671,\n",
      "       0.00979395, 0.00973654, 0.00722298, 0.00718004, 0.00858292,\n",
      "       0.00763449, 0.00944516, 0.00610063, 0.00442715, 0.00844931,\n",
      "       0.00920149, 0.00537109, 0.00500531, 0.0059843 , 0.00667187,\n",
      "       0.00806263, 0.00649879, 0.00951294, 0.00506613, 0.00719765,\n",
      "       0.00703807, 0.005455  , 0.01154047, 0.00758866, 0.00543348,\n",
      "       0.01039024, 0.00703175, 0.00926489, 0.0038165 , 0.0112956 ,\n",
      "       0.00555078, 0.00364965, 0.00831199, 0.00524606, 0.00876476,\n",
      "       0.00757271, 0.0036731 , 0.00916055, 0.00958149, 0.00768992,\n",
      "       0.00841263, 0.00586688, 0.00346537, 0.00876562, 0.00481076,\n",
      "       0.00372512, 0.0080584 , 0.00622779, 0.01027695, 0.00358652,\n",
      "       0.00550821, 0.00862235, 0.0078526 , 0.00866876, 0.0083586 ,\n",
      "       0.01096478, 0.01168178, 0.00930701, 0.00680051, 0.00741455,\n",
      "       0.00344126, 0.00894482, 0.00864898, 0.00930262, 0.00535344,\n",
      "       0.00497065, 0.00968419], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer16/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 79,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.65276292e-04, 1.80726682e-04, 2.13499457e-04, 1.58017443e-04,\n",
      "       1.36448856e-04, 1.15407187e-04, 1.67045087e-04, 1.03990656e-04,\n",
      "       1.76649890e-04, 2.46853742e-04, 1.39610100e-04, 7.51965126e-05,\n",
      "       3.05700756e-04, 2.47348595e-04, 2.32757375e-04, 1.99929651e-04,\n",
      "       1.84823599e-04, 1.65063044e-04, 2.26118267e-04, 1.12959358e-04,\n",
      "       1.52256340e-04, 2.35555068e-04, 1.20276534e-04, 1.42278805e-04,\n",
      "       1.47766230e-04, 1.13636837e-04, 1.36519375e-04, 1.76910195e-04,\n",
      "       1.28519183e-04, 2.50127632e-04, 1.04107785e-04, 2.32021775e-04,\n",
      "       2.11714272e-04, 1.66471262e-04, 1.45640181e-04, 8.68378411e-05,\n",
      "       1.72068758e-04, 2.55115418e-04, 1.54713460e-04, 2.73646961e-04,\n",
      "       1.83009601e-04, 1.08762099e-04, 1.05654362e-04, 1.59778487e-04,\n",
      "       1.30172106e-04, 1.66120721e-04, 1.43322774e-04, 1.03479913e-04,\n",
      "       2.18290923e-04, 9.22204708e-05, 1.84445104e-04, 1.49514730e-04,\n",
      "       2.72343605e-04, 1.52485940e-04, 1.69185543e-04, 1.27473264e-04,\n",
      "       1.25959385e-04, 1.31056368e-04, 3.03450506e-04, 2.17242981e-04,\n",
      "       2.27839962e-04, 3.06734088e-04, 2.66656396e-04, 2.13889711e-04,\n",
      "       1.97147601e-04, 2.55102321e-04, 1.20627228e-04, 1.46581107e-04,\n",
      "       1.79406867e-04, 2.09969308e-04, 1.91439671e-04, 1.52910914e-04,\n",
      "       2.14997897e-04, 1.56396942e-04, 1.83338358e-04, 1.47285013e-04,\n",
      "       1.63925884e-04, 2.35404630e-04, 1.03781771e-04, 1.43619327e-04,\n",
      "       1.14381641e-04, 2.16211934e-04, 1.00238547e-04, 1.61408127e-04,\n",
      "       1.68528422e-04, 1.66803060e-04, 2.49318895e-04, 1.49269385e-04,\n",
      "       1.26210318e-04, 2.99341045e-04, 1.23422375e-04, 1.70877334e-04,\n",
      "       1.97850633e-04, 1.15831011e-04, 1.74076311e-04, 1.15653944e-04,\n",
      "       2.36873908e-04, 1.45734855e-04, 1.40470424e-04, 1.15690942e-04,\n",
      "       1.23895021e-04, 1.48287218e-04, 2.35784959e-04, 1.81775045e-04,\n",
      "       1.78193019e-04, 1.24002545e-04, 2.08550890e-04, 1.61655727e-04,\n",
      "       1.10759414e-04, 1.97212299e-04, 2.05573160e-04, 2.88527895e-04,\n",
      "       1.14445225e-04, 1.68217171e-04, 2.45810719e-04, 2.76096485e-04,\n",
      "       1.09763096e-04, 2.44757044e-04, 1.88325066e-04, 1.73760302e-04,\n",
      "       9.39972815e-05, 1.11527232e-04, 1.92699372e-04, 1.17000163e-04,\n",
      "       2.04995187e-04, 2.81835528e-04, 1.83885393e-04, 1.20819903e-04,\n",
      "       1.64873753e-04, 1.56678114e-04, 1.90970852e-04, 1.67519815e-04,\n",
      "       1.48035833e-04, 1.68455052e-04, 1.28551852e-04, 1.43781246e-04,\n",
      "       1.95463406e-04, 1.63893244e-04, 1.86425561e-04, 2.49497301e-04,\n",
      "       1.25346138e-04, 1.85626690e-04, 2.11808467e-04, 1.93462925e-04,\n",
      "       9.40776154e-05, 9.05593261e-05, 2.82018300e-04, 1.62751807e-04,\n",
      "       2.19890571e-04, 2.47276883e-04, 1.50872860e-04, 1.84284727e-04,\n",
      "       1.10093701e-04, 1.70300133e-04, 1.47881001e-04, 2.96507584e-04,\n",
      "       2.17830049e-04, 1.59606934e-04, 1.39052849e-04, 1.27955194e-04,\n",
      "       1.16611482e-04, 1.75939465e-04, 1.75188296e-04, 2.22257921e-04,\n",
      "       1.66631915e-04, 1.36702234e-04, 2.62535730e-04, 1.67840364e-04,\n",
      "       1.58582887e-04, 1.42376171e-04, 1.37367970e-04, 1.72677566e-04,\n",
      "       2.17063396e-04, 1.98040972e-04, 1.25702951e-04, 2.21654380e-04,\n",
      "       1.34207454e-04, 1.14074079e-04, 9.88502288e-05, 1.99245507e-04,\n",
      "       1.45977363e-04, 2.58112006e-04, 1.91423460e-04, 2.30348203e-04,\n",
      "       2.40085079e-04, 2.14070897e-04, 2.38878332e-04, 2.16693676e-04,\n",
      "       9.62411214e-05, 1.18852658e-04, 2.54989631e-04, 1.21440346e-04,\n",
      "       2.37093234e-04, 1.09075263e-04, 1.49887623e-04, 1.35718481e-04,\n",
      "       1.71828520e-04, 2.44608644e-04, 1.45889600e-04, 1.64605401e-04,\n",
      "       1.64976824e-04, 1.21129327e-04, 2.28648525e-04, 1.10653535e-04,\n",
      "       2.40957786e-04, 3.48480477e-04, 1.54692811e-04, 1.46099133e-04,\n",
      "       1.33588532e-04, 1.31527835e-04, 1.04078674e-04, 1.84279459e-04,\n",
      "       2.59987602e-04, 2.54122919e-04, 1.80450254e-04, 1.31224428e-04,\n",
      "       1.77369962e-04, 2.27717072e-04, 1.78569622e-04, 2.17656372e-04,\n",
      "       1.59356423e-04, 1.82652249e-04, 1.98575814e-04, 2.50504439e-04,\n",
      "       1.37646435e-04, 1.99356306e-04, 1.19818236e-04, 1.90291728e-04,\n",
      "       1.29309847e-04, 2.24527263e-04, 1.51710847e-04, 1.47572442e-04,\n",
      "       1.90910971e-04, 2.11836537e-04, 2.49552890e-04, 1.15540919e-04,\n",
      "       2.50536745e-04, 2.82469438e-04, 1.42612014e-04, 1.99227405e-04,\n",
      "       2.28774865e-04, 1.86503239e-04, 1.91862535e-04, 1.54941285e-04,\n",
      "       9.82500205e-05, 2.11979612e-04, 1.48956300e-04, 1.50990832e-04,\n",
      "       1.72262444e-04, 1.43088517e-04, 1.21746794e-04, 1.65823323e-04,\n",
      "       1.44445527e-04, 1.91873158e-04, 1.39287105e-04, 1.76515736e-04,\n",
      "       1.45624406e-04, 1.19490047e-04, 2.35864878e-04, 1.34447939e-04,\n",
      "       1.21795907e-04, 1.03605729e-04, 1.84981502e-04, 1.02880491e-04,\n",
      "       1.18556054e-04, 1.95982837e-04, 1.98916503e-04, 2.61724490e-04,\n",
      "       9.12853866e-05, 1.53079221e-04, 1.47982224e-04, 1.91755069e-04,\n",
      "       1.63078250e-04, 1.92025240e-04, 1.79518524e-04, 1.86357895e-04,\n",
      "       1.98692869e-04, 1.35605078e-04, 1.48513500e-04, 1.10365603e-04,\n",
      "       9.06240675e-05, 2.15260996e-04, 1.75933747e-04, 2.63893569e-04,\n",
      "       1.77517315e-04, 1.09999477e-04, 2.06160272e-04, 1.65462086e-04,\n",
      "       1.59715710e-04, 1.54416586e-04, 1.99116635e-04, 2.48529017e-04,\n",
      "       2.44956202e-04, 3.53226875e-04, 2.47349264e-04, 1.31957771e-04,\n",
      "       1.16398143e-04, 1.97967427e-04, 2.21368813e-04, 1.92657244e-04,\n",
      "       1.15893541e-04, 1.11672161e-04, 1.53433386e-04, 1.54185182e-04,\n",
      "       8.86531125e-05, 1.52519235e-04, 2.32685314e-04, 3.00921645e-04,\n",
      "       1.08532186e-04, 3.03725945e-04, 2.05114600e-04, 1.38974166e-04,\n",
      "       1.38827250e-04, 1.17068419e-04, 1.25541643e-04, 1.98736307e-04,\n",
      "       1.84372329e-04, 1.30664586e-04, 1.52800116e-04, 2.02390889e-04,\n",
      "       1.78491158e-04, 1.03101418e-04, 2.52470025e-04, 1.47583720e-04,\n",
      "       1.86803416e-04, 2.09298843e-04, 1.19941651e-04, 1.69092964e-04,\n",
      "       2.03764954e-04, 1.85407524e-04, 1.03662933e-04, 1.59673000e-04,\n",
      "       2.51351419e-04, 2.22189614e-04, 1.29598295e-04, 1.47197759e-04,\n",
      "       2.01015690e-04, 1.71592575e-04, 1.37709198e-04, 2.50492798e-04,\n",
      "       1.17532909e-04, 1.79409079e-04, 2.42165377e-04, 1.43859346e-04,\n",
      "       1.43924524e-04, 1.06099214e-04, 1.65857666e-04, 1.56272377e-04,\n",
      "       1.55296264e-04, 1.38877484e-04, 2.21299139e-04, 1.59948875e-04,\n",
      "       1.67159553e-04, 1.63679928e-04, 1.62986500e-04, 1.05711144e-04,\n",
      "       2.21781433e-04, 1.54003486e-04, 2.79053493e-04, 1.64257508e-04,\n",
      "       9.10191884e-05, 1.52592591e-04, 1.77338341e-04, 1.46902326e-04,\n",
      "       1.43754864e-04, 1.00209312e-04, 1.62187251e-04, 1.05369254e-04,\n",
      "       1.87906335e-04, 2.23070369e-04, 2.38589986e-04, 1.91792176e-04,\n",
      "       2.27351935e-04, 2.16162094e-04, 1.44761696e-04, 1.21651239e-04,\n",
      "       1.72691944e-04, 2.02668874e-04, 1.82880831e-04, 2.45202275e-04,\n",
      "       2.41943475e-04, 2.02644165e-04, 1.32403817e-04, 1.30218716e-04,\n",
      "       1.97764355e-04, 1.16509531e-04, 1.27639621e-04, 1.54508045e-04,\n",
      "       1.79983399e-04, 1.46358347e-04, 2.56290892e-04, 2.23579787e-04,\n",
      "       1.43497906e-04, 1.24536702e-04, 1.88010410e-04, 1.65273115e-04,\n",
      "       2.10969039e-04, 1.17740718e-04, 1.12304413e-04, 1.57503833e-04,\n",
      "       1.74740315e-04, 1.23840728e-04, 9.72784546e-05, 1.77729540e-04,\n",
      "       1.82683667e-04, 1.88678227e-04, 1.23556660e-04, 1.65774632e-04,\n",
      "       1.76183021e-04, 1.44579884e-04, 1.98902126e-04, 1.35865514e-04,\n",
      "       1.48615218e-04, 1.48695224e-04, 7.96636668e-05, 1.81330557e-04,\n",
      "       2.26328222e-04, 3.30664829e-04, 1.05482606e-04, 1.75619803e-04,\n",
      "       1.49159241e-04, 1.31435329e-04, 2.05338860e-04, 1.68082479e-04,\n",
      "       2.01532559e-04, 1.13036462e-04, 1.80515519e-04, 1.49421787e-04,\n",
      "       2.37391738e-04, 2.31206490e-04, 1.98328518e-04, 1.03943908e-04,\n",
      "       2.09121325e-04, 1.37821917e-04, 2.63256748e-04, 1.25894847e-04,\n",
      "       1.06567270e-04, 2.10875602e-04, 2.57243548e-04, 1.63257690e-04,\n",
      "       1.37122639e-04, 2.14069543e-04, 1.56725611e-04, 2.06707467e-04,\n",
      "       2.01334464e-04, 2.30445803e-04, 2.29095036e-04, 1.69952400e-04,\n",
      "       1.68942177e-04, 2.01951130e-04, 1.79635172e-04, 2.22239032e-04,\n",
      "       1.43544341e-04, 1.04168321e-04, 1.98807204e-04, 2.16505548e-04,\n",
      "       1.26378654e-04, 1.17771975e-04, 1.40807184e-04, 1.56985101e-04,\n",
      "       1.89709011e-04, 1.52912704e-04, 2.23833878e-04, 1.19203032e-04,\n",
      "       1.69356528e-04, 1.65601712e-04, 1.28353015e-04, 2.71540543e-04,\n",
      "       1.78556613e-04, 1.27846652e-04, 2.44476192e-04, 1.65453006e-04,\n",
      "       2.17997425e-04, 8.97998980e-05, 2.65778915e-04, 1.30606582e-04,\n",
      "       8.58740896e-05, 1.95576256e-04, 1.23436679e-04, 2.06229641e-04,\n",
      "       1.78181508e-04, 8.64258982e-05, 2.15542343e-04, 2.25446900e-04,\n",
      "       1.80939343e-04, 1.97944202e-04, 1.38044183e-04, 8.15380190e-05,\n",
      "       2.06249999e-04, 1.13194284e-04, 8.76499907e-05, 1.89609331e-04,\n",
      "       1.46536142e-04, 2.41810572e-04, 8.43886446e-05, 1.29604974e-04,\n",
      "       2.02878902e-04, 1.84766977e-04, 2.03970776e-04, 1.96672889e-04,\n",
      "       2.57994921e-04, 2.74865481e-04, 2.18988542e-04, 1.60011943e-04,\n",
      "       1.74460089e-04, 8.09707999e-05, 2.10466387e-04, 2.03505449e-04,\n",
      "       2.18885194e-04, 1.25963328e-04, 1.16956457e-04, 2.27863275e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer16/sepconv/Relu6;tower0/network/layer16/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer16/sepconv/depthwise,\n",
      "index: 80,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer17/conv/Conv2D,\n",
      "index: 81,\n",
      "shape: [512   1   1 512],\n",
      "shape_signature: [512   1   1 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00147609, 0.00155409, 0.00126583, 0.00163998, 0.00152879,\n",
      "       0.00144054, 0.00144981, 0.00110917, 0.00207016, 0.00118755,\n",
      "       0.00137263, 0.00164914, 0.0015627 , 0.00129343, 0.00160847,\n",
      "       0.00143607, 0.00136196, 0.00144251, 0.0014862 , 0.00133537,\n",
      "       0.00171199, 0.00164321, 0.00140677, 0.00177006, 0.00093433,\n",
      "       0.00159457, 0.00162793, 0.00143063, 0.0013405 , 0.00142309,\n",
      "       0.00143904, 0.00166125, 0.00145558, 0.00139628, 0.00103826,\n",
      "       0.00111777, 0.00131572, 0.00183159, 0.00135035, 0.00147618,\n",
      "       0.00142729, 0.00119597, 0.00149051, 0.00156808, 0.00154437,\n",
      "       0.00153318, 0.00141654, 0.00142188, 0.00142382, 0.00165734,\n",
      "       0.0013159 , 0.0016756 , 0.00157905, 0.00196984, 0.00158565,\n",
      "       0.00167775, 0.00206952, 0.00159722, 0.00198156, 0.00139023,\n",
      "       0.00152941, 0.00142526, 0.00144595, 0.00201976, 0.00172308,\n",
      "       0.00108151, 0.00111334, 0.00174869, 0.00135843, 0.00175947,\n",
      "       0.00155015, 0.00191922, 0.00148562, 0.00147421, 0.00156923,\n",
      "       0.00121832, 0.00129286, 0.00161979, 0.00135395, 0.00120783,\n",
      "       0.00131112, 0.00128588, 0.00153221, 0.00181103, 0.00203387,\n",
      "       0.00157828, 0.00130246, 0.00172482, 0.00162559, 0.00145122,\n",
      "       0.00156626, 0.00143824, 0.00147347, 0.00190989, 0.00117151,\n",
      "       0.00118907, 0.00120162, 0.00139692, 0.00203163, 0.00167231,\n",
      "       0.00130078, 0.00122335, 0.00158189, 0.00147219, 0.00138055,\n",
      "       0.00175294, 0.00148763, 0.00166178, 0.00170664, 0.00141451,\n",
      "       0.00153399, 0.00151848, 0.00131073, 0.00146517, 0.00128956,\n",
      "       0.0015614 , 0.00114115, 0.00134373, 0.00174899, 0.00149375,\n",
      "       0.00182167, 0.00148441, 0.00140479, 0.00149487, 0.00123822,\n",
      "       0.00123776, 0.00144165, 0.00101347, 0.00136322, 0.00156533,\n",
      "       0.00142449, 0.00182791, 0.00144074, 0.00187523, 0.00180269,\n",
      "       0.00124724, 0.00147689, 0.00144641, 0.00147527, 0.00135777,\n",
      "       0.00140029, 0.00103212, 0.00110137, 0.0013986 , 0.00153303,\n",
      "       0.00155623, 0.00156965, 0.00169551, 0.00145248, 0.00113303,\n",
      "       0.00173931, 0.00150907, 0.00171189, 0.00146367, 0.00147397,\n",
      "       0.00118026, 0.00157178, 0.00146018, 0.00169534, 0.00111702,\n",
      "       0.00163993, 0.00134774, 0.00158294, 0.00190312, 0.00125392,\n",
      "       0.00159496, 0.00112705, 0.00129233, 0.00110495, 0.00144481,\n",
      "       0.00146325, 0.00227196, 0.00178039, 0.00158702, 0.00163767,\n",
      "       0.00184237, 0.00149028, 0.00168545, 0.00125228, 0.00166803,\n",
      "       0.0012772 , 0.00120567, 0.00146712, 0.00199176, 0.00166865,\n",
      "       0.0017861 , 0.00124335, 0.00147524, 0.00146701, 0.00174383,\n",
      "       0.00172856, 0.00125093, 0.00117416, 0.001294  , 0.00169546,\n",
      "       0.00163486, 0.00155508, 0.00121469, 0.00131247, 0.00150161,\n",
      "       0.00154589, 0.00145093, 0.00142677, 0.0015    , 0.00132441,\n",
      "       0.00118354, 0.00142613, 0.00171328, 0.00143262, 0.00137988,\n",
      "       0.00163548, 0.00147758, 0.00196435, 0.00126288, 0.00168153,\n",
      "       0.00183013, 0.00127693, 0.00138144, 0.00155912, 0.00153701,\n",
      "       0.00165596, 0.00139389, 0.00159654, 0.00161516, 0.00178446,\n",
      "       0.00155881, 0.00144537, 0.00115916, 0.00153293, 0.00139775,\n",
      "       0.00119488, 0.0012043 , 0.00096596, 0.00106904, 0.00116906,\n",
      "       0.00193444, 0.00169481, 0.00129244, 0.00138163, 0.00140095,\n",
      "       0.00126596, 0.00170324, 0.00173046, 0.00222213, 0.00189427,\n",
      "       0.00129286, 0.00119408, 0.00183905, 0.00174459, 0.00159181,\n",
      "       0.00146407, 0.00152974, 0.00142714, 0.00164195, 0.00126366,\n",
      "       0.00159107, 0.00142552, 0.00152302, 0.00112575, 0.00152513,\n",
      "       0.0014262 , 0.00140291, 0.00153603, 0.0016182 , 0.00149762,\n",
      "       0.00127625, 0.00145254, 0.00161482, 0.00152749, 0.00139155,\n",
      "       0.0013795 , 0.0025777 , 0.00183079, 0.00151723, 0.00134732,\n",
      "       0.00148179, 0.00122351, 0.00159859, 0.00155913, 0.00125518,\n",
      "       0.00140329, 0.00146914, 0.00147908, 0.00143595, 0.00175453,\n",
      "       0.00190874, 0.00137561, 0.00174244, 0.00176795, 0.00113948,\n",
      "       0.00145703, 0.00141901, 0.00172411, 0.00143866, 0.00150116,\n",
      "       0.00139581, 0.00128325, 0.00136437, 0.00143179, 0.00133529,\n",
      "       0.00152102, 0.00111557, 0.00143997, 0.00141854, 0.00238716,\n",
      "       0.00133409, 0.00130513, 0.00185716, 0.0014892 , 0.00133844,\n",
      "       0.00210303, 0.00134665, 0.00137973, 0.00172572, 0.00141602,\n",
      "       0.0020082 , 0.00196127, 0.00116364, 0.00146994, 0.00146512,\n",
      "       0.0013759 , 0.00204936, 0.00111199, 0.00160741, 0.00113772,\n",
      "       0.00184462, 0.00158858, 0.00147932, 0.00150385, 0.00156665,\n",
      "       0.00114184, 0.00126217, 0.00177899, 0.00159842, 0.00129864,\n",
      "       0.00110402, 0.00149376, 0.00200268, 0.00192869, 0.00160785,\n",
      "       0.00202181, 0.00126763, 0.00184276, 0.001371  , 0.00149539,\n",
      "       0.00129932, 0.00166847, 0.00148467, 0.00150644, 0.00161097,\n",
      "       0.00152733, 0.00163908, 0.00135875, 0.00181248, 0.00163246,\n",
      "       0.00106489, 0.00121458, 0.00159076, 0.00131598, 0.00184222,\n",
      "       0.00176554, 0.00122887, 0.00097578, 0.00134778, 0.00136821,\n",
      "       0.00228214, 0.00117181, 0.00129993, 0.00157007, 0.00160117,\n",
      "       0.00146969, 0.00111891, 0.00142221, 0.0013654 , 0.00154452,\n",
      "       0.00141846, 0.00137147, 0.00172233, 0.00135863, 0.00146542,\n",
      "       0.00248829, 0.00153594, 0.00182636, 0.00191774, 0.00153268,\n",
      "       0.00155831, 0.00177175, 0.00142732, 0.00143489, 0.0014268 ,\n",
      "       0.0015152 , 0.00158125, 0.00143544, 0.0013487 , 0.00164523,\n",
      "       0.0011853 , 0.0017227 , 0.00208933, 0.00138504, 0.00249937,\n",
      "       0.0012256 , 0.0016664 , 0.00155671, 0.00154396, 0.00175113,\n",
      "       0.00162113, 0.001281  , 0.00218715, 0.00124417, 0.00173275,\n",
      "       0.00172878, 0.00131137, 0.00131478, 0.00137721, 0.00142636,\n",
      "       0.00117808, 0.00181542, 0.00224704, 0.00147434, 0.00134282,\n",
      "       0.00135831, 0.00171523, 0.00140848, 0.00109068, 0.00176376,\n",
      "       0.00149452, 0.00141501, 0.0017582 , 0.00112863, 0.00114952,\n",
      "       0.0016143 , 0.00129541, 0.00139111, 0.00143158, 0.00150498,\n",
      "       0.00156715, 0.00121296, 0.00125222, 0.00254381, 0.00179515,\n",
      "       0.00162149, 0.00154407, 0.00149122, 0.00157744, 0.00136812,\n",
      "       0.00170582, 0.00174866, 0.00144513, 0.00174974, 0.0013376 ,\n",
      "       0.00137882, 0.00155173, 0.00130123, 0.00159747, 0.00134976,\n",
      "       0.0015328 , 0.00105741, 0.00137831, 0.00151903, 0.00163915,\n",
      "       0.00143752, 0.00128713, 0.00150165, 0.00130233, 0.00213635,\n",
      "       0.00132176, 0.00157308, 0.00170775, 0.00143822, 0.00195344,\n",
      "       0.00182552, 0.00164266, 0.00128348, 0.00213263, 0.00134785,\n",
      "       0.00118927, 0.00129684, 0.00183   , 0.00171688, 0.00165182,\n",
      "       0.00153777, 0.00137208, 0.0014853 , 0.00178233, 0.00125927,\n",
      "       0.00143881, 0.00141156, 0.00237287, 0.00113496, 0.0012046 ,\n",
      "       0.00158932, 0.00158248, 0.00145766, 0.00212707, 0.00173912,\n",
      "       0.00140474, 0.00157892, 0.00143191, 0.00128948, 0.00118073,\n",
      "       0.00155228, 0.00130477, 0.00182059, 0.00180828, 0.0012755 ,\n",
      "       0.00132898, 0.00107604, 0.00145527, 0.001505  , 0.00145974,\n",
      "       0.00132482, 0.00141734], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer17/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 82,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([3.4731511e-05, 3.6566740e-05, 2.9784333e-05, 3.8587761e-05,\n",
      "       3.5971512e-05, 3.3895096e-05, 3.4113211e-05, 2.6098203e-05,\n",
      "       4.8709684e-05, 2.7942286e-05, 3.2297266e-05, 3.8803348e-05,\n",
      "       3.6769488e-05, 3.0433752e-05, 3.7846370e-05, 3.3789980e-05,\n",
      "       3.2046151e-05, 3.3941415e-05, 3.4969475e-05, 3.1420506e-05,\n",
      "       4.0282081e-05, 3.8663722e-05, 3.3100365e-05, 4.1648567e-05,\n",
      "       2.1984213e-05, 3.7519236e-05, 3.8304188e-05, 3.3661996e-05,\n",
      "       3.1541265e-05, 3.3484499e-05, 3.3859833e-05, 3.9088325e-05,\n",
      "       3.4248864e-05, 3.2853677e-05, 2.4429723e-05, 2.6300424e-05,\n",
      "       3.0958083e-05, 4.3096348e-05, 3.1772874e-05, 3.4733570e-05,\n",
      "       3.3583401e-05, 2.8140501e-05, 3.5070712e-05, 3.6896014e-05,\n",
      "       3.6338133e-05, 3.6074744e-05, 3.3330281e-05, 3.3455988e-05,\n",
      "       3.3501732e-05, 3.8996186e-05, 3.0962416e-05, 3.9425842e-05,\n",
      "       3.7154121e-05, 4.6349076e-05, 3.7309397e-05, 3.9476567e-05,\n",
      "       4.8694488e-05, 3.7581707e-05, 4.6625057e-05, 3.2711254e-05,\n",
      "       3.5986155e-05, 3.3535449e-05, 3.4022381e-05, 4.7523765e-05,\n",
      "       4.0543047e-05, 2.5447300e-05, 2.6196212e-05, 4.1145649e-05,\n",
      "       3.1962998e-05, 4.1399206e-05, 3.6474099e-05, 4.5158235e-05,\n",
      "       3.4955745e-05, 3.4687338e-05, 3.6923022e-05, 2.8666469e-05,\n",
      "       3.0420291e-05, 3.8112710e-05, 3.1857737e-05, 2.8419601e-05,\n",
      "       3.0849769e-05, 3.0256102e-05, 3.6051948e-05, 4.2612392e-05,\n",
      "       4.7855759e-05, 3.7135942e-05, 3.0646126e-05, 4.0584095e-05,\n",
      "       3.8249127e-05, 3.4146251e-05, 3.6853151e-05, 3.3841021e-05,\n",
      "       3.4669909e-05, 4.4938624e-05, 2.7564965e-05, 2.7978158e-05,\n",
      "       2.8273429e-05, 3.2868771e-05, 4.7803096e-05, 3.9348532e-05,\n",
      "       3.0606694e-05, 2.8784791e-05, 3.7220998e-05, 3.4639786e-05,\n",
      "       3.2483425e-05, 4.1245545e-05, 3.5003046e-05, 3.9100603e-05,\n",
      "       4.0156334e-05, 3.3282486e-05, 3.6093970e-05, 3.5728870e-05,\n",
      "       3.0840703e-05, 3.4474688e-05, 3.0342560e-05, 3.6738795e-05,\n",
      "       2.6850566e-05, 3.1617077e-05, 4.1152758e-05, 3.5146946e-05,\n",
      "       4.2862761e-05, 3.4927292e-05, 3.3053813e-05, 3.5173387e-05,\n",
      "       2.9134491e-05, 2.9123858e-05, 3.3921264e-05, 2.3846243e-05,\n",
      "       3.2075845e-05, 3.6831210e-05, 3.3517375e-05, 4.3009761e-05,\n",
      "       3.3899680e-05, 4.4123175e-05, 4.2416312e-05, 2.9346709e-05,\n",
      "       3.4750359e-05, 3.4033226e-05, 3.4712131e-05, 3.1947584e-05,\n",
      "       3.2948057e-05, 2.4285220e-05, 2.5914627e-05, 3.2908156e-05,\n",
      "       3.6071197e-05, 3.6617272e-05, 3.6933001e-05, 3.9894239e-05,\n",
      "       3.4175922e-05, 2.6659567e-05, 4.0925017e-05, 3.5507495e-05,\n",
      "       4.0279836e-05, 3.4439297e-05, 3.4681751e-05, 2.7770793e-05,\n",
      "       3.6982958e-05, 3.4357141e-05, 3.9890263e-05, 2.6282863e-05,\n",
      "       3.8586699e-05, 3.1711428e-05, 3.7245663e-05, 4.4779277e-05,\n",
      "       2.9503888e-05, 3.7528458e-05, 2.6518766e-05, 3.0407726e-05,\n",
      "       2.5998881e-05, 3.3995519e-05, 3.4429453e-05, 5.3457839e-05,\n",
      "       4.1891479e-05, 3.7341721e-05, 3.8533501e-05, 4.3349941e-05,\n",
      "       3.5065346e-05, 3.9657712e-05, 2.9465486e-05, 3.9247851e-05,\n",
      "       3.0051808e-05, 2.8368604e-05, 3.4520355e-05, 4.6864941e-05,\n",
      "       3.9262308e-05, 4.2025793e-05, 2.9255387e-05, 3.4711440e-05,\n",
      "       3.4517860e-05, 4.1031297e-05, 4.0672065e-05, 2.9433668e-05,\n",
      "       2.7627260e-05, 3.0446952e-05, 3.9893279e-05, 3.8467300e-05,\n",
      "       3.6590198e-05, 2.8580836e-05, 3.0881587e-05, 3.5331981e-05,\n",
      "       3.6373898e-05, 3.4139550e-05, 3.3571083e-05, 3.5294113e-05,\n",
      "       3.1162555e-05, 2.7847898e-05, 3.3556007e-05, 4.0312418e-05,\n",
      "       3.3708722e-05, 3.2467789e-05, 3.8481841e-05, 3.4766505e-05,\n",
      "       4.6219931e-05, 2.9714805e-05, 3.9565468e-05, 4.3061878e-05,\n",
      "       3.0045503e-05, 3.2504486e-05, 3.6685113e-05, 3.6164893e-05,\n",
      "       3.8963728e-05, 3.2797310e-05, 3.7565664e-05, 3.8003753e-05,\n",
      "       4.1987216e-05, 3.6677866e-05, 3.4008590e-05, 2.7274442e-05,\n",
      "       3.6069046e-05, 3.2888347e-05, 2.8114720e-05, 2.8336462e-05,\n",
      "       2.2728389e-05, 2.5153935e-05, 2.7507398e-05, 4.5516237e-05,\n",
      "       3.9877774e-05, 3.0410247e-05, 3.2508986e-05, 3.2963486e-05,\n",
      "       2.9787187e-05, 4.0076142e-05, 4.0716623e-05, 5.2285421e-05,\n",
      "       4.4571058e-05, 3.0420277e-05, 2.8095927e-05, 4.3271652e-05,\n",
      "       4.1049072e-05, 3.7454356e-05, 3.4448589e-05, 3.5993984e-05,\n",
      "       3.3579719e-05, 3.8634229e-05, 2.9733170e-05, 3.7436832e-05,\n",
      "       3.3541590e-05, 3.5835783e-05, 2.6488140e-05, 3.5885525e-05,\n",
      "       3.3557539e-05, 3.3009652e-05, 3.6141864e-05, 3.8075334e-05,\n",
      "       3.5238168e-05, 3.0029450e-05, 3.4177316e-05, 3.7995673e-05,\n",
      "       3.5940862e-05, 3.2742406e-05, 3.2458720e-05, 6.0651688e-05,\n",
      "       4.3077391e-05, 3.5699497e-05, 3.1701547e-05, 3.4865578e-05,\n",
      "       2.8788529e-05, 3.7613831e-05, 3.6685338e-05, 2.9533760e-05,\n",
      "       3.3018616e-05, 3.4568107e-05, 3.4801884e-05, 3.3786957e-05,\n",
      "       4.1283078e-05, 4.4911500e-05, 3.2367236e-05, 4.0998584e-05,\n",
      "       4.1598727e-05, 2.6811320e-05, 3.4283123e-05, 3.3388431e-05,\n",
      "       4.0567214e-05, 3.3850716e-05, 3.5321344e-05, 3.2842676e-05,\n",
      "       3.0194122e-05, 3.2102733e-05, 3.3689070e-05, 3.1418527e-05,\n",
      "       3.5788806e-05, 2.6248788e-05, 3.3881657e-05, 3.3377310e-05,\n",
      "       5.6168563e-05, 3.1390377e-05, 3.0709052e-05, 4.3697797e-05,\n",
      "       3.5040004e-05, 3.1492764e-05, 4.9483093e-05, 3.1685839e-05,\n",
      "       3.2464330e-05, 4.0605231e-05, 3.3318105e-05, 4.7251666e-05,\n",
      "       4.6147517e-05, 2.7379698e-05, 3.4586879e-05, 3.4473433e-05,\n",
      "       3.2374021e-05, 4.8220263e-05, 2.6164495e-05, 3.7821297e-05,\n",
      "       2.6769778e-05, 4.3402793e-05, 3.7378468e-05, 3.4807479e-05,\n",
      "       3.5384717e-05, 3.6862311e-05, 2.6866803e-05, 2.9698131e-05,\n",
      "       4.1858697e-05, 3.7609887e-05, 3.0556290e-05, 2.5976984e-05,\n",
      "       3.5147390e-05, 4.7121768e-05, 4.5380904e-05, 3.7831818e-05,\n",
      "       4.7572041e-05, 2.9826529e-05, 4.3358941e-05, 3.2258711e-05,\n",
      "       3.5185731e-05, 3.0572119e-05, 3.9258048e-05, 3.4933517e-05,\n",
      "       3.5445664e-05, 3.7905138e-05, 3.5937173e-05, 3.8566664e-05,\n",
      "       3.1970616e-05, 4.2646505e-05, 3.8410821e-05, 2.5056286e-05,\n",
      "       2.8578293e-05, 3.7429731e-05, 3.0964289e-05, 4.3346332e-05,\n",
      "       4.1542091e-05, 2.8914674e-05, 2.2959528e-05, 3.1712429e-05,\n",
      "       3.2193097e-05, 5.3697328e-05, 2.7571885e-05, 3.0586583e-05,\n",
      "       3.6942794e-05, 3.7674687e-05, 3.4581055e-05, 2.6327178e-05,\n",
      "       3.3463813e-05, 3.2127071e-05, 3.6341695e-05, 3.3375549e-05,\n",
      "       3.2269807e-05, 4.0525443e-05, 3.1967666e-05, 3.4480476e-05,\n",
      "       5.8547896e-05, 3.6139856e-05, 4.2973115e-05, 4.5123412e-05,\n",
      "       3.6063117e-05, 3.6666126e-05, 4.1688334e-05, 3.3584009e-05,\n",
      "       3.3762171e-05, 3.3571658e-05, 3.5651734e-05, 3.7205780e-05,\n",
      "       3.3775028e-05, 3.1734144e-05, 3.8711361e-05, 2.7889468e-05,\n",
      "       4.0534091e-05, 4.9160739e-05, 3.2589087e-05, 5.8808673e-05,\n",
      "       2.8837589e-05, 3.9209444e-05, 3.6628571e-05, 3.6328405e-05,\n",
      "       4.1202999e-05, 3.8144135e-05, 3.0141107e-05, 5.1462379e-05,\n",
      "       2.9274608e-05, 4.0770658e-05, 4.0677089e-05, 3.0855768e-05,\n",
      "       3.0935927e-05, 3.2405056e-05, 3.3561508e-05, 2.7719552e-05,\n",
      "       4.2715707e-05, 5.2871601e-05, 3.4690420e-05, 3.1595733e-05,\n",
      "       3.1960160e-05, 4.0358249e-05, 3.3140619e-05, 2.5663016e-05,\n",
      "       4.1500141e-05, 3.5165212e-05, 3.3294356e-05, 4.1369494e-05,\n",
      "       2.6556103e-05, 2.7047539e-05, 3.7983456e-05, 3.0480205e-05,\n",
      "       3.2731976e-05, 3.3684260e-05, 3.5411256e-05, 3.6874215e-05,\n",
      "       2.8540197e-05, 2.9463976e-05, 5.9854334e-05, 4.2238920e-05,\n",
      "       3.8152783e-05, 3.6331166e-05, 3.5087574e-05, 3.7116217e-05,\n",
      "       3.2191059e-05, 4.0136907e-05, 4.1145027e-05, 3.4002995e-05,\n",
      "       4.1170275e-05, 3.1472919e-05, 3.2442931e-05, 3.6511254e-05,\n",
      "       3.0617248e-05, 3.7587623e-05, 3.1759027e-05, 3.6065841e-05,\n",
      "       2.4880348e-05, 3.2430755e-05, 3.5741952e-05, 3.8568254e-05,\n",
      "       3.3823977e-05, 3.0285444e-05, 3.5332923e-05, 3.0643096e-05,\n",
      "       5.0267015e-05, 3.1100135e-05, 3.7013720e-05, 4.0182422e-05,\n",
      "       3.3840464e-05, 4.5963345e-05, 4.2953438e-05, 3.8650873e-05,\n",
      "       3.0199437e-05, 5.0179569e-05, 3.1714058e-05, 2.7982793e-05,\n",
      "       3.0513902e-05, 4.3058877e-05, 4.0397150e-05, 3.8866390e-05,\n",
      "       3.6182864e-05, 3.2284333e-05, 3.4948280e-05, 4.1937077e-05,\n",
      "       2.9629984e-05, 3.3854314e-05, 3.3213073e-05, 5.5832352e-05,\n",
      "       2.6704987e-05, 2.8343511e-05, 3.7395694e-05, 3.7234913e-05,\n",
      "       3.4297984e-05, 5.0048657e-05, 4.0920517e-05, 3.3052642e-05,\n",
      "       3.7151043e-05, 3.3691966e-05, 3.0340654e-05, 2.7781996e-05,\n",
      "       3.6524161e-05, 3.0700452e-05, 4.2837357e-05, 4.2547796e-05,\n",
      "       3.0011859e-05, 3.1270090e-05, 2.5318697e-05, 3.4241591e-05,\n",
      "       3.5411744e-05, 3.4346740e-05, 3.1172171e-05, 3.3349184e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer17/conv/Relu6;tower0/network/layer17/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer17/conv/Conv2D,\n",
      "index: 83,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer18/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer18/sepconv/depthwise;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 84,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00736901, 0.00598102, 0.00573156, 0.00784232, 0.00613477,\n",
      "       0.00806268, 0.00670422, 0.00790146, 0.00695995, 0.00467776,\n",
      "       0.00648515, 0.00356657, 0.00606407, 0.00431847, 0.00917276,\n",
      "       0.00427971, 0.00527349, 0.00395185, 0.00444191, 0.00534146,\n",
      "       0.01021251, 0.00877407, 0.00697715, 0.00558345, 0.00651095,\n",
      "       0.00833906, 0.00531991, 0.00490898, 0.0059101 , 0.00713438,\n",
      "       0.0048635 , 0.00636839, 0.00634709, 0.00785731, 0.01071648,\n",
      "       0.00982215, 0.00421819, 0.00710475, 0.0035083 , 0.00516082,\n",
      "       0.00546839, 0.00385049, 0.00587115, 0.00963824, 0.00611798,\n",
      "       0.00671911, 0.005443  , 0.01111144, 0.00727424, 0.00633442,\n",
      "       0.00680226, 0.00532231, 0.00380119, 0.00772857, 0.00750638,\n",
      "       0.00566528, 0.00646753, 0.00558595, 0.01420715, 0.00812807,\n",
      "       0.00582839, 0.0058183 , 0.00472301, 0.00792186, 0.00449684,\n",
      "       0.00481101, 0.00019838, 0.0054645 , 0.0056104 , 0.00585771,\n",
      "       0.00405009, 0.0075246 , 0.00473259, 0.00494297, 0.0084128 ,\n",
      "       0.00497613, 0.00668847, 0.00862791, 0.00425845, 0.01348669,\n",
      "       0.0053023 , 0.00548008, 0.00460586, 0.01222283, 0.00608112,\n",
      "       0.00503126, 0.00600182, 0.00813072, 0.00642142, 0.00643056,\n",
      "       0.00596966, 0.00478356, 0.01075596, 0.0080048 , 0.01078592,\n",
      "       0.00920823, 0.00439108, 0.00537152, 0.00565528, 0.0065198 ,\n",
      "       0.00518966, 0.00552626, 0.00746328, 0.00927126, 0.00442582,\n",
      "       0.00499674, 0.0043306 , 0.00479106, 0.00765012, 0.00789201,\n",
      "       0.00728088, 0.0067157 , 0.00503882, 0.00852556, 0.00990756,\n",
      "       0.00705689, 0.00536486, 0.00566667, 0.00969019, 0.00716192,\n",
      "       0.00623767, 0.0075702 , 0.00832938, 0.00796822, 0.00778041,\n",
      "       0.00713828, 0.00949116, 0.00620597, 0.00662553, 0.00462134,\n",
      "       0.00803868, 0.00668349, 0.00650051, 0.00639419, 0.00598081,\n",
      "       0.0056751 , 0.00441807, 0.00662496, 0.00644159, 0.00507179,\n",
      "       0.00670965, 0.00771697, 0.00734539, 0.00629706, 0.01182228,\n",
      "       0.0069734 , 0.00625126, 0.00502064, 0.00931923, 0.00502481,\n",
      "       0.0048967 , 0.00531117, 0.00646275, 0.0045    , 0.00694834,\n",
      "       0.00425491, 0.00588901, 0.00520742, 0.00610568, 0.00028017,\n",
      "       0.00460156, 0.00616895, 0.00532693, 0.00800316, 0.00392184,\n",
      "       0.0053494 , 0.00457077, 0.00772262, 0.00435357, 0.00771451,\n",
      "       0.00721401, 0.00647403, 0.00567954, 0.00769649, 0.00852458,\n",
      "       0.00816463, 0.00870304, 0.00620795, 0.00434009, 0.00451651,\n",
      "       0.01193554, 0.00920869, 0.01411889, 0.01396445, 0.00480203,\n",
      "       0.00521826, 0.00684746, 0.00840709, 0.00899511, 0.01061723,\n",
      "       0.00721098, 0.00481778, 0.0062592 , 0.0059222 , 0.00472364,\n",
      "       0.00939329, 0.00541783, 0.00543752, 0.00533645, 0.0064903 ,\n",
      "       0.00981066, 0.0062869 , 0.00531464, 0.00648916, 0.00503039,\n",
      "       0.00539635, 0.00768315, 0.00671662, 0.00887104, 0.00691209,\n",
      "       0.00611055, 0.00706421, 0.00906325, 0.00434177, 0.01055698,\n",
      "       0.00766589, 0.0101982 , 0.00919226, 0.00623639, 0.00672728,\n",
      "       0.00722576, 0.0058198 , 0.00523821, 0.00442495, 0.00683962,\n",
      "       0.00556895, 0.00564758, 0.00433195, 0.00438097, 0.00642837,\n",
      "       0.00555546, 0.00628317, 0.01101014, 0.00563104, 0.00600314,\n",
      "       0.0058022 , 0.00955413, 0.01552195, 0.00466321, 0.00812037,\n",
      "       0.00932446, 0.0084724 , 0.00787557, 0.0104623 , 0.00574533,\n",
      "       0.01107591, 0.0048647 , 0.00977604, 0.00440793, 0.00766756,\n",
      "       0.00449652, 0.00929546, 0.00785149, 0.0094895 , 0.00933289,\n",
      "       0.00967925, 0.00630581, 0.00821229, 0.0092593 , 0.00499178,\n",
      "       0.00644067, 0.01171415, 0.00723524, 0.00779123, 0.00860711,\n",
      "       0.00407926, 0.00884862, 0.00633347, 0.01213746, 0.00660333,\n",
      "       0.00681142, 0.00714047, 0.01203327, 0.00472056, 0.00908969,\n",
      "       0.00764013, 0.00417724, 0.00714118, 0.00592221, 0.00694426,\n",
      "       0.0053717 , 0.00543642, 0.00419153, 0.00360969, 0.00465962,\n",
      "       0.0061672 , 0.0073987 , 0.00496333, 0.00667951, 0.00912382,\n",
      "       0.00487562, 0.00471685, 0.00720981, 0.00477706, 0.00707798,\n",
      "       0.00617171, 0.00423562, 0.00610717, 0.00917786, 0.00462141,\n",
      "       0.00539199, 0.0131553 , 0.00417363, 0.00575118, 0.00336169,\n",
      "       0.01135117, 0.00608102, 0.00802702, 0.00397186, 0.00972871,\n",
      "       0.00724899, 0.00516079, 0.00749297, 0.00915645, 0.00873762,\n",
      "       0.00827826, 0.00552559, 0.00424288, 0.00923705, 0.00947732,\n",
      "       0.00400449, 0.00477263, 0.00968468, 0.00655502, 0.0085557 ,\n",
      "       0.00424584, 0.00696571, 0.00820951, 0.00542117, 0.00516737,\n",
      "       0.00603373, 0.00883816, 0.00530561, 0.00623479, 0.00705878,\n",
      "       0.00621814, 0.00651447, 0.0055831 , 0.0058371 , 0.00620008,\n",
      "       0.00583168, 0.00571696, 0.00635262, 0.00679497, 0.00892643,\n",
      "       0.00561946, 0.00734076, 0.00720297, 0.00562403, 0.01038134,\n",
      "       0.00452774, 0.00848239, 0.01157604, 0.00472973, 0.00500227,\n",
      "       0.00476111, 0.00840143, 0.00665029, 0.00511689, 0.00641278,\n",
      "       0.00561152, 0.00407711, 0.00781875, 0.00564825, 0.00636818,\n",
      "       0.00579159, 0.01368943, 0.00491275, 0.00822357, 0.00757345,\n",
      "       0.00668334, 0.00486938, 0.00790083, 0.00500383, 0.01049957,\n",
      "       0.00734502, 0.00990095, 0.00677585, 0.00689306, 0.00583833,\n",
      "       0.00664813, 0.00403271, 0.0075142 , 0.00728315, 0.00760025,\n",
      "       0.00785799, 0.00651452, 0.00720508, 0.00821048, 0.00471418,\n",
      "       0.00486184, 0.00807625, 0.0049601 , 0.00631717, 0.00619819,\n",
      "       0.00832417, 0.00725559, 0.00587806, 0.00472093, 0.00475007,\n",
      "       0.00483469, 0.00681885, 0.00733355, 0.00548374, 0.00642998,\n",
      "       0.00800075, 0.00769805, 0.00458003, 0.00737126, 0.00542862,\n",
      "       0.00803772, 0.01000587, 0.0058862 , 0.00391544, 0.00594623,\n",
      "       0.00795696, 0.00491778, 0.00612725, 0.00451456, 0.00664796,\n",
      "       0.0049059 , 0.00711848, 0.00350033, 0.00436273, 0.01150082,\n",
      "       0.00527974, 0.0068887 , 0.004719  , 0.00498466, 0.00489945,\n",
      "       0.00640689, 0.00597978, 0.00712089, 0.00605041, 0.00433979,\n",
      "       0.00552011, 0.00791761, 0.00703492, 0.00624677, 0.00626077,\n",
      "       0.00596211, 0.00595983, 0.00920003, 0.00684926, 0.00506224,\n",
      "       0.00950074, 0.00665172, 0.00635572, 0.00635013, 0.00697935,\n",
      "       0.00540497, 0.00562498, 0.00504615, 0.00528552, 0.00856044,\n",
      "       0.00703822, 0.01286872, 0.00846902, 0.00528225, 0.00740658,\n",
      "       0.0057609 , 0.00880289, 0.00610963, 0.00454536, 0.00462683,\n",
      "       0.00743747, 0.00509116, 0.00617751, 0.00822303, 0.00413966,\n",
      "       0.00676122, 0.00523374, 0.00707071, 0.00652668, 0.0073157 ,\n",
      "       0.00988383, 0.00487335, 0.00915711, 0.00418451, 0.00576309,\n",
      "       0.00603333, 0.00678794, 0.00421434, 0.00603098, 0.00742409,\n",
      "       0.0065597 , 0.00588806, 0.00803802, 0.00603387, 0.00420379,\n",
      "       0.00898648, 0.00600564, 0.00544397, 0.00835389, 0.00452539,\n",
      "       0.00616857, 0.00563754, 0.0060806 , 0.00976989, 0.00794045,\n",
      "       0.00574331, 0.00748246, 0.00612298, 0.00559394, 0.00945279,\n",
      "       0.00457791, 0.00428189, 0.00719424, 0.00391696, 0.01438811,\n",
      "       0.01074939, 0.00827341], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer18/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 85,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.73388398e-04, 1.40729782e-04, 1.34860151e-04, 1.84525241e-04,\n",
      "       1.44347548e-04, 1.89710088e-04, 1.57746385e-04, 1.85916680e-04,\n",
      "       1.63763514e-04, 1.10064917e-04, 1.52591747e-04, 8.39193453e-05,\n",
      "       1.42684046e-04, 1.01611033e-04, 2.15829670e-04, 1.00699013e-04,\n",
      "       1.24082071e-04, 9.29847374e-05, 1.04515479e-04, 1.25681399e-04,\n",
      "       2.40294394e-04, 2.06448662e-04, 1.64168188e-04, 1.31375287e-04,\n",
      "       1.53198780e-04, 1.96213281e-04, 1.25174352e-04, 1.15505311e-04,\n",
      "       1.39061216e-04, 1.67867809e-04, 1.14435308e-04, 1.49844564e-04,\n",
      "       1.49343192e-04, 1.84877863e-04, 2.52152560e-04, 2.31109385e-04,\n",
      "       9.92514906e-05, 1.67170539e-04, 8.25481256e-05, 1.21430945e-04,\n",
      "       1.28667933e-04, 9.05996712e-05, 1.38144809e-04, 2.26782184e-04,\n",
      "       1.43952508e-04, 1.58096780e-04, 1.28070518e-04, 2.61445588e-04,\n",
      "       1.71158594e-04, 1.49045300e-04, 1.60053183e-04, 1.25230741e-04,\n",
      "       8.94397162e-05, 1.81848605e-04, 1.76620670e-04, 1.33300651e-04,\n",
      "       1.52177177e-04, 1.31434150e-04, 3.34285985e-04, 1.91248779e-04,\n",
      "       1.37138530e-04, 1.36901290e-04, 1.11129695e-04, 1.86396705e-04,\n",
      "       1.05807929e-04, 1.13200309e-04, 4.66778692e-06, 1.28576547e-04,\n",
      "       1.32009518e-04, 1.37828552e-04, 9.52962364e-05, 1.77049340e-04,\n",
      "       1.11355141e-04, 1.16305164e-04, 1.97948175e-04, 1.17085481e-04,\n",
      "       1.57375674e-04, 2.03009651e-04, 1.00198864e-04, 3.17333877e-04,\n",
      "       1.24760045e-04, 1.28943109e-04, 1.08373148e-04, 2.87595904e-04,\n",
      "       1.43085228e-04, 1.18382617e-04, 1.41219352e-04, 1.91311163e-04,\n",
      "       1.51092245e-04, 1.51307177e-04, 1.40462653e-04, 1.12554248e-04,\n",
      "       2.53081351e-04, 1.88348160e-04, 2.53786362e-04, 2.16664164e-04,\n",
      "       1.03319493e-04, 1.26388710e-04, 1.33065463e-04, 1.53407091e-04,\n",
      "       1.22109603e-04, 1.30029744e-04, 1.75606707e-04, 2.18147310e-04,\n",
      "       1.04136932e-04, 1.17570395e-04, 1.01896563e-04, 1.12730741e-04,\n",
      "       1.80002840e-04, 1.85694327e-04, 1.71314838e-04, 1.58016468e-04,\n",
      "       1.18560478e-04, 2.00601411e-04, 2.33119004e-04, 1.66044483e-04,\n",
      "       1.26232058e-04, 1.33333422e-04, 2.28004530e-04, 1.68515660e-04,\n",
      "       1.46768798e-04, 1.78122427e-04, 1.95985398e-04, 1.87487516e-04,\n",
      "       1.83068551e-04, 1.67959544e-04, 2.23321316e-04, 1.46022721e-04,\n",
      "       1.55894857e-04, 1.08737302e-04, 1.89145358e-04, 1.57258517e-04,\n",
      "       1.52953129e-04, 1.50451655e-04, 1.40724878e-04, 1.33531736e-04,\n",
      "       1.03954677e-04, 1.55881353e-04, 1.51566797e-04, 1.19336291e-04,\n",
      "       1.57874063e-04, 1.81575771e-04, 1.72832617e-04, 1.48166087e-04,\n",
      "       2.78171297e-04, 1.64080018e-04, 1.47088402e-04, 1.18132717e-04,\n",
      "       2.19275913e-04, 1.18230913e-04, 1.15216470e-04, 1.24968792e-04,\n",
      "       1.52064647e-04, 1.05882304e-04, 1.63490331e-04, 1.00115569e-04,\n",
      "       1.38565054e-04, 1.22527621e-04, 1.43663114e-04, 6.59226953e-06,\n",
      "       1.08272048e-04, 1.45151847e-04, 1.25339604e-04, 1.88309597e-04,\n",
      "       9.22785621e-05, 1.25868304e-04, 1.07547530e-04, 1.81708616e-04,\n",
      "       1.02436970e-04, 1.81517797e-04, 1.69741324e-04, 1.52330133e-04,\n",
      "       1.33636291e-04, 1.81093928e-04, 2.00578419e-04, 1.92108841e-04,\n",
      "       2.04777505e-04, 1.46069506e-04, 1.02119739e-04, 1.06270898e-04,\n",
      "       2.80836219e-04, 2.16675166e-04, 3.32209223e-04, 3.28575290e-04,\n",
      "       1.12988855e-04, 1.22782571e-04, 1.61116812e-04, 1.97813992e-04,\n",
      "       2.11649545e-04, 2.49817182e-04, 1.69670064e-04, 1.13359631e-04,\n",
      "       1.47275365e-04, 1.39345968e-04, 1.11144524e-04, 2.21018636e-04,\n",
      "       1.27478401e-04, 1.27941748e-04, 1.25563587e-04, 1.52712833e-04,\n",
      "       2.30839025e-04, 1.47927145e-04, 1.25050297e-04, 1.52686087e-04,\n",
      "       1.18362186e-04, 1.26972940e-04, 1.80780029e-04, 1.58038049e-04,\n",
      "       2.08730344e-04, 1.62637516e-04, 1.43777565e-04, 1.66216676e-04,\n",
      "       2.13252890e-04, 1.02159218e-04, 2.48399534e-04, 1.80373958e-04,\n",
      "       2.39957604e-04, 2.16288492e-04, 1.46738603e-04, 1.58288996e-04,\n",
      "       1.70017971e-04, 1.36936505e-04, 1.23251957e-04, 1.04116552e-04,\n",
      "       1.60932352e-04, 1.31034030e-04, 1.32884219e-04, 1.01928134e-04,\n",
      "       1.03081707e-04, 1.51255852e-04, 1.30716828e-04, 1.47839368e-04,\n",
      "       2.59062101e-04, 1.32495072e-04, 1.41250363e-04, 1.36522300e-04,\n",
      "       2.24803065e-04, 3.65222368e-04, 1.09722510e-04, 1.91067433e-04,\n",
      "       2.19399109e-04, 1.99350572e-04, 1.85307508e-04, 2.46171869e-04,\n",
      "       1.35184295e-04, 2.60609580e-04, 1.14463648e-04, 2.30024409e-04,\n",
      "       1.03715931e-04, 1.80413263e-04, 1.05800449e-04, 2.18716639e-04,\n",
      "       1.84740959e-04, 2.23282404e-04, 2.19597365e-04, 2.27747136e-04,\n",
      "       1.48371953e-04, 1.93230444e-04, 2.17865847e-04, 1.17453616e-04,\n",
      "       1.51545129e-04, 2.75627157e-04, 1.70240906e-04, 1.83323122e-04,\n",
      "       2.02520299e-04, 9.59825702e-05, 2.08202924e-04, 1.49022875e-04,\n",
      "       2.85587390e-04, 1.55372531e-04, 1.60268770e-04, 1.68011029e-04,\n",
      "       2.83135800e-04, 1.11072040e-04, 2.13875159e-04, 1.79767798e-04,\n",
      "       9.82880156e-05, 1.68027706e-04, 1.39346113e-04, 1.63394332e-04,\n",
      "       1.26393032e-04, 1.27915875e-04, 9.86242594e-05, 8.49338612e-05,\n",
      "       1.09638175e-04, 1.45110622e-04, 1.74087108e-04, 1.16784278e-04,\n",
      "       1.57165035e-04, 2.14678032e-04, 1.14720504e-04, 1.10984693e-04,\n",
      "       1.69642619e-04, 1.12401358e-04, 1.66540733e-04, 1.45216676e-04,\n",
      "       9.96616945e-05, 1.43698213e-04, 2.15949622e-04, 1.08739136e-04,\n",
      "       1.26870422e-04, 3.09536466e-04, 9.82030033e-05, 1.35321869e-04,\n",
      "       7.90985068e-05, 2.67086347e-04, 1.43082754e-04, 1.88871010e-04,\n",
      "       9.34555064e-05, 2.28910896e-04, 1.70564381e-04, 1.21430385e-04,\n",
      "       1.76305228e-04, 2.15445791e-04, 2.05591059e-04, 1.94782566e-04,\n",
      "       1.30013825e-04, 9.98325340e-05, 2.17342342e-04, 2.22995877e-04,\n",
      "       9.42233964e-05, 1.12297210e-04, 2.27874843e-04, 1.54235750e-04,\n",
      "       2.01310686e-04, 9.99022159e-05, 1.63898949e-04, 1.93164829e-04,\n",
      "       1.27556894e-04, 1.21585268e-04, 1.41970115e-04, 2.07956691e-04,\n",
      "       1.24837868e-04, 1.46701001e-04, 1.66088896e-04, 1.46309161e-04,\n",
      "       1.53281551e-04, 1.31366978e-04, 1.37343479e-04, 1.45884216e-04,\n",
      "       1.37215931e-04, 1.34516711e-04, 1.49473446e-04, 1.59881747e-04,\n",
      "       2.10033599e-04, 1.32222485e-04, 1.72723798e-04, 1.69481675e-04,\n",
      "       1.32330068e-04, 2.44266907e-04, 1.06535001e-04, 1.99585629e-04,\n",
      "       2.72377336e-04, 1.11287780e-04, 1.17700416e-04, 1.12026217e-04,\n",
      "       1.97680623e-04, 1.56477472e-04, 1.20397519e-04, 1.50889013e-04,\n",
      "       1.32035741e-04, 9.59320241e-05, 1.83970507e-04, 1.32899921e-04,\n",
      "       1.49839601e-04, 1.36272720e-04, 3.22104286e-04, 1.15594063e-04,\n",
      "       1.93495696e-04, 1.78198767e-04, 1.57254995e-04, 1.14573762e-04,\n",
      "       1.85901808e-04, 1.17737196e-04, 2.47048796e-04, 1.72824060e-04,\n",
      "       2.32963648e-04, 1.59431816e-04, 1.62189564e-04, 1.37372394e-04,\n",
      "       1.56426613e-04, 9.48872403e-05, 1.76804635e-04, 1.71368345e-04,\n",
      "       1.78829534e-04, 1.84893957e-04, 1.53282934e-04, 1.69531384e-04,\n",
      "       1.93187880e-04, 1.10921916e-04, 1.14396229e-04, 1.90029445e-04,\n",
      "       1.16708135e-04, 1.48639316e-04, 1.45839687e-04, 1.95862798e-04,\n",
      "       1.70719795e-04, 1.38307310e-04, 1.11080677e-04, 1.11766283e-04,\n",
      "       1.13757349e-04, 1.60443553e-04, 1.72554108e-04, 1.29029286e-04,\n",
      "       1.51293687e-04, 1.88252990e-04, 1.81130483e-04, 1.07765387e-04,\n",
      "       1.73441513e-04, 1.27732259e-04, 1.89122846e-04, 2.35432279e-04,\n",
      "       1.38498828e-04, 9.21279425e-05, 1.39911266e-04, 1.87222642e-04,\n",
      "       1.15712428e-04, 1.44170539e-04, 1.06224943e-04, 1.56422597e-04,\n",
      "       1.15432995e-04, 1.67493592e-04, 8.23606897e-05, 1.02652411e-04,\n",
      "       2.70607561e-04, 1.24229220e-04, 1.62087119e-04, 1.11035217e-04,\n",
      "       1.17286014e-04, 1.15281189e-04, 1.50750464e-04, 1.40700693e-04,\n",
      "       1.67550257e-04, 1.42362565e-04, 1.02112630e-04, 1.29884997e-04,\n",
      "       1.86296777e-04, 1.65527628e-04, 1.46982828e-04, 1.47312297e-04,\n",
      "       1.40284959e-04, 1.40231336e-04, 2.16471250e-04, 1.61159114e-04,\n",
      "       1.19111544e-04, 2.23546915e-04, 1.56511102e-04, 1.49546337e-04,\n",
      "       1.49414729e-04, 1.64220080e-04, 1.27175692e-04, 1.32352565e-04,\n",
      "       1.18732984e-04, 1.24365208e-04, 2.01422023e-04, 1.65605248e-04,\n",
      "       3.02793458e-04, 1.99271104e-04, 1.24288272e-04, 1.74272398e-04,\n",
      "       1.35550668e-04, 2.07126839e-04, 1.43755911e-04, 1.06949701e-04,\n",
      "       1.08866625e-04, 1.74999223e-04, 1.19791985e-04, 1.45353129e-04,\n",
      "       1.93482963e-04, 9.74036666e-05, 1.59087576e-04, 1.23146776e-04,\n",
      "       1.66369646e-04, 1.53568937e-04, 1.72134169e-04, 2.32560822e-04,\n",
      "       1.14667077e-04, 2.15461376e-04, 9.84591388e-05, 1.35602008e-04,\n",
      "       1.41960772e-04, 1.59716175e-04, 9.91609268e-05, 1.41905344e-04,\n",
      "       1.74684494e-04, 1.54345806e-04, 1.38542542e-04, 1.89129831e-04,\n",
      "       1.41973505e-04, 9.89126202e-05, 2.11446648e-04, 1.41309225e-04,\n",
      "       1.28093481e-04, 1.96562207e-04, 1.06479856e-04, 1.45142811e-04,\n",
      "       1.32647998e-04, 1.43072917e-04, 2.29879763e-04, 1.86834091e-04,\n",
      "       1.35136768e-04, 1.76057947e-04, 1.44070014e-04, 1.31622161e-04,\n",
      "       2.22418705e-04, 1.07715510e-04, 1.00750251e-04, 1.69276143e-04,\n",
      "       9.21637038e-05, 3.38543759e-04, 2.52926897e-04, 1.94668493e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer18/sepconv/Relu6;tower0/network/layer18/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer18/sepconv/depthwise,\n",
      "index: 86,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer19/conv/Conv2D,\n",
      "index: 87,\n",
      "shape: [512   1   1 512],\n",
      "shape_signature: [512   1   1 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00130061, 0.00152458, 0.00176713, 0.00197967, 0.00145319,\n",
      "       0.0011498 , 0.00130054, 0.00151666, 0.00107511, 0.00231111,\n",
      "       0.00164962, 0.00136067, 0.00142493, 0.00118386, 0.00125848,\n",
      "       0.00134641, 0.00140493, 0.00150693, 0.00111473, 0.00146603,\n",
      "       0.00162359, 0.00158177, 0.00145189, 0.00161721, 0.00149163,\n",
      "       0.0014724 , 0.00157173, 0.0014601 , 0.00150226, 0.00142993,\n",
      "       0.00164432, 0.00141779, 0.00124467, 0.00089168, 0.00129006,\n",
      "       0.0015295 , 0.00136098, 0.00136077, 0.00143033, 0.00129646,\n",
      "       0.00119752, 0.00128646, 0.00135083, 0.00155661, 0.00123449,\n",
      "       0.0013131 , 0.00204272, 0.00132023, 0.00135961, 0.00120598,\n",
      "       0.00145897, 0.00199628, 0.00128618, 0.00170757, 0.00133966,\n",
      "       0.00160808, 0.00132519, 0.00093303, 0.00147783, 0.00133488,\n",
      "       0.00162866, 0.00163783, 0.00143078, 0.00126955, 0.00142523,\n",
      "       0.00193356, 0.00160473, 0.00236229, 0.00133969, 0.00140809,\n",
      "       0.00137326, 0.00141239, 0.00136605, 0.00239293, 0.00118049,\n",
      "       0.00125163, 0.00145251, 0.00162451, 0.0013582 , 0.00135022,\n",
      "       0.00177724, 0.00147294, 0.00142758, 0.00138608, 0.00147509,\n",
      "       0.00164343, 0.0016481 , 0.00145623, 0.0018371 , 0.0014355 ,\n",
      "       0.00164156, 0.00183787, 0.00142568, 0.00109275, 0.00131401,\n",
      "       0.00133748, 0.001765  , 0.00127412, 0.00191788, 0.00113719,\n",
      "       0.00100866, 0.00148374, 0.00153311, 0.00140056, 0.00165664,\n",
      "       0.00183266, 0.00150967, 0.00139618, 0.00178864, 0.00146556,\n",
      "       0.00128083, 0.00193711, 0.0012005 , 0.00137897, 0.00101981,\n",
      "       0.00189662, 0.00110241, 0.00123739, 0.0013679 , 0.00141824,\n",
      "       0.00140298, 0.00150213, 0.00161161, 0.00147614, 0.00166695,\n",
      "       0.00174944, 0.00157016, 0.00153703, 0.00150148, 0.00128789,\n",
      "       0.00090956, 0.00168758, 0.00224775, 0.0012454 , 0.00124061,\n",
      "       0.00116319, 0.00153992, 0.00148318, 0.00164257, 0.00158425,\n",
      "       0.00116332, 0.00128542, 0.00216131, 0.00136719, 0.00126013,\n",
      "       0.00091363, 0.00139269, 0.00150298, 0.00178413, 0.00148222,\n",
      "       0.00096744, 0.00116146, 0.00129512, 0.00125276, 0.00140527,\n",
      "       0.00132137, 0.00170578, 0.00133829, 0.00122365, 0.00151521,\n",
      "       0.00091262, 0.00144122, 0.00186779, 0.00130965, 0.00158546,\n",
      "       0.00119736, 0.00175457, 0.00152429, 0.00131021, 0.00139228,\n",
      "       0.00119337, 0.00125676, 0.00158704, 0.00137909, 0.00156035,\n",
      "       0.00116234, 0.0011656 , 0.00099271, 0.00114885, 0.00171716,\n",
      "       0.00141117, 0.00178533, 0.00162653, 0.00142243, 0.00128589,\n",
      "       0.00148335, 0.0020708 , 0.00147063, 0.00328239, 0.00184135,\n",
      "       0.00178703, 0.00118808, 0.00140937, 0.00140195, 0.00142403,\n",
      "       0.00133117, 0.00174532, 0.00147361, 0.0015209 , 0.00156839,\n",
      "       0.0014211 , 0.0016703 , 0.0013497 , 0.00106337, 0.00139564,\n",
      "       0.0017046 , 0.00118254, 0.0013659 , 0.0013783 , 0.00112082,\n",
      "       0.00130382, 0.00119625, 0.00125891, 0.00092152, 0.00130752,\n",
      "       0.00161999, 0.00126112, 0.00164566, 0.00110542, 0.00145744,\n",
      "       0.00158895, 0.0012597 , 0.00132901, 0.00141822, 0.00115776,\n",
      "       0.00135844, 0.00132633, 0.00141781, 0.00170351, 0.00132073,\n",
      "       0.00159726, 0.00120438, 0.00156978, 0.00152247, 0.00109966,\n",
      "       0.00156433, 0.00224803, 0.00138155, 0.00138953, 0.00171752,\n",
      "       0.00141421, 0.0012837 , 0.00123499, 0.0015906 , 0.00156304,\n",
      "       0.00222807, 0.00144083, 0.00136117, 0.00140715, 0.00146077,\n",
      "       0.00095825, 0.00133944, 0.00124912, 0.00183265, 0.00138488,\n",
      "       0.00142992, 0.00153392, 0.00148585, 0.00195006, 0.00157579,\n",
      "       0.00128957, 0.00179324, 0.00164164, 0.00176998, 0.00131395,\n",
      "       0.00136831, 0.00140029, 0.00129239, 0.00148334, 0.00135784,\n",
      "       0.00181565, 0.00136575, 0.00143966, 0.00142875, 0.00129206,\n",
      "       0.00190291, 0.00118264, 0.00157683, 0.00137476, 0.00130703,\n",
      "       0.00166608, 0.00134099, 0.00148287, 0.00160503, 0.00061984,\n",
      "       0.00155613, 0.00147895, 0.00140528, 0.00154602, 0.00193345,\n",
      "       0.0011823 , 0.00140426, 0.00191596, 0.00121524, 0.00125173,\n",
      "       0.00147839, 0.00176989, 0.00137068, 0.00144354, 0.00110894,\n",
      "       0.00112396, 0.00152831, 0.00143413, 0.00120704, 0.00141901,\n",
      "       0.00159868, 0.00213851, 0.00200889, 0.00236178, 0.00157729,\n",
      "       0.00144719, 0.00319544, 0.00145558, 0.00133803, 0.00191424,\n",
      "       0.00101021, 0.0017527 , 0.00132096, 0.00175805, 0.00140372,\n",
      "       0.00145687, 0.00169627, 0.00117185, 0.00159538, 0.00179294,\n",
      "       0.00133083, 0.00098489, 0.00118943, 0.00148715, 0.00148209,\n",
      "       0.00153982, 0.00156177, 0.00218097, 0.00239587, 0.00102724,\n",
      "       0.00097837, 0.00218554, 0.00136718, 0.00134734, 0.00190768,\n",
      "       0.00146109, 0.00187486, 0.00156349, 0.00091918, 0.00090864,\n",
      "       0.00159746, 0.001699  , 0.00101801, 0.00155432, 0.00146858,\n",
      "       0.00122904, 0.00129811, 0.00161342, 0.00149134, 0.00226287,\n",
      "       0.00197227, 0.00108805, 0.00164373, 0.00146138, 0.00105793,\n",
      "       0.0018429 , 0.00152137, 0.00129761, 0.00116824, 0.00123285,\n",
      "       0.0020037 , 0.00139486, 0.00150246, 0.00169301, 0.00149957,\n",
      "       0.00135272, 0.00167088, 0.00117539, 0.00149219, 0.00223367,\n",
      "       0.00138567, 0.00131171, 0.00166214, 0.00093107, 0.00133787,\n",
      "       0.00177833, 0.00169353, 0.00135161, 0.00162113, 0.00125313,\n",
      "       0.00170842, 0.00136035, 0.00131458, 0.00215551, 0.00145741,\n",
      "       0.00120525, 0.00153344, 0.00136842, 0.00201789, 0.00135059,\n",
      "       0.00126494, 0.00158386, 0.00192399, 0.00204672, 0.00188218,\n",
      "       0.0011119 , 0.00115124, 0.00130196, 0.00151023, 0.00137603,\n",
      "       0.00168261, 0.00167173, 0.00139508, 0.00125126, 0.00146188,\n",
      "       0.00149536, 0.00144887, 0.00160174, 0.0015907 , 0.00109157,\n",
      "       0.00104356, 0.00140877, 0.00114617, 0.00165506, 0.00154765,\n",
      "       0.00142345, 0.00095812, 0.00134731, 0.00142311, 0.00154343,\n",
      "       0.00142009, 0.00113031, 0.00124242, 0.00142719, 0.00125674,\n",
      "       0.00142603, 0.00159699, 0.00185762, 0.00191146, 0.00159751,\n",
      "       0.00112768, 0.00118214, 0.00142484, 0.00122027, 0.00157316,\n",
      "       0.00144148, 0.00130011, 0.00191952, 0.00104215, 0.0015076 ,\n",
      "       0.00155102, 0.00157374, 0.00124747, 0.00134032, 0.00106745,\n",
      "       0.0013965 , 0.00151479, 0.00131895, 0.00135311, 0.00116016,\n",
      "       0.00130756, 0.00144825, 0.00185359, 0.0013097 , 0.00156556,\n",
      "       0.0016352 , 0.0017949 , 0.00139692, 0.00129898, 0.00116374,\n",
      "       0.00131661, 0.00180802, 0.00160221, 0.00134204, 0.00112547,\n",
      "       0.00172733, 0.00123331, 0.00103533, 0.001286  , 0.00131084,\n",
      "       0.00138371, 0.00080327, 0.00185693, 0.00132568, 0.00144627,\n",
      "       0.00179624, 0.0012804 , 0.00180948, 0.00165946, 0.00153225,\n",
      "       0.00076247, 0.00129435, 0.00164794, 0.00129528, 0.00165087,\n",
      "       0.00144641, 0.00127111, 0.00101946, 0.00126903, 0.00135704,\n",
      "       0.00112932, 0.0013049 , 0.00099483, 0.00116327, 0.00149379,\n",
      "       0.00139832, 0.0018806 , 0.00126459, 0.00122979, 0.00184648,\n",
      "       0.00129991, 0.00181397, 0.00194167, 0.0014377 , 0.00155468,\n",
      "       0.00218423, 0.00151069], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer19/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 88,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([3.0602703e-05, 3.5872581e-05, 4.1579569e-05, 4.6580368e-05,\n",
      "       3.4192628e-05, 2.7054173e-05, 3.0601048e-05, 3.5686007e-05,\n",
      "       2.5296815e-05, 5.4379059e-05, 3.8814542e-05, 3.2015738e-05,\n",
      "       3.3527722e-05, 2.7855580e-05, 2.9611410e-05, 3.1680265e-05,\n",
      "       3.3057197e-05, 3.5457157e-05, 2.6228898e-05, 3.4494758e-05,\n",
      "       3.8202008e-05, 3.7218091e-05, 3.4162204e-05, 3.8051927e-05,\n",
      "       3.5097248e-05, 3.4644650e-05, 3.6981983e-05, 3.4355391e-05,\n",
      "       3.5347388e-05, 3.3645381e-05, 3.8689785e-05, 3.3359851e-05,\n",
      "       2.9286297e-05, 2.0980737e-05, 3.0354413e-05, 3.5988331e-05,\n",
      "       3.2023003e-05, 3.2018215e-05, 3.3654931e-05, 3.0505042e-05,\n",
      "       2.8176953e-05, 3.0269710e-05, 3.1784250e-05, 3.6626119e-05,\n",
      "       2.9046842e-05, 3.0896372e-05, 4.8064114e-05, 3.1064166e-05,\n",
      "       3.1990934e-05, 2.8375931e-05, 3.4328659e-05, 4.6971381e-05,\n",
      "       3.0263021e-05, 4.0178136e-05, 3.1521362e-05, 3.7837279e-05,\n",
      "       3.1180985e-05, 2.1953723e-05, 3.4772482e-05, 3.1409028e-05,\n",
      "       3.8321472e-05, 3.8537175e-05, 3.3665379e-05, 2.9871835e-05,\n",
      "       3.3534707e-05, 4.5495570e-05, 3.7758400e-05, 5.5583347e-05,\n",
      "       3.1522159e-05, 3.3131630e-05, 3.2312080e-05, 3.3232816e-05,\n",
      "       3.2142278e-05, 5.6304336e-05, 2.7776228e-05, 2.9450157e-05,\n",
      "       3.4176723e-05, 3.8223796e-05, 3.1957545e-05, 3.1769818e-05,\n",
      "       4.1817471e-05, 3.4657351e-05, 3.3590208e-05, 3.2613691e-05,\n",
      "       3.4708104e-05, 3.8668924e-05, 3.8778871e-05, 3.4264121e-05,\n",
      "       4.3225973e-05, 3.3776563e-05, 3.8624970e-05, 4.3243912e-05,\n",
      "       3.3545399e-05, 2.5711754e-05, 3.0917865e-05, 3.1470052e-05,\n",
      "       4.1529358e-05, 2.9979299e-05, 4.5126661e-05, 2.6757487e-05,\n",
      "       2.3733170e-05, 3.4911489e-05, 3.6073157e-05, 3.2954416e-05,\n",
      "       3.8979688e-05, 4.3121505e-05, 3.5521585e-05, 3.2851291e-05,\n",
      "       4.2085678e-05, 3.4483772e-05, 3.0137142e-05, 4.5578978e-05,\n",
      "       2.8247050e-05, 3.2446427e-05, 2.3995623e-05, 4.4626369e-05,\n",
      "       2.5938942e-05, 2.9115166e-05, 3.2185817e-05, 3.3370408e-05,\n",
      "       3.3011234e-05, 3.5344121e-05, 3.7920265e-05, 3.4732697e-05,\n",
      "       3.9222468e-05, 4.1163399e-05, 3.6945024e-05, 3.6165493e-05,\n",
      "       3.5328889e-05, 3.0303336e-05, 2.1401303e-05, 3.9707771e-05,\n",
      "       5.2888321e-05, 2.9303625e-05, 2.9190875e-05, 2.7369286e-05,\n",
      "       3.6233519e-05, 3.4898374e-05, 3.8648595e-05, 3.7276412e-05,\n",
      "       2.7372158e-05, 3.0245090e-05, 5.0854465e-05, 3.2169177e-05,\n",
      "       2.9650233e-05, 2.1497264e-05, 3.2769109e-05, 3.5364345e-05,\n",
      "       4.1979572e-05, 3.4875819e-05, 2.2763210e-05, 2.7328357e-05,\n",
      "       3.0473306e-05, 2.9476774e-05, 3.3065127e-05, 3.1091116e-05,\n",
      "       4.0136038e-05, 3.1489293e-05, 2.8791870e-05, 3.5652061e-05,\n",
      "       2.1473337e-05, 3.3911114e-05, 4.3948112e-05, 3.0815216e-05,\n",
      "       3.7304922e-05, 2.8173134e-05, 4.1283976e-05, 3.5865640e-05,\n",
      "       3.0828451e-05, 3.2759483e-05, 2.8079206e-05, 2.9570747e-05,\n",
      "       3.7342019e-05, 3.2449116e-05, 3.6714009e-05, 2.7349206e-05,\n",
      "       2.7425807e-05, 2.3357798e-05, 2.7031720e-05, 4.0403796e-05,\n",
      "       3.3203974e-05, 4.2007738e-05, 3.8271297e-05, 3.3468990e-05,\n",
      "       3.0256258e-05, 3.4902372e-05, 4.8724716e-05, 3.4602999e-05,\n",
      "       7.7232638e-05, 4.3325923e-05, 4.2047766e-05, 2.7954782e-05,\n",
      "       3.3161599e-05, 3.2986998e-05, 3.3506654e-05, 3.1321684e-05,\n",
      "       4.1066454e-05, 3.4673260e-05, 3.5785939e-05, 3.6903290e-05,\n",
      "       3.3437740e-05, 3.9301241e-05, 3.1757674e-05, 2.5020523e-05,\n",
      "       3.2838594e-05, 4.0108211e-05, 2.7824484e-05, 3.2138931e-05,\n",
      "       3.2430489e-05, 2.6372238e-05, 3.0678042e-05, 2.8147073e-05,\n",
      "       2.9621297e-05, 2.1682743e-05, 3.0765295e-05, 3.8117465e-05,\n",
      "       2.9673469e-05, 3.8721388e-05, 2.6009819e-05, 3.4292807e-05,\n",
      "       3.7387097e-05, 2.9639996e-05, 3.1270883e-05, 3.3369895e-05,\n",
      "       2.7241384e-05, 3.1963285e-05, 3.1207797e-05, 3.3360138e-05,\n",
      "       4.0082530e-05, 3.1075957e-05, 3.7582635e-05, 2.8338407e-05,\n",
      "       3.6935948e-05, 3.5822752e-05, 2.5874446e-05, 3.6807745e-05,\n",
      "       5.2894884e-05, 3.2507058e-05, 3.2694854e-05, 4.0412189e-05,\n",
      "       3.3275603e-05, 3.0204697e-05, 2.9058599e-05, 3.7425983e-05,\n",
      "       3.6777365e-05, 5.2425195e-05, 3.3901881e-05, 3.2027496e-05,\n",
      "       3.3109525e-05, 3.4370965e-05, 2.2547114e-05, 3.1516316e-05,\n",
      "       2.9391023e-05, 4.3121265e-05, 3.2585525e-05, 3.3645207e-05,\n",
      "       3.6092195e-05, 3.4961264e-05, 4.5883877e-05, 3.7077305e-05,\n",
      "       3.0342839e-05, 4.2193828e-05, 3.8626866e-05, 4.1646617e-05,\n",
      "       3.0916417e-05, 3.2195629e-05, 3.2948064e-05, 3.0409134e-05,\n",
      "       3.4902136e-05, 3.1949152e-05, 4.2721262e-05, 3.2135325e-05,\n",
      "       3.3874458e-05, 3.3617605e-05, 3.0401507e-05, 4.4774264e-05,\n",
      "       2.7826747e-05, 3.7101865e-05, 3.2347194e-05, 3.0753676e-05,\n",
      "       3.9201768e-05, 3.1552761e-05, 3.4891156e-05, 3.7765367e-05,\n",
      "       1.4584556e-05, 3.6614823e-05, 3.4798872e-05, 3.3065528e-05,\n",
      "       3.6376925e-05, 4.5492849e-05, 2.7818773e-05, 3.3041382e-05,\n",
      "       4.5081313e-05, 2.8593959e-05, 2.9452398e-05, 3.4785644e-05,\n",
      "       4.1644507e-05, 3.2251221e-05, 3.3965553e-05, 2.6092734e-05,\n",
      "       2.6446112e-05, 3.5960224e-05, 3.3744276e-05, 2.8401002e-05,\n",
      "       3.3388525e-05, 3.7615893e-05, 5.0317918e-05, 4.7267946e-05,\n",
      "       5.5571410e-05, 3.7112677e-05, 3.4051576e-05, 7.5186756e-05,\n",
      "       3.4248886e-05, 3.1482967e-05, 4.5040895e-05, 2.3769668e-05,\n",
      "       4.1240026e-05, 3.1081370e-05, 4.1365787e-05, 3.3028780e-05,\n",
      "       3.4279255e-05, 3.9912324e-05, 2.7573002e-05, 3.7538302e-05,\n",
      "       4.2186719e-05, 3.1313612e-05, 2.3173943e-05, 2.7986633e-05,\n",
      "       3.4991783e-05, 3.4872770e-05, 3.6231173e-05, 3.6747446e-05,\n",
      "       5.1317031e-05, 5.6373399e-05, 2.4170467e-05, 2.3020419e-05,\n",
      "       5.1424555e-05, 3.2168915e-05, 3.1702006e-05, 4.4886590e-05,\n",
      "       3.4378507e-05, 4.4114266e-05, 3.6787882e-05, 2.1627833e-05,\n",
      "       2.1379665e-05, 3.7587241e-05, 3.9976399e-05, 2.3953222e-05,\n",
      "       3.6572259e-05, 3.4554756e-05, 2.8918665e-05, 3.0543797e-05,\n",
      "       3.7962731e-05, 3.5090281e-05, 5.3244046e-05, 4.6406418e-05,\n",
      "       2.5601061e-05, 3.8675920e-05, 3.4385404e-05, 2.4892535e-05,\n",
      "       4.3362335e-05, 3.5796929e-05, 3.0531923e-05, 2.7488062e-05,\n",
      "       2.9008330e-05, 4.7145808e-05, 3.2820310e-05, 3.5352052e-05,\n",
      "       3.9835442e-05, 3.5284116e-05, 3.1828629e-05, 3.9314742e-05,\n",
      "       2.7656328e-05, 3.5110348e-05, 5.2556861e-05, 3.2604039e-05,\n",
      "       3.0863695e-05, 3.9109171e-05, 2.1907550e-05, 3.1479209e-05,\n",
      "       4.1842944e-05, 3.9847779e-05, 3.1802632e-05, 3.8144120e-05,\n",
      "       2.9485451e-05, 4.0198142e-05, 3.2008345e-05, 3.0931249e-05,\n",
      "       5.0717976e-05, 3.4292116e-05, 2.8358932e-05, 3.6080906e-05,\n",
      "       3.2198077e-05, 4.7479687e-05, 3.1778498e-05, 2.9763265e-05,\n",
      "       3.7267342e-05, 4.5270452e-05, 4.8158177e-05, 4.4286582e-05,\n",
      "       2.6162383e-05, 2.7088105e-05, 3.0634415e-05, 3.5534886e-05,\n",
      "       3.2377175e-05, 3.9590795e-05, 3.9334816e-05, 3.2825428e-05,\n",
      "       2.9441479e-05, 3.4397221e-05, 3.5184898e-05, 3.4091012e-05,\n",
      "       3.7688016e-05, 3.7428272e-05, 2.5684085e-05, 2.4554336e-05,\n",
      "       3.3147506e-05, 2.6968815e-05, 3.8942664e-05, 3.6415320e-05,\n",
      "       3.3492957e-05, 2.2543898e-05, 3.1701471e-05, 3.3484870e-05,\n",
      "       3.6316022e-05, 3.3413955e-05, 2.6595573e-05, 2.9233350e-05,\n",
      "       3.3580829e-05, 2.9570256e-05, 3.3553577e-05, 3.7576297e-05,\n",
      "       4.3708751e-05, 4.4975637e-05, 3.7588448e-05, 2.6533546e-05,\n",
      "       2.7815167e-05, 3.3525546e-05, 2.8712297e-05, 3.7015550e-05,\n",
      "       3.3917269e-05, 3.0590920e-05, 4.5165129e-05, 2.4521241e-05,\n",
      "       3.5472855e-05, 3.6494650e-05, 3.7029116e-05, 2.9352314e-05,\n",
      "       3.1536962e-05, 2.5116376e-05, 3.2858919e-05, 3.5642199e-05,\n",
      "       3.1034033e-05, 3.1837888e-05, 2.7297945e-05, 3.0766194e-05,\n",
      "       3.4076387e-05, 4.3613949e-05, 3.0816533e-05, 3.6836616e-05,\n",
      "       3.8475409e-05, 4.2232979e-05, 3.2868618e-05, 3.0564162e-05,\n",
      "       2.7382010e-05, 3.0979034e-05, 4.2541535e-05, 3.7699028e-05,\n",
      "       3.1577441e-05, 2.6481603e-05, 4.0643110e-05, 2.9018982e-05,\n",
      "       2.4360654e-05, 3.0258907e-05, 3.0843239e-05, 3.2557869e-05,\n",
      "       1.8900471e-05, 4.3692373e-05, 3.1192521e-05, 3.4029796e-05,\n",
      "       4.2264455e-05, 3.0127039e-05, 4.2576052e-05, 3.9046128e-05,\n",
      "       3.6052934e-05, 1.7940394e-05, 3.0455320e-05, 3.8775157e-05,\n",
      "       3.0477220e-05, 3.8844028e-05, 3.4033197e-05, 2.9908486e-05,\n",
      "       2.3987332e-05, 2.9859591e-05, 3.1930274e-05, 2.6572123e-05,\n",
      "       3.0703533e-05, 2.3407752e-05, 2.7370968e-05, 3.5147888e-05,\n",
      "       3.2901746e-05, 4.4249497e-05, 2.9755111e-05, 2.8936149e-05,\n",
      "       4.3446616e-05, 3.0586205e-05, 4.2681550e-05, 4.5686302e-05,\n",
      "       3.3828295e-05, 3.6580677e-05, 5.1393603e-05, 3.5545596e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer19/conv/Relu6;tower0/network/layer19/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer19/conv/Conv2D,\n",
      "index: 89,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer20/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer20/sepconv/depthwise;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 90,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([7.58470176e-03, 4.90550138e-03, 6.84648519e-03, 8.77513364e-03,\n",
      "       7.36357970e-03, 8.85424763e-03, 5.11652045e-03, 8.88934731e-03,\n",
      "       7.67194061e-03, 8.99958052e-03, 5.54944156e-03, 5.31237479e-03,\n",
      "       4.92348522e-03, 6.48869807e-03, 4.20029229e-03, 6.05097879e-03,\n",
      "       8.89251195e-03, 4.94201342e-03, 2.30331992e-04, 8.81288573e-03,\n",
      "       1.17604351e-02, 6.43337239e-03, 1.00415610e-02, 4.98188008e-03,\n",
      "       4.68806503e-03, 8.24911520e-03, 9.27165523e-03, 6.16708817e-03,\n",
      "       5.94339380e-03, 6.60724146e-03, 4.63703228e-03, 5.10319974e-03,\n",
      "       8.18330329e-03, 1.91238083e-04, 4.39808564e-03, 5.19135688e-03,\n",
      "       6.46999851e-03, 5.01424307e-03, 6.22660667e-03, 5.20617561e-03,\n",
      "       5.36281010e-03, 6.86930900e-04, 5.63019002e-03, 4.02544532e-03,\n",
      "       6.81290776e-03, 7.19646038e-03, 5.01267100e-03, 8.00526794e-03,\n",
      "       7.10519776e-03, 5.60533721e-03, 6.44923793e-03, 6.26648543e-03,\n",
      "       5.24731865e-03, 4.78347996e-03, 6.89438125e-03, 4.66108182e-03,\n",
      "       5.21346275e-03, 7.53510278e-03, 7.18295295e-03, 7.88985658e-03,\n",
      "       5.03145158e-03, 5.39151765e-03, 4.83523542e-03, 1.07619083e-02,\n",
      "       8.17176141e-03, 6.73074229e-03, 6.27405988e-03, 6.01015380e-03,\n",
      "       8.35577585e-03, 5.65144606e-03, 6.40411302e-03, 9.87074710e-03,\n",
      "       5.89593314e-03, 6.11599907e-03, 6.63917093e-03, 4.93445899e-03,\n",
      "       5.94334956e-03, 8.11838266e-03, 5.78896143e-03, 7.73946289e-03,\n",
      "       4.43503540e-03, 1.24881398e-02, 8.50233808e-03, 8.79845116e-03,\n",
      "       8.27612914e-03, 5.89598296e-03, 6.47706492e-03, 6.39089011e-03,\n",
      "       5.51422546e-03, 7.46116415e-03, 8.44438653e-03, 5.05085569e-03,\n",
      "       5.56544727e-03, 4.39225789e-03, 5.50002651e-03, 7.17757922e-03,\n",
      "       8.70622974e-03, 6.49748184e-03, 7.69261038e-03, 7.67963845e-03,\n",
      "       6.05019648e-03, 1.00907953e-02, 6.74631959e-03, 8.56171269e-03,\n",
      "       4.63413307e-03, 7.46204285e-03, 5.85345039e-03, 5.89370029e-03,\n",
      "       5.50635345e-03, 5.97538659e-03, 6.94899866e-03, 6.81269076e-03,\n",
      "       6.56378129e-03, 7.91657344e-03, 9.01754852e-03, 1.02512119e-02,\n",
      "       6.65027602e-03, 8.03244393e-03, 5.32767037e-03, 5.05471369e-03,\n",
      "       9.92127415e-03, 4.70665749e-03, 7.93143455e-03, 7.06520537e-03,\n",
      "       8.09638295e-03, 4.27974900e-03, 6.35412429e-03, 9.18069389e-03,\n",
      "       7.16419704e-03, 7.83872511e-03, 9.41525307e-03, 5.46675362e-03,\n",
      "       7.99198262e-03, 7.01978430e-03, 9.07992944e-03, 9.46325436e-03,\n",
      "       5.53055201e-03, 5.40659996e-03, 6.13909494e-03, 4.03737323e-03,\n",
      "       4.81132651e-03, 6.83653029e-03, 4.56802920e-03, 7.81470723e-03,\n",
      "       7.10441498e-03, 1.19808521e-02, 6.48559444e-03, 7.80997612e-03,\n",
      "       6.08068798e-03, 8.93219840e-03, 8.52136780e-03, 6.41095638e-03,\n",
      "       5.05933212e-03, 3.65080050e-04, 6.06811792e-03, 3.84609593e-04,\n",
      "       6.46632910e-03, 5.43973921e-03, 6.57008123e-03, 5.94230928e-03,\n",
      "       1.00896740e-02, 6.37307158e-03, 4.85664327e-03, 5.23124263e-03,\n",
      "       6.99007232e-03, 7.62152439e-03, 7.90046994e-03, 9.31304973e-03,\n",
      "       5.49573312e-03, 6.96999161e-03, 5.05298562e-03, 6.28006458e-03,\n",
      "       5.18631935e-03, 6.02512993e-03, 6.83922647e-03, 5.51370624e-03,\n",
      "       1.63077697e-04, 8.25439766e-03, 5.39557822e-03, 7.12537207e-03,\n",
      "       5.89304091e-03, 5.54127432e-03, 4.90904879e-03, 7.08301831e-03,\n",
      "       1.41390658e-04, 8.30138195e-03, 6.96565397e-03, 8.32936075e-03,\n",
      "       5.75661054e-03, 8.93130060e-03, 6.11696951e-03, 8.29779264e-03,\n",
      "       5.37133915e-03, 5.79223316e-03, 6.15590997e-03, 5.31135779e-03,\n",
      "       5.85383410e-03, 4.64460347e-03, 7.52187474e-03, 4.94741974e-03,\n",
      "       6.17039623e-03, 9.40413307e-03, 3.27067799e-04, 7.91810732e-03,\n",
      "       5.99875115e-03, 7.13489810e-03, 1.09026842e-02, 5.61605534e-03,\n",
      "       7.78843276e-03, 1.04744816e-02, 5.34411613e-03, 8.19942355e-03,\n",
      "       5.22843155e-04, 1.51477205e-02, 7.10200053e-03, 6.33780845e-03,\n",
      "       9.87101439e-03, 6.84285862e-03, 2.81562621e-04, 6.74680946e-03,\n",
      "       6.87904656e-03, 7.47492211e-03, 4.90915636e-03, 5.92048094e-03,\n",
      "       5.95365698e-03, 6.24261051e-03, 4.55716345e-03, 5.95628843e-03,\n",
      "       4.32766462e-03, 1.23471880e-04, 5.84951555e-03, 9.57515836e-03,\n",
      "       6.58467738e-03, 4.50081611e-03, 7.19271554e-03, 6.70802500e-03,\n",
      "       7.40855234e-03, 1.01033291e-02, 6.74180128e-03, 4.29017935e-03,\n",
      "       7.12823076e-03, 5.95139759e-03, 8.65917187e-03, 2.70135439e-04,\n",
      "       6.07621670e-03, 5.27042057e-03, 4.11819061e-03, 7.85419252e-03,\n",
      "       7.90062919e-03, 6.66256715e-03, 9.77103133e-03, 6.16346346e-03,\n",
      "       1.03831813e-02, 8.12316872e-03, 6.14361186e-03, 5.34518249e-03,\n",
      "       4.68785176e-03, 7.11801881e-03, 6.90014800e-03, 6.89495169e-03,\n",
      "       5.53827127e-03, 6.04378898e-03, 6.53088326e-03, 6.37000380e-03,\n",
      "       6.23709988e-03, 7.34914700e-03, 5.28103253e-03, 5.58369001e-03,\n",
      "       7.89489690e-03, 5.33583108e-03, 7.56929768e-03, 5.47600584e-03,\n",
      "       5.00388769e-03, 7.35439826e-03, 7.53980782e-03, 7.69969961e-03,\n",
      "       5.56230778e-03, 7.09439209e-03, 6.83632540e-03, 5.39624412e-03,\n",
      "       5.82378032e-03, 6.25570072e-03, 6.48525730e-03, 5.01486100e-03,\n",
      "       2.94853817e-04, 7.23866513e-03, 5.87437395e-03, 7.71096675e-03,\n",
      "       6.32195687e-03, 7.84479175e-03, 7.97932409e-03, 4.45105601e-03,\n",
      "       4.71281353e-03, 1.09621976e-02, 6.06144592e-03, 7.01355096e-03,\n",
      "       7.50271464e-03, 7.23088952e-03, 9.37857199e-03, 8.97672586e-03,\n",
      "       1.25802495e-02, 5.54722408e-03, 7.20527722e-03, 6.34659501e-03,\n",
      "       4.58301511e-03, 6.79753302e-03, 6.72644610e-03, 6.96515897e-03,\n",
      "       6.16230583e-03, 8.94766208e-03, 6.85307058e-03, 8.03480390e-03,\n",
      "       6.23035524e-03, 8.39008205e-03, 1.13960691e-02, 2.70874210e-04,\n",
      "       1.05134146e-02, 7.09108077e-03, 7.33487681e-03, 9.73363500e-03,\n",
      "       4.71008942e-03, 5.73388999e-03, 1.53894958e-04, 5.81072643e-03,\n",
      "       5.86517528e-03, 3.93567467e-03, 2.60684872e-04, 7.16301007e-03,\n",
      "       7.03833811e-03, 7.77617795e-03, 9.29927081e-03, 8.11797567e-03,\n",
      "       8.56632926e-03, 7.03743054e-03, 7.43787503e-03, 6.58310344e-03,\n",
      "       4.30897437e-03, 6.89966045e-03, 4.56413208e-03, 7.29327649e-03,\n",
      "       6.49283035e-03, 6.54659141e-03, 5.03648771e-03, 2.30098129e-04,\n",
      "       1.32713723e-03, 6.65288791e-03, 4.38957522e-03, 5.98840532e-04,\n",
      "       6.96420996e-03, 9.97752044e-03, 9.38875787e-03, 7.91500788e-03,\n",
      "       6.63601793e-03, 5.67791238e-03, 8.76205508e-03, 6.85910694e-03,\n",
      "       9.19660460e-03, 5.26073016e-03, 6.03225408e-03, 1.36330230e-02,\n",
      "       8.08700174e-03, 6.42064400e-03, 5.61632682e-03, 5.86954504e-03,\n",
      "       7.50845857e-03, 5.62334061e-03, 4.00638580e-03, 5.70833217e-03,\n",
      "       6.47602323e-03, 7.00851111e-03, 5.60530182e-03, 6.98295655e-03,\n",
      "       4.51679621e-03, 4.58668405e-03, 6.76977215e-03, 8.67311098e-03,\n",
      "       4.51981649e-03, 4.90779895e-03, 8.33805744e-03, 5.95041038e-03,\n",
      "       5.22181811e-03, 1.92914231e-04, 7.65767135e-03, 7.98691250e-03,\n",
      "       1.11111626e-02, 6.01408398e-03, 6.45466195e-03, 7.98763987e-03,\n",
      "       7.83044752e-03, 7.18117505e-03, 5.38753998e-03, 5.73301176e-03,\n",
      "       4.27411310e-03, 5.29814279e-03, 8.49035662e-03, 7.12478068e-03,\n",
      "       6.06609462e-03, 6.46232814e-03, 4.13903641e-03, 5.80246840e-03,\n",
      "       4.71926806e-03, 1.04982778e-02, 7.49017950e-03, 6.51449757e-03,\n",
      "       5.95526351e-03, 7.92336650e-03, 9.07325558e-03, 6.56622797e-05,\n",
      "       7.13792536e-03, 6.76025311e-03, 1.05080325e-02, 6.69266516e-03,\n",
      "       5.84811019e-03, 5.85337356e-03, 7.39601115e-03, 1.34218177e-02,\n",
      "       6.85119862e-03, 6.49785437e-03, 6.84148492e-03, 7.65254442e-03,\n",
      "       7.59683782e-03, 2.69527402e-04, 5.82646206e-03, 4.43349825e-03,\n",
      "       1.06039234e-02, 4.54803556e-03, 6.19441271e-03, 6.85272925e-03,\n",
      "       1.06323119e-02, 3.23923130e-04, 5.93482424e-03, 6.43358799e-03,\n",
      "       4.94116219e-03, 8.31811875e-03, 4.36846865e-03, 4.28815343e-04,\n",
      "       3.84495012e-03, 6.31988887e-03, 7.49548525e-03, 7.39008840e-03,\n",
      "       1.01541067e-02, 9.17841215e-03, 5.23753231e-03, 2.65791430e-04,\n",
      "       8.45747720e-03, 5.77813899e-03, 1.01531511e-02, 3.61505756e-03,\n",
      "       8.58047511e-03, 1.10256225e-02, 5.98447211e-03, 6.54430315e-03,\n",
      "       7.44640362e-03, 4.73984983e-03, 3.42178246e-04, 1.54929803e-04,\n",
      "       6.93826936e-03, 5.36394306e-03, 7.19453394e-03, 6.22180384e-03,\n",
      "       7.78483599e-03, 5.62744401e-03, 9.40713566e-03, 6.35033986e-03,\n",
      "       1.27715571e-02, 9.97777842e-03, 8.26362986e-03, 7.46453600e-03,\n",
      "       9.30946320e-03, 6.47309795e-03, 5.76125924e-03, 4.87807719e-03,\n",
      "       8.35635420e-03, 7.24063907e-03, 7.09246658e-03, 5.40863862e-03,\n",
      "       1.44131696e-02, 6.13920856e-03, 7.46795256e-03, 8.68135784e-03,\n",
      "       5.87252155e-03, 6.63650315e-03, 1.09718107e-02, 8.18257872e-03,\n",
      "       8.78165942e-03, 3.75610078e-04, 1.17054852e-02, 7.50503270e-03,\n",
      "       3.59009835e-03, 7.52842752e-03, 6.71173586e-03, 7.87007716e-03,\n",
      "       1.17578376e-02, 7.03125400e-03, 6.68752566e-03, 5.42668859e-03,\n",
      "       8.85756966e-03, 9.15744342e-03, 1.21136801e-02, 8.14659242e-03,\n",
      "       4.14275657e-03, 6.42246753e-03, 9.43166949e-03, 4.16538306e-03,\n",
      "       4.64062346e-03, 6.23603771e-03, 7.00412411e-03, 5.75290713e-03,\n",
      "       6.32113311e-03, 6.77772937e-03, 5.66095812e-03, 8.32209084e-03],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer20/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 91,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.78463568e-04, 1.15423565e-04, 1.61093776e-04, 2.06473735e-04,\n",
      "       1.73260705e-04, 2.08335245e-04, 1.20388722e-04, 2.09161124e-04,\n",
      "       1.80516246e-04, 2.11754843e-04, 1.30575092e-04, 1.24997052e-04,\n",
      "       1.15846713e-04, 1.52675246e-04, 9.88304091e-05, 1.42375968e-04,\n",
      "       2.09235586e-04, 1.16282674e-04, 5.41957661e-06, 2.07362027e-04,\n",
      "       2.76716135e-04, 1.51373475e-04, 2.36272026e-04, 1.17220712e-04,\n",
      "       1.10307417e-04, 1.94096836e-04, 2.18156594e-04, 1.45107959e-04,\n",
      "       1.39844560e-04, 1.55464513e-04, 1.09106644e-04, 1.20075289e-04,\n",
      "       1.92548323e-04, 4.49971958e-06, 1.03484374e-04, 1.22149577e-04,\n",
      "       1.52235269e-04, 1.17982192e-04, 1.46508391e-04, 1.22498255e-04,\n",
      "       1.26183775e-04, 1.61630796e-05, 1.32475063e-04, 9.47163644e-05,\n",
      "       1.60303709e-04, 1.69328487e-04, 1.17945201e-04, 1.88359249e-04,\n",
      "       1.67181133e-04, 1.31890294e-04, 1.51746775e-04, 1.47446714e-04,\n",
      "       1.23466321e-04, 1.12552472e-04, 1.62220735e-04, 1.09672517e-04,\n",
      "       1.22669720e-04, 1.77296533e-04, 1.69010658e-04, 1.85643687e-04,\n",
      "       1.18387099e-04, 1.26859246e-04, 1.13770249e-04, 2.53221369e-04,\n",
      "       1.92276741e-04, 1.58370414e-04, 1.47624945e-04, 1.41415381e-04,\n",
      "       1.96606488e-04, 1.32975198e-04, 1.50685009e-04, 2.32252874e-04,\n",
      "       1.38727846e-04, 1.43905869e-04, 1.56215785e-04, 1.16104922e-04,\n",
      "       1.39843527e-04, 1.91020779e-04, 1.36210860e-04, 1.82105010e-04,\n",
      "       1.04353778e-04, 2.93838588e-04, 2.00055016e-04, 2.07022385e-04,\n",
      "       1.94732449e-04, 1.38729010e-04, 1.52401524e-04, 1.50373889e-04,\n",
      "       1.29746477e-04, 1.75556808e-04, 1.98691458e-04, 1.18843665e-04,\n",
      "       1.30951710e-04, 1.03347244e-04, 1.29412394e-04, 1.68884217e-04,\n",
      "       2.04852462e-04, 1.52881927e-04, 1.81002601e-04, 1.80697374e-04,\n",
      "       1.42357574e-04, 2.37430490e-04, 1.58736933e-04, 2.01452072e-04,\n",
      "       1.09038425e-04, 1.75577487e-04, 1.37728246e-04, 1.38675299e-04,\n",
      "       1.29561260e-04, 1.40597331e-04, 1.63505858e-04, 1.60298616e-04,\n",
      "       1.54441921e-04, 1.86272315e-04, 2.12177620e-04, 2.41204994e-04,\n",
      "       1.56477079e-04, 1.88998689e-04, 1.25356950e-04, 1.18934440e-04,\n",
      "       2.33441751e-04, 1.10744884e-04, 1.86621997e-04, 1.66240134e-04,\n",
      "       1.90503139e-04, 1.00699981e-04, 1.49508807e-04, 2.16016328e-04,\n",
      "       1.68569342e-04, 1.84440592e-04, 2.21535374e-04, 1.28629501e-04,\n",
      "       1.88046659e-04, 1.65171397e-04, 2.13645399e-04, 2.22664807e-04,\n",
      "       1.30130633e-04, 1.27214123e-04, 1.44449295e-04, 9.49970199e-05,\n",
      "       1.13207687e-04, 1.60859534e-04, 1.07483043e-04, 1.83875469e-04,\n",
      "       1.67162711e-04, 2.81902408e-04, 1.52602224e-04, 1.83764147e-04,\n",
      "       1.43075013e-04, 2.10169383e-04, 2.00502778e-04, 1.50846041e-04,\n",
      "       1.19043114e-04, 8.59011925e-06, 1.42779245e-04, 9.04963781e-06,\n",
      "       1.52148918e-04, 1.27993873e-04, 1.54590147e-04, 1.39819051e-04,\n",
      "       2.37404092e-04, 1.49954634e-04, 1.14273964e-04, 1.23088059e-04,\n",
      "       1.64472294e-04, 1.79329989e-04, 1.85893412e-04, 2.19130583e-04,\n",
      "       1.29311375e-04, 1.63999808e-04, 1.18893782e-04, 1.47766230e-04,\n",
      "       1.22031044e-04, 1.41767770e-04, 1.60922980e-04, 1.29734268e-04,\n",
      "       3.83712222e-06, 1.94221124e-04, 1.26954779e-04, 1.67655817e-04,\n",
      "       1.38659787e-04, 1.30382934e-04, 1.15507035e-04, 1.66659258e-04,\n",
      "       3.32683908e-06, 1.95326633e-04, 1.63897741e-04, 1.95984961e-04,\n",
      "       1.35449664e-04, 2.10148253e-04, 1.43928701e-04, 1.95242188e-04,\n",
      "       1.26384446e-04, 1.36287839e-04, 1.44844947e-04, 1.24973129e-04,\n",
      "       1.37737283e-04, 1.09284789e-04, 1.76985297e-04, 1.16409879e-04,\n",
      "       1.45185797e-04, 2.21273731e-04, 7.69571307e-06, 1.86308418e-04,\n",
      "       1.41147088e-04, 1.67879960e-04, 2.56533764e-04, 1.32142479e-04,\n",
      "       1.83257245e-04, 2.46458396e-04, 1.25743914e-04, 1.92927619e-04,\n",
      "       1.23021919e-05, 3.56416946e-04, 1.67105900e-04, 1.49124913e-04,\n",
      "       2.32259161e-04, 1.61008444e-04, 6.62500315e-06, 1.58748458e-04,\n",
      "       1.61859920e-04, 1.75880530e-04, 1.15509567e-04, 1.39305441e-04,\n",
      "       1.40086049e-04, 1.46884951e-04, 1.07227381e-04, 1.40147968e-04,\n",
      "       1.01827405e-04, 2.90522075e-06, 1.37635667e-04, 2.25297845e-04,\n",
      "       1.54933587e-04, 1.05901556e-04, 1.69240375e-04, 1.57835879e-04,\n",
      "       1.74318877e-04, 2.37725399e-04, 1.58630617e-04, 1.00945399e-04,\n",
      "       1.67723076e-04, 1.40032891e-04, 2.03745221e-04, 6.35612787e-06,\n",
      "       1.42969802e-04, 1.24009894e-04, 9.68986060e-05, 1.84804536e-04,\n",
      "       1.85897166e-04, 1.56766284e-04, 2.29906625e-04, 1.45022670e-04,\n",
      "       2.44310155e-04, 1.91133382e-04, 1.44555583e-04, 1.25769002e-04,\n",
      "       1.10302397e-04, 1.67482794e-04, 1.62356431e-04, 1.62234166e-04,\n",
      "       1.30312270e-04, 1.42206802e-04, 1.53667846e-04, 1.49882442e-04,\n",
      "       1.46755294e-04, 1.72921107e-04, 1.24259590e-04, 1.31380948e-04,\n",
      "       1.85762285e-04, 1.25548962e-04, 1.78101123e-04, 1.28847198e-04,\n",
      "       1.17738535e-04, 1.73044667e-04, 1.77407244e-04, 1.81169409e-04,\n",
      "       1.30877830e-04, 1.66926882e-04, 1.60854717e-04, 1.26970452e-04,\n",
      "       1.37030132e-04, 1.47192957e-04, 1.52594293e-04, 1.17996729e-04,\n",
      "       6.93773700e-06, 1.70321538e-04, 1.38220566e-04, 1.81434516e-04,\n",
      "       1.48751933e-04, 1.84583332e-04, 1.87748810e-04, 1.04730731e-04,\n",
      "       1.10889734e-04, 2.57934065e-04, 1.42622259e-04, 1.65024729e-04,\n",
      "       1.76534464e-04, 1.70138577e-04, 2.20672286e-04, 2.11217077e-04,\n",
      "       2.96005863e-04, 1.30522923e-04, 1.69535939e-04, 1.49331652e-04,\n",
      "       1.07835651e-04, 1.59941963e-04, 1.58269322e-04, 1.63886099e-04,\n",
      "       1.44995429e-04, 2.10533224e-04, 1.61248725e-04, 1.89054219e-04,\n",
      "       1.46596591e-04, 1.97413698e-04, 2.68142816e-04, 6.37351104e-06,\n",
      "       2.47374468e-04, 1.66848957e-04, 1.72585336e-04, 2.29026715e-04,\n",
      "       1.10825633e-04, 1.34915055e-04, 3.62105789e-06, 1.36722971e-04,\n",
      "       1.38004121e-04, 9.26041103e-05, 6.13376187e-06, 1.68541417e-04,\n",
      "       1.65607955e-04, 1.82968899e-04, 2.18806381e-04, 1.91011190e-04,\n",
      "       2.01560688e-04, 1.65586607e-04, 1.75008827e-04, 1.54896552e-04,\n",
      "       1.01387632e-04, 1.62344950e-04, 1.07391344e-04, 1.71606516e-04,\n",
      "       1.52772482e-04, 1.54037451e-04, 1.18505595e-04, 5.41407371e-06,\n",
      "       3.12267584e-05, 1.56538546e-04, 1.03284125e-04, 1.40903658e-05,\n",
      "       1.63863762e-04, 2.34765190e-04, 2.20911956e-04, 1.86235484e-04,\n",
      "       1.56141599e-04, 1.33597947e-04, 2.06166005e-04, 1.61390752e-04,\n",
      "       2.16390705e-04, 1.23781894e-04, 1.41935394e-04, 3.20777006e-04,\n",
      "       1.90282401e-04, 1.51073982e-04, 1.32148867e-04, 1.38106945e-04,\n",
      "       1.76669622e-04, 1.32313900e-04, 9.42679035e-05, 1.34313697e-04,\n",
      "       1.52377019e-04, 1.64906145e-04, 1.31889450e-04, 1.64304860e-04,\n",
      "       1.06277563e-04, 1.07921980e-04, 1.59288757e-04, 2.04073207e-04,\n",
      "       1.06348627e-04, 1.15477626e-04, 1.96189590e-04, 1.40009652e-04,\n",
      "       1.22866317e-04, 4.53915845e-06, 1.80180505e-04, 1.87927362e-04,\n",
      "       2.61439127e-04, 1.41507859e-04, 1.51874396e-04, 1.87944475e-04,\n",
      "       1.84245830e-04, 1.68968822e-04, 1.26765648e-04, 1.34894392e-04,\n",
      "       1.00567369e-04, 1.24662183e-04, 1.99773101e-04, 1.67641905e-04,\n",
      "       1.42731646e-04, 1.52054781e-04, 9.73890928e-05, 1.36528673e-04,\n",
      "       1.11041605e-04, 2.47018295e-04, 1.76239526e-04, 1.53282293e-04,\n",
      "       1.40123855e-04, 1.86432153e-04, 2.13488369e-04, 1.54499480e-06,\n",
      "       1.67951192e-04, 1.59064788e-04, 2.47247837e-04, 1.57474482e-04,\n",
      "       1.37602590e-04, 1.37726442e-04, 1.74023793e-04, 3.15807469e-04,\n",
      "       1.61204676e-04, 1.52890687e-04, 1.60976124e-04, 1.80059869e-04,\n",
      "       1.78749135e-04, 6.34182152e-06, 1.37093230e-04, 1.04317609e-04,\n",
      "       2.49504083e-04, 1.07012602e-04, 1.45750892e-04, 1.61240692e-04,\n",
      "       2.50172045e-04, 7.62172067e-06, 1.39642929e-04, 1.51378539e-04,\n",
      "       1.16262643e-04, 1.95720451e-04, 1.02787497e-04, 1.00897732e-05,\n",
      "       9.04694170e-05, 1.48703271e-04, 1.76364367e-04, 1.73884429e-04,\n",
      "       2.38920155e-04, 2.15962646e-04, 1.23236052e-04, 6.25391613e-06,\n",
      "       1.98999463e-04, 1.35956216e-04, 2.38897672e-04, 8.50601791e-05,\n",
      "       2.01893534e-04, 2.59426422e-04, 1.40811113e-04, 1.53983608e-04,\n",
      "       1.75209498e-04, 1.11525878e-04, 8.05125273e-06, 3.64540711e-06,\n",
      "       1.63253397e-04, 1.26210434e-04, 1.69283157e-04, 1.46395381e-04,\n",
      "       1.83172611e-04, 1.32410452e-04, 2.21344366e-04, 1.49419764e-04,\n",
      "       3.00507236e-04, 2.34771258e-04, 1.94438355e-04, 1.75636145e-04,\n",
      "       2.19046196e-04, 1.52308188e-04, 1.35559050e-04, 1.14778290e-04,\n",
      "       1.96620109e-04, 1.70367988e-04, 1.66881568e-04, 1.27262087e-04,\n",
      "       3.39133403e-04, 1.44451973e-04, 1.75716530e-04, 2.04267242e-04,\n",
      "       1.38176983e-04, 1.56153023e-04, 2.58160260e-04, 1.92531268e-04,\n",
      "       2.06627286e-04, 8.83788471e-06, 2.75423197e-04, 1.76589005e-04,\n",
      "       8.44729075e-05, 1.77139475e-04, 1.57923205e-04, 1.85178287e-04,\n",
      "       2.76655017e-04, 1.65441277e-04, 1.57353541e-04, 1.27686799e-04,\n",
      "       2.08413403e-04, 2.15469263e-04, 2.85027782e-04, 1.91684536e-04,\n",
      "       9.74766299e-05, 1.51116881e-04, 2.21921640e-04, 9.80090117e-05,\n",
      "       1.09191140e-04, 1.46730308e-04, 1.64802928e-04, 1.35362527e-04,\n",
      "       1.48732550e-04, 1.59475981e-04, 1.33199021e-04, 1.95813904e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer20/sepconv/Relu6;tower0/network/layer20/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer20/sepconv/depthwise,\n",
      "index: 92,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer21/conv/Conv2D,\n",
      "index: 93,\n",
      "shape: [512   1   1 512],\n",
      "shape_signature: [512   1   1 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00112851, 0.00138387, 0.0014059 , 0.00248897, 0.00084835,\n",
      "       0.00129989, 0.00129052, 0.00116724, 0.00131477, 0.00235014,\n",
      "       0.00143598, 0.00161946, 0.00150323, 0.00117982, 0.00092956,\n",
      "       0.00124373, 0.00121806, 0.00163117, 0.00132242, 0.00112517,\n",
      "       0.0013203 , 0.00109857, 0.00108035, 0.00135905, 0.00103394,\n",
      "       0.00103013, 0.00131758, 0.00167868, 0.00136365, 0.00112663,\n",
      "       0.0011966 , 0.00123168, 0.00127269, 0.00080786, 0.00140887,\n",
      "       0.00129207, 0.00136259, 0.00100108, 0.00135252, 0.00124913,\n",
      "       0.00169038, 0.00133882, 0.00168367, 0.00125261, 0.00153676,\n",
      "       0.00118468, 0.00166714, 0.0014076 , 0.00074603, 0.00181213,\n",
      "       0.00188606, 0.00117929, 0.00147092, 0.00134743, 0.00135239,\n",
      "       0.00162655, 0.00111908, 0.00143147, 0.00135177, 0.001474  ,\n",
      "       0.00125299, 0.00116925, 0.00075437, 0.00110733, 0.00135635,\n",
      "       0.00118224, 0.00078968, 0.00133371, 0.0014273 , 0.00109223,\n",
      "       0.0015778 , 0.00100454, 0.00133453, 0.00196302, 0.00156219,\n",
      "       0.00103072, 0.00138682, 0.00161425, 0.00108523, 0.00120527,\n",
      "       0.00121984, 0.00103212, 0.00158181, 0.0013224 , 0.00129511,\n",
      "       0.00111244, 0.00110487, 0.00158481, 0.00132006, 0.00127562,\n",
      "       0.0015864 , 0.00130698, 0.00160225, 0.00134801, 0.00158739,\n",
      "       0.00123275, 0.00144958, 0.00131219, 0.00112035, 0.00103558,\n",
      "       0.00138821, 0.00088128, 0.00118192, 0.00126424, 0.00095908,\n",
      "       0.00163106, 0.00120361, 0.00123477, 0.00135541, 0.0013233 ,\n",
      "       0.00090468, 0.00117379, 0.00125886, 0.00143105, 0.00107239,\n",
      "       0.00138209, 0.00108239, 0.00082167, 0.00130601, 0.00123636,\n",
      "       0.00146872, 0.00100181, 0.00149277, 0.00151984, 0.00117157,\n",
      "       0.00112692, 0.00136112, 0.00120791, 0.00085265, 0.00132846,\n",
      "       0.00185709, 0.00129698, 0.00138069, 0.00077559, 0.00146108,\n",
      "       0.00104048, 0.00118769, 0.00134225, 0.00148803, 0.00121845,\n",
      "       0.00139712, 0.00086004, 0.00136   , 0.00134199, 0.00113989,\n",
      "       0.00156665, 0.00152706, 0.0008547 , 0.00197226, 0.00131723,\n",
      "       0.00114669, 0.00123182, 0.0015537 , 0.00127331, 0.00169913,\n",
      "       0.00113839, 0.00112895, 0.00141671, 0.00119731, 0.00157507,\n",
      "       0.00140496, 0.00130813, 0.00130898, 0.00105963, 0.00117727,\n",
      "       0.00090677, 0.0014344 , 0.00120115, 0.00084921, 0.00123558,\n",
      "       0.0014109 , 0.00114203, 0.00144168, 0.00113893, 0.00168163,\n",
      "       0.00095582, 0.00131435, 0.00114383, 0.00187077, 0.00086011,\n",
      "       0.00146092, 0.00129088, 0.00123476, 0.0015635 , 0.00167349,\n",
      "       0.00216448, 0.00085459, 0.00156439, 0.0012116 , 0.00110094,\n",
      "       0.00174885, 0.0011307 , 0.00114712, 0.00131311, 0.00117565,\n",
      "       0.00116209, 0.00124001, 0.00121074, 0.00116011, 0.00152436,\n",
      "       0.00134013, 0.0010419 , 0.00142924, 0.00100882, 0.00124729,\n",
      "       0.00143466, 0.0014265 , 0.00115442, 0.00146868, 0.00135892,\n",
      "       0.00139683, 0.00124553, 0.00166852, 0.00107519, 0.00121836,\n",
      "       0.00133151, 0.00160009, 0.00235919, 0.00148272, 0.00154895,\n",
      "       0.00148247, 0.00249802, 0.00095481, 0.00166068, 0.00193717,\n",
      "       0.00148995, 0.00103224, 0.00116884, 0.00165462, 0.00138462,\n",
      "       0.00147376, 0.00158321, 0.00155014, 0.00104782, 0.00131904,\n",
      "       0.0015477 , 0.00164052, 0.00132793, 0.00097228, 0.00142477,\n",
      "       0.00116137, 0.00102646, 0.00104712, 0.00157032, 0.00128966,\n",
      "       0.0017226 , 0.0010226 , 0.00129429, 0.00141665, 0.00116115,\n",
      "       0.00142085, 0.00130873, 0.00117332, 0.00113656, 0.00108678,\n",
      "       0.00086484, 0.0007296 , 0.00096343, 0.00125162, 0.00133459,\n",
      "       0.00110643, 0.00163699, 0.00221169, 0.00162174, 0.0017606 ,\n",
      "       0.00108419, 0.0012118 , 0.00125272, 0.001093  , 0.00188312,\n",
      "       0.00133624, 0.00165007, 0.00164359, 0.00103371, 0.00134389,\n",
      "       0.00116032, 0.00135356, 0.00149953, 0.00108146, 0.0016545 ,\n",
      "       0.00144319, 0.00156048, 0.00121796, 0.00127775, 0.0011154 ,\n",
      "       0.00116245, 0.00137601, 0.00122578, 0.0018227 , 0.00113469,\n",
      "       0.00124448, 0.00107065, 0.00112977, 0.00122389, 0.00117772,\n",
      "       0.00179029, 0.00113139, 0.00162886, 0.00137176, 0.0014084 ,\n",
      "       0.00107669, 0.00103293, 0.00131112, 0.00158952, 0.0010486 ,\n",
      "       0.00155431, 0.00137695, 0.00176252, 0.00131571, 0.0016082 ,\n",
      "       0.00175155, 0.00135426, 0.00103259, 0.00132248, 0.00127908,\n",
      "       0.00079313, 0.00149001, 0.0010992 , 0.00133842, 0.00165095,\n",
      "       0.00154274, 0.00113695, 0.00142603, 0.00163621, 0.00107798,\n",
      "       0.00130942, 0.00176688, 0.0005828 , 0.00123275, 0.00157282,\n",
      "       0.00145847, 0.00102202, 0.00142018, 0.00152534, 0.00099029,\n",
      "       0.00140925, 0.00141693, 0.00131467, 0.00117663, 0.00135513,\n",
      "       0.00113065, 0.00132581, 0.00104953, 0.00157066, 0.00196177,\n",
      "       0.00084256, 0.00114163, 0.00098966, 0.00128213, 0.00185   ,\n",
      "       0.00181986, 0.00105995, 0.00132388, 0.00124458, 0.0011519 ,\n",
      "       0.00156601, 0.00134918, 0.00121784, 0.00118615, 0.00118017,\n",
      "       0.00235438, 0.00124358, 0.00163705, 0.00124581, 0.00186821,\n",
      "       0.00136252, 0.00069318, 0.00097851, 0.0015126 , 0.00115304,\n",
      "       0.00141913, 0.00118318, 0.00130275, 0.00131001, 0.00135035,\n",
      "       0.00140014, 0.00121606, 0.00148809, 0.00128453, 0.00169773,\n",
      "       0.00094377, 0.00120344, 0.00145021, 0.00185886, 0.00111144,\n",
      "       0.0014632 , 0.00124141, 0.00150773, 0.00104743, 0.00131793,\n",
      "       0.00119562, 0.00125287, 0.00158138, 0.00106851, 0.00112158,\n",
      "       0.00142825, 0.00074041, 0.00134434, 0.00106608, 0.00124302,\n",
      "       0.00157357, 0.001053  , 0.00182964, 0.0012188 , 0.00124679,\n",
      "       0.00177214, 0.00121495, 0.00156497, 0.00141585, 0.00142772,\n",
      "       0.00117763, 0.00112649, 0.00133037, 0.00133867, 0.00172331,\n",
      "       0.00123313, 0.00121668, 0.00095375, 0.00183319, 0.00173563,\n",
      "       0.00139671, 0.00162062, 0.00084242, 0.00119809, 0.00117564,\n",
      "       0.00138497, 0.00117132, 0.0011656 , 0.00089056, 0.00142759,\n",
      "       0.00116189, 0.0013902 , 0.00173635, 0.00080578, 0.00164954,\n",
      "       0.00110629, 0.00177349, 0.00110768, 0.0014018 , 0.00144359,\n",
      "       0.00133977, 0.00143903, 0.00146502, 0.00137745, 0.00154241,\n",
      "       0.00139625, 0.00165439, 0.00138895, 0.00166377, 0.00125799,\n",
      "       0.00094698, 0.00110432, 0.00187862, 0.00108135, 0.00153952,\n",
      "       0.00107717, 0.00132988, 0.00121975, 0.00110902, 0.00122921,\n",
      "       0.00168658, 0.00095244, 0.00138414, 0.00145554, 0.00195394,\n",
      "       0.00113507, 0.0011953 , 0.00124654, 0.0011847 , 0.00110812,\n",
      "       0.00107264, 0.0019497 , 0.00135785, 0.0008095 , 0.00171793,\n",
      "       0.00127694, 0.00136159, 0.00140271, 0.00202595, 0.00153739,\n",
      "       0.00153073, 0.00091414, 0.00114501, 0.00132886, 0.00137497,\n",
      "       0.00154835, 0.00142875, 0.0013465 , 0.00094587, 0.00138724,\n",
      "       0.00182274, 0.00137243, 0.00102622, 0.00130669, 0.00105707,\n",
      "       0.00099287, 0.00106218, 0.00134801, 0.00137155, 0.00173469,\n",
      "       0.00133195, 0.00144928, 0.0012797 , 0.00128292, 0.00193623,\n",
      "       0.00139455, 0.00150299, 0.00140336, 0.00105342, 0.00172797,\n",
      "       0.00153806, 0.00172913], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer21/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 94,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.6553122e-05, 3.2561540e-05, 3.3080065e-05, 5.8564008e-05,\n",
      "       1.9961202e-05, 3.0585543e-05, 3.0365063e-05, 2.7464535e-05,\n",
      "       3.0935764e-05, 5.5297362e-05, 3.3787859e-05, 3.8105030e-05,\n",
      "       3.5370165e-05, 2.7760441e-05, 2.1872032e-05, 2.9264207e-05,\n",
      "       2.8660210e-05, 3.8380545e-05, 3.1115684e-05, 2.6474490e-05,\n",
      "       3.1065771e-05, 2.5848707e-05, 2.5419955e-05, 3.1977568e-05,\n",
      "       2.4327970e-05, 2.4238461e-05, 3.1001819e-05, 3.9498449e-05,\n",
      "       3.2085809e-05, 2.6508980e-05, 2.8155391e-05, 2.8980812e-05,\n",
      "       2.9945728e-05, 1.9008541e-05, 3.3149779e-05, 3.0401612e-05,\n",
      "       3.2061020e-05, 2.3554830e-05, 3.1824005e-05, 2.9391213e-05,\n",
      "       3.9773691e-05, 3.1501753e-05, 3.9615861e-05, 2.9473111e-05,\n",
      "       3.6159072e-05, 2.7874721e-05, 3.9226776e-05, 3.3119883e-05,\n",
      "       1.7553544e-05, 4.2638283e-05, 4.4377874e-05, 2.7748116e-05,\n",
      "       3.4609817e-05, 3.1704247e-05, 3.1820924e-05, 3.8271766e-05,\n",
      "       2.6331254e-05, 3.3681656e-05, 3.1806296e-05, 3.4682438e-05,\n",
      "       2.9482115e-05, 2.7511713e-05, 1.7749797e-05, 2.6054819e-05,\n",
      "       3.1914158e-05, 2.7817301e-05, 1.8580664e-05, 3.1381373e-05,\n",
      "       3.3583583e-05, 2.5699504e-05, 3.7124668e-05, 2.3636338e-05,\n",
      "       3.1400668e-05, 4.6188812e-05, 3.6757352e-05, 2.4252327e-05,\n",
      "       3.2631029e-05, 3.7982449e-05, 2.5534920e-05, 2.8359264e-05,\n",
      "       2.8702143e-05, 2.4285231e-05, 3.7218964e-05, 3.1115254e-05,\n",
      "       3.0473246e-05, 2.6175134e-05, 2.5997040e-05, 3.7289745e-05,\n",
      "       3.1060186e-05, 3.0014542e-05, 3.7327121e-05, 3.0752406e-05,\n",
      "       3.7699894e-05, 3.1717951e-05, 3.7350372e-05, 2.9005982e-05,\n",
      "       3.4107688e-05, 3.0874970e-05, 2.6361138e-05, 2.4366615e-05,\n",
      "       3.2663705e-05, 2.0736017e-05, 2.7809920e-05, 2.9746880e-05,\n",
      "       2.2566537e-05, 3.8377995e-05, 2.8320284e-05, 2.9053299e-05,\n",
      "       3.1891926e-05, 3.1136533e-05, 2.1286578e-05, 2.7618675e-05,\n",
      "       2.9620314e-05, 3.3671800e-05, 2.5232721e-05, 3.2519652e-05,\n",
      "       2.5468016e-05, 1.9333471e-05, 3.0729643e-05, 2.9090823e-05,\n",
      "       3.4558121e-05, 2.3571907e-05, 3.5123918e-05, 3.5760964e-05,\n",
      "       2.7566277e-05, 2.6515771e-05, 3.2026310e-05, 2.8421475e-05,\n",
      "       2.0062256e-05, 3.1257987e-05, 4.3696142e-05, 3.0517102e-05,\n",
      "       3.2486791e-05, 1.8249153e-05, 3.4378270e-05, 2.4481773e-05,\n",
      "       2.7945724e-05, 3.1582455e-05, 3.5012534e-05, 2.8669394e-05,\n",
      "       3.2873377e-05, 2.0236343e-05, 3.1999902e-05, 3.1576252e-05,\n",
      "       2.6820870e-05, 3.6862377e-05, 3.5930832e-05, 2.0110676e-05,\n",
      "       4.6406039e-05, 3.0993568e-05, 2.6980930e-05, 2.8983906e-05,\n",
      "       3.6557656e-05, 2.9960174e-05, 3.9979601e-05, 2.6785649e-05,\n",
      "       2.6563454e-05, 3.3334283e-05, 2.8172019e-05, 3.7060450e-05,\n",
      "       3.3057997e-05, 3.0779454e-05, 3.0799511e-05, 2.4932540e-05,\n",
      "       2.7700531e-05, 2.1335694e-05, 3.3750493e-05, 2.8262391e-05,\n",
      "       1.9981351e-05, 2.9072393e-05, 3.3197706e-05, 2.6871357e-05,\n",
      "       3.3921788e-05, 2.6798416e-05, 3.9567858e-05, 2.2489914e-05,\n",
      "       3.0925879e-05, 2.6913714e-05, 4.4018096e-05, 2.0237905e-05,\n",
      "       3.4374596e-05, 3.0373612e-05, 2.9053112e-05, 3.6788253e-05,\n",
      "       3.9376311e-05, 5.0928942e-05, 2.0108029e-05, 3.6809142e-05,\n",
      "       2.8508139e-05, 2.5904481e-05, 4.1149360e-05, 2.6604643e-05,\n",
      "       2.6991114e-05, 3.0896790e-05, 2.7662409e-05, 2.7343187e-05,\n",
      "       2.9176808e-05, 2.8488015e-05, 2.7296775e-05, 3.5867193e-05,\n",
      "       3.1532538e-05, 2.4515313e-05, 3.3629094e-05, 2.3736862e-05,\n",
      "       2.9347988e-05, 3.3756703e-05, 3.3564636e-05, 2.7162851e-05,\n",
      "       3.4557266e-05, 3.1974665e-05, 3.2866483e-05, 2.9306548e-05,\n",
      "       3.9259208e-05, 2.5298663e-05, 2.8667235e-05, 3.1329590e-05,\n",
      "       3.7649213e-05, 5.5510442e-05, 3.4887420e-05, 3.6445825e-05,\n",
      "       3.4881708e-05, 5.8777008e-05, 2.2466031e-05, 3.9074799e-05,\n",
      "       4.5580509e-05, 3.5057696e-05, 2.4287965e-05, 2.7502074e-05,\n",
      "       3.8932183e-05, 3.2579395e-05, 3.4676617e-05, 3.7251895e-05,\n",
      "       3.6473892e-05, 2.4654626e-05, 3.1036321e-05, 3.6416372e-05,\n",
      "       3.8600436e-05, 3.1245327e-05, 2.2877153e-05, 3.3524106e-05,\n",
      "       2.7326379e-05, 2.4152027e-05, 2.4638231e-05, 3.6948677e-05,\n",
      "       3.0344872e-05, 4.0531697e-05, 2.4061146e-05, 3.0453972e-05,\n",
      "       3.3332970e-05, 2.7321212e-05, 3.3431796e-05, 3.0793701e-05,\n",
      "       2.7607461e-05, 2.6742679e-05, 2.5571371e-05, 2.0349255e-05,\n",
      "       1.7167176e-05, 2.2668946e-05, 2.9449919e-05, 3.1402058e-05,\n",
      "       2.6033553e-05, 3.8517373e-05, 5.2039733e-05, 3.8158592e-05,\n",
      "       4.1425916e-05, 2.5510337e-05, 2.8512834e-05, 2.9475817e-05,\n",
      "       2.5717747e-05, 4.4308763e-05, 3.1440868e-05, 3.8825088e-05,\n",
      "       3.8672675e-05, 2.4322591e-05, 3.1620937e-05, 2.7301579e-05,\n",
      "       3.1848402e-05, 3.5283159e-05, 2.5446081e-05, 3.8929338e-05,\n",
      "       3.3957367e-05, 3.6717069e-05, 2.8657892e-05, 3.0064799e-05,\n",
      "       2.6244696e-05, 2.7351747e-05, 3.2376764e-05, 2.8841954e-05,\n",
      "       4.2887088e-05, 2.6698515e-05, 2.9281884e-05, 2.5191810e-05,\n",
      "       2.6582798e-05, 2.8797525e-05, 2.7711103e-05, 4.2124517e-05,\n",
      "       2.6620952e-05, 3.8326169e-05, 3.2276803e-05, 3.3138764e-05,\n",
      "       2.5333913e-05, 2.4304290e-05, 3.0849933e-05, 3.7400543e-05,\n",
      "       2.4672830e-05, 3.6572044e-05, 3.2398711e-05, 4.1471165e-05,\n",
      "       3.0957901e-05, 3.7839989e-05, 4.1213050e-05, 3.1864933e-05,\n",
      "       2.4296192e-05, 3.1117088e-05, 3.0096071e-05, 1.8661902e-05,\n",
      "       3.5058973e-05, 2.5863637e-05, 3.1492207e-05, 3.8845807e-05,\n",
      "       3.6299680e-05, 2.6751737e-05, 3.3553661e-05, 3.8498983e-05,\n",
      "       2.5364343e-05, 3.0809977e-05, 4.1573639e-05, 1.3712988e-05,\n",
      "       2.9005863e-05, 3.7007412e-05, 3.4316985e-05, 2.4047607e-05,\n",
      "       3.3415909e-05, 3.5890374e-05, 2.3300883e-05, 3.3158773e-05,\n",
      "       3.3339547e-05, 3.0933443e-05, 2.7685306e-05, 3.1885320e-05,\n",
      "       2.6603617e-05, 3.1195468e-05, 2.4694838e-05, 3.6956739e-05,\n",
      "       4.6159326e-05, 1.9824845e-05, 2.6861921e-05, 2.3286215e-05,\n",
      "       3.0167705e-05, 4.3529461e-05, 4.2820127e-05, 2.4940049e-05,\n",
      "       3.1150146e-05, 2.9284305e-05, 2.7103550e-05, 3.6847181e-05,\n",
      "       3.1745469e-05, 2.8655062e-05, 2.7909344e-05, 2.7768670e-05,\n",
      "       5.5397151e-05, 2.9260818e-05, 3.8518891e-05, 2.9313094e-05,\n",
      "       4.3957982e-05, 3.2059201e-05, 1.6310149e-05, 2.3023809e-05,\n",
      "       3.5590689e-05, 2.7130318e-05, 3.3391316e-05, 2.7839575e-05,\n",
      "       3.0653046e-05, 3.0823703e-05, 3.1772965e-05, 3.2944536e-05,\n",
      "       2.8613140e-05, 3.5013956e-05, 3.0224339e-05, 3.9946630e-05,\n",
      "       2.2206390e-05, 2.8316299e-05, 3.4122626e-05, 4.3737939e-05,\n",
      "       2.6151569e-05, 3.4428147e-05, 2.9209679e-05, 3.5476012e-05,\n",
      "       2.4645513e-05, 3.1010091e-05, 2.8132330e-05, 2.9479212e-05,\n",
      "       3.7208891e-05, 2.5141388e-05, 2.6390022e-05, 3.3605829e-05,\n",
      "       1.7421467e-05, 3.1631571e-05, 2.5084275e-05, 2.9247436e-05,\n",
      "       3.7025147e-05, 2.4776373e-05, 4.3050433e-05, 2.8677718e-05,\n",
      "       2.9336130e-05, 4.1697385e-05, 2.8587096e-05, 3.6822894e-05,\n",
      "       3.3314169e-05, 3.3593380e-05, 2.7708837e-05, 2.6505699e-05,\n",
      "       3.1302770e-05, 3.1498093e-05, 4.0548388e-05, 2.9014802e-05,\n",
      "       2.8627723e-05, 2.2441160e-05, 4.3133881e-05, 4.0838266e-05,\n",
      "       3.2863856e-05, 3.8132290e-05, 1.9821540e-05, 2.8190241e-05,\n",
      "       2.7662169e-05, 3.2587595e-05, 2.7560372e-05, 2.7425807e-05,\n",
      "       2.0954387e-05, 3.3590422e-05, 2.7338498e-05, 3.2710697e-05,\n",
      "       4.0855317e-05, 1.8959605e-05, 3.8812705e-05, 2.6030340e-05,\n",
      "       4.1729138e-05, 2.6062997e-05, 3.2983593e-05, 3.3966804e-05,\n",
      "       3.1523923e-05, 3.3859560e-05, 3.4471064e-05, 3.2410619e-05,\n",
      "       3.6292080e-05, 3.2853048e-05, 3.8926904e-05, 3.2681171e-05,\n",
      "       3.9147544e-05, 2.9599676e-05, 2.2281905e-05, 2.5984038e-05,\n",
      "       4.4202763e-05, 2.5443585e-05, 3.6223941e-05, 2.5345167e-05,\n",
      "       3.1291180e-05, 2.8700100e-05, 2.6094500e-05, 2.8922605e-05,\n",
      "       3.9684306e-05, 2.2410399e-05, 3.2568023e-05, 3.4248111e-05,\n",
      "       4.5975019e-05, 2.6707536e-05, 2.8124707e-05, 2.9330406e-05,\n",
      "       2.7875345e-05, 2.6073370e-05, 2.5238647e-05, 4.5875375e-05,\n",
      "       3.1949305e-05, 1.9047004e-05, 4.0421801e-05, 3.0045720e-05,\n",
      "       3.2037358e-05, 3.3004912e-05, 4.7669473e-05, 3.6173802e-05,\n",
      "       3.6017060e-05, 2.1509255e-05, 2.6941527e-05, 3.1267289e-05,\n",
      "       3.2352131e-05, 3.6431717e-05, 3.3617594e-05, 3.1682470e-05,\n",
      "       2.2255834e-05, 3.2640866e-05, 4.2887925e-05, 3.2292563e-05,\n",
      "       2.4146284e-05, 3.0745538e-05, 2.4872252e-05, 2.3361674e-05,\n",
      "       2.4992456e-05, 3.1717991e-05, 3.2271677e-05, 4.0816198e-05,\n",
      "       3.1339918e-05, 3.4100594e-05, 3.0110496e-05, 3.0186326e-05,\n",
      "       4.5558256e-05, 3.2812848e-05, 3.5364563e-05, 3.3020231e-05,\n",
      "       2.4786412e-05, 4.0658040e-05, 3.6189540e-05, 4.0685340e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer21/conv/Relu6;tower0/network/layer21/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer21/conv/Conv2D,\n",
      "index: 95,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer22/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer22/sepconv/depthwise;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 96,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00626577, 0.00604344, 0.0004378 , 0.00604907, 0.00778568,\n",
      "       0.00530121, 0.00502094, 0.00548475, 0.00864252, 0.0057196 ,\n",
      "       0.00865551, 0.00559258, 0.00381216, 0.00042734, 0.00623732,\n",
      "       0.00449229, 0.0048404 , 0.00690826, 0.0087593 , 0.01137591,\n",
      "       0.00594612, 0.01034786, 0.00736584, 0.00824321, 0.00012446,\n",
      "       0.00056441, 0.00594524, 0.00564417, 0.00630172, 0.01004174,\n",
      "       0.00810042, 0.00544502, 0.00827759, 0.00887274, 0.00683051,\n",
      "       0.00872364, 0.00849435, 0.00717953, 0.00751745, 0.00837701,\n",
      "       0.00020213, 0.0047712 , 0.00753391, 0.0088312 , 0.00594435,\n",
      "       0.01036752, 0.00504959, 0.00017757, 0.00047626, 0.0046724 ,\n",
      "       0.00892986, 0.00523793, 0.00623549, 0.01021229, 0.00023063,\n",
      "       0.00868366, 0.00741396, 0.00672096, 0.0040081 , 0.00466698,\n",
      "       0.00024276, 0.00520987, 0.00656677, 0.00722649, 0.00373558,\n",
      "       0.00020752, 0.00031314, 0.00510052, 0.00672888, 0.00440692,\n",
      "       0.00550064, 0.00580342, 0.00908087, 0.00018305, 0.00454549,\n",
      "       0.00619013, 0.00888191, 0.00426352, 0.00766992, 0.00592545,\n",
      "       0.00618614, 0.00961498, 0.00833431, 0.00650348, 0.01127173,\n",
      "       0.00743461, 0.00063864, 0.00736089, 0.00602827, 0.00911069,\n",
      "       0.00923571, 0.00634854, 0.00526951, 0.00799764, 0.00619369,\n",
      "       0.01243985, 0.00362181, 0.00695298, 0.012317  , 0.00749247,\n",
      "       0.00011658, 0.00804996, 0.00451244, 0.00453801, 0.00099807,\n",
      "       0.00594892, 0.00389766, 0.00683198, 0.00923287, 0.00538618,\n",
      "       0.006806  , 0.00597872, 0.00558815, 0.00839673, 0.00536432,\n",
      "       0.0081922 , 0.0068744 , 0.00795743, 0.00852141, 0.00516851,\n",
      "       0.00965889, 0.00476227, 0.00773863, 0.00504171, 0.00478335,\n",
      "       0.00595253, 0.00645204, 0.00670384, 0.01086358, 0.00898048,\n",
      "       0.00678775, 0.0044826 , 0.00450027, 0.00580344, 0.00511065,\n",
      "       0.0094544 , 0.00788804, 0.00481409, 0.00078526, 0.00513905,\n",
      "       0.00404785, 0.00801742, 0.00039996, 0.00738629, 0.00508751,\n",
      "       0.00717693, 0.0109612 , 0.00551645, 0.00677308, 0.01210448,\n",
      "       0.00422995, 0.00771754, 0.00586423, 0.00846874, 0.00441391,\n",
      "       0.00969775, 0.0100295 , 0.00618603, 0.00532417, 0.00423424,\n",
      "       0.00592608, 0.00667239, 0.00020793, 0.00604711, 0.0043499 ,\n",
      "       0.00033835, 0.00992843, 0.00484679, 0.00689441, 0.00566657,\n",
      "       0.00418942, 0.00780933, 0.00711798, 0.00599099, 0.00699956,\n",
      "       0.00653685, 0.00813101, 0.00031789, 0.00728669, 0.01105903,\n",
      "       0.004534  , 0.00802845, 0.00636266, 0.01005941, 0.00764876,\n",
      "       0.00701526, 0.00546617, 0.00667663, 0.00593288, 0.0115767 ,\n",
      "       0.00542079, 0.00400917, 0.00426269, 0.0059946 , 0.00478401,\n",
      "       0.00689675, 0.00492823, 0.00014464, 0.00749372, 0.00502661,\n",
      "       0.00658941, 0.00024994, 0.00564971, 0.00011452, 0.00437714,\n",
      "       0.00650104, 0.00574045, 0.00789518, 0.00517093, 0.00451579,\n",
      "       0.00722361, 0.0045974 , 0.01068847, 0.00420799, 0.00638275,\n",
      "       0.00692906, 0.00722517, 0.00440074, 0.00699835, 0.00593074,\n",
      "       0.00579356, 0.00720365, 0.00703213, 0.00522843, 0.00679016,\n",
      "       0.00657067, 0.00787195, 0.00483001, 0.00623576, 0.00659413,\n",
      "       0.00574163, 0.004473  , 0.00589005, 0.00836682, 0.00660737,\n",
      "       0.00924589, 0.00671989, 0.00619932, 0.00549535, 0.01008998,\n",
      "       0.00957685, 0.00594014, 0.01006368, 0.00535466, 0.00609993,\n",
      "       0.00501178, 0.0043324 , 0.00560724, 0.00023757, 0.00731438,\n",
      "       0.00805091, 0.0069627 , 0.00060638, 0.00891256, 0.00720484,\n",
      "       0.01039095, 0.00781741, 0.00588247, 0.00945765, 0.01013863,\n",
      "       0.00665192, 0.00611323, 0.00542116, 0.00958076, 0.00696467,\n",
      "       0.00499123, 0.0039266 , 0.00982892, 0.0111308 , 0.00724014,\n",
      "       0.00868451, 0.00557033, 0.00678808, 0.006679  , 0.00392949,\n",
      "       0.00027532, 0.00686953, 0.00393964, 0.00459512, 0.00684518,\n",
      "       0.00672704, 0.00425952, 0.00503907, 0.00573355, 0.00639551,\n",
      "       0.00848084, 0.00563713, 0.00957948, 0.00713878, 0.00049912,\n",
      "       0.0032699 , 0.00642647, 0.00014658, 0.00583516, 0.01076756,\n",
      "       0.00638937, 0.0060998 , 0.00955158, 0.00740908, 0.00584331,\n",
      "       0.00913919, 0.005702  , 0.00473985, 0.00711248, 0.00415146,\n",
      "       0.00479164, 0.0061628 , 0.00480683, 0.00905565, 0.00856092,\n",
      "       0.00803824, 0.00597884, 0.00529859, 0.00624925, 0.00569053,\n",
      "       0.00162906, 0.00585843, 0.00742382, 0.008717  , 0.00455832,\n",
      "       0.00474251, 0.00680959, 0.00511524, 0.00476565, 0.00538667,\n",
      "       0.00047222, 0.00628799, 0.01607749, 0.00653369, 0.0046824 ,\n",
      "       0.01092263, 0.00792461, 0.00840956, 0.00381446, 0.00048385,\n",
      "       0.00670887, 0.00491347, 0.0060465 , 0.0001143 , 0.00590979,\n",
      "       0.00785529, 0.0056934 , 0.00782396, 0.00828853, 0.00474451,\n",
      "       0.00050514, 0.00455586, 0.00503048, 0.00620505, 0.0063018 ,\n",
      "       0.00440116, 0.00052916, 0.00469158, 0.00442796, 0.00556651,\n",
      "       0.00473463, 0.00508584, 0.00760202, 0.00543305, 0.00705029,\n",
      "       0.0049898 , 0.0080459 , 0.00808556, 0.00522413, 0.00738556,\n",
      "       0.00489873, 0.0001917 , 0.00744792, 0.00878268, 0.00029418,\n",
      "       0.00504764, 0.00687975, 0.00657355, 0.00677857, 0.00517972,\n",
      "       0.0046555 , 0.0062001 , 0.00588744, 0.0101687 , 0.00519474,\n",
      "       0.00578105, 0.00706901, 0.00500459, 0.00638208, 0.00775394,\n",
      "       0.00928229, 0.00638474, 0.00949078, 0.00686161, 0.00829922,\n",
      "       0.00677994, 0.00698872, 0.00507557, 0.00023256, 0.0065526 ,\n",
      "       0.00474157, 0.00032492, 0.00442753, 0.00870531, 0.00570055,\n",
      "       0.00627164, 0.00589353, 0.00701957, 0.00607518, 0.00593848,\n",
      "       0.00510111, 0.01159408, 0.00795148, 0.00747421, 0.00564453,\n",
      "       0.00720989, 0.00439446, 0.0093622 , 0.00530835, 0.00618792,\n",
      "       0.00435189, 0.00534253, 0.00032294, 0.00854449, 0.00893874,\n",
      "       0.00516932, 0.00467885, 0.00572948, 0.00667989, 0.00789738,\n",
      "       0.00495894, 0.00020901, 0.00013848, 0.00693014, 0.00496414,\n",
      "       0.0060862 , 0.00853674, 0.00518303, 0.00034868, 0.00536077,\n",
      "       0.00014974, 0.00575773, 0.01193884, 0.00656104, 0.00531862,\n",
      "       0.00932976, 0.00832058, 0.00533853, 0.00434199, 0.00646584,\n",
      "       0.0079026 , 0.00493783, 0.00944756, 0.00586627, 0.00715372,\n",
      "       0.0063899 , 0.00819252, 0.00432251, 0.00051373, 0.0087432 ,\n",
      "       0.00041342, 0.00910016, 0.00918508, 0.00328165, 0.00436762,\n",
      "       0.00575732, 0.00032091, 0.00366406, 0.00644926, 0.00586451,\n",
      "       0.00560726, 0.00845783, 0.00366214, 0.00693191, 0.00869681,\n",
      "       0.00011487, 0.00670052, 0.00489686, 0.00011777, 0.00644432,\n",
      "       0.01008219, 0.00615801, 0.00905023, 0.00561807, 0.00341541,\n",
      "       0.00944388, 0.0079238 , 0.00647699, 0.00719653, 0.00438712,\n",
      "       0.00655458, 0.00853735, 0.01104235, 0.00464852, 0.00825929,\n",
      "       0.00563394, 0.00771187, 0.00731473, 0.00742582, 0.00627034,\n",
      "       0.00021686, 0.01215394, 0.0121484 , 0.01040505, 0.00697648,\n",
      "       0.00503331, 0.00582305, 0.00999978, 0.00532143, 0.0064613 ,\n",
      "       0.00457614, 0.00467519, 0.00532152, 0.0049477 , 0.00569615,\n",
      "       0.00638466, 0.00641287], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer22/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 97,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.47429993e-04, 1.42198493e-04, 1.03012508e-05, 1.42330959e-04,\n",
      "       1.83192358e-04, 1.24734375e-04, 1.18139673e-04, 1.29052904e-04,\n",
      "       2.03353527e-04, 1.34578790e-04, 2.03659059e-04, 1.31590074e-04,\n",
      "       8.96979836e-05, 1.00550869e-05, 1.46760591e-04, 1.05701038e-04,\n",
      "       1.13891816e-04, 1.62547178e-04, 2.06101118e-04, 2.67668394e-04,\n",
      "       1.39908720e-04, 2.43478949e-04, 1.73313776e-04, 1.93957894e-04,\n",
      "       2.92842537e-06, 1.32802097e-05, 1.39888085e-04, 1.32804111e-04,\n",
      "       1.48275678e-04, 2.36276304e-04, 1.90598192e-04, 1.28118030e-04,\n",
      "       1.94766923e-04, 2.08770289e-04, 1.60717798e-04, 2.05262142e-04,\n",
      "       1.99867049e-04, 1.68930215e-04, 1.76881149e-04, 1.97106012e-04,\n",
      "       4.75595107e-06, 1.12263486e-04, 1.77268375e-04, 2.07792968e-04,\n",
      "       1.39866985e-04, 2.43941584e-04, 1.18813987e-04, 4.17800129e-06,\n",
      "       1.12060234e-05, 1.09938919e-04, 2.10114304e-04, 1.23245336e-04,\n",
      "       1.46717401e-04, 2.40289286e-04, 5.42663929e-06, 2.04321419e-04,\n",
      "       1.74446235e-04, 1.58140159e-04, 9.43081686e-05, 1.09811197e-04,\n",
      "       5.71205510e-06, 1.22585232e-04, 1.54512221e-04, 1.70035113e-04,\n",
      "       8.78961000e-05, 4.88293654e-06, 7.36796756e-06, 1.20012257e-04,\n",
      "       1.58326526e-04, 1.03692255e-04, 1.29426946e-04, 1.36550952e-04,\n",
      "       2.13667474e-04, 4.30697992e-06, 1.06952706e-04, 1.45650061e-04,\n",
      "       2.08986137e-04, 1.00318161e-04, 1.80468749e-04, 1.39422453e-04,\n",
      "       1.45556201e-04, 2.26234741e-04, 1.96101493e-04, 1.53022993e-04,\n",
      "       2.65217153e-04, 1.74932124e-04, 1.50267297e-05, 1.73197390e-04,\n",
      "       1.41841680e-04, 2.14369255e-04, 2.17310779e-04, 1.49377476e-04,\n",
      "       1.23988590e-04, 1.88179780e-04, 1.45733953e-04, 2.92702345e-04,\n",
      "       8.52189551e-05, 1.63599427e-04, 2.89811695e-04, 1.76293441e-04,\n",
      "       2.74306740e-06, 1.89410915e-04, 1.06175052e-04, 1.06776781e-04,\n",
      "       2.34839918e-05, 1.39974683e-04, 9.17096768e-05, 1.60752577e-04,\n",
      "       2.17244102e-04, 1.26733546e-04, 1.60141091e-04, 1.40675649e-04,\n",
      "       1.31485838e-04, 1.97570233e-04, 1.26219267e-04, 1.92757725e-04,\n",
      "       1.61750679e-04, 1.87233731e-04, 2.00503724e-04, 1.21611898e-04,\n",
      "       2.27267898e-04, 1.12053523e-04, 1.82085394e-04, 1.18628486e-04,\n",
      "       1.12549358e-04, 1.40059521e-04, 1.51812797e-04, 1.57737522e-04,\n",
      "       2.55613704e-04, 2.11305378e-04, 1.59711693e-04, 1.05473053e-04,\n",
      "       1.05888757e-04, 1.36551520e-04, 1.20250566e-04, 2.22456569e-04,\n",
      "       1.85600846e-04, 1.13272778e-04, 1.84767960e-05, 1.20918885e-04,\n",
      "       9.52434493e-05, 1.88645179e-04, 9.41091457e-06, 1.73795124e-04,\n",
      "       1.19706201e-04, 1.68868864e-04, 2.57910491e-04, 1.29798762e-04,\n",
      "       1.59366638e-04, 2.84811365e-04, 9.95283190e-05, 1.81589232e-04,\n",
      "       1.37981857e-04, 1.99264396e-04, 1.03856823e-04, 2.28182456e-04,\n",
      "       2.35988264e-04, 1.45553611e-04, 1.25274513e-04, 9.96290764e-05,\n",
      "       1.39437150e-04, 1.56997485e-04, 4.89256718e-06, 1.42284873e-04,\n",
      "       1.02350634e-04, 7.96127188e-06, 2.33610088e-04, 1.14042115e-04,\n",
      "       1.62221448e-04, 1.33331181e-04, 9.85745282e-05, 1.83748911e-04,\n",
      "       1.67481790e-04, 1.40964476e-04, 1.64695564e-04, 1.53808141e-04,\n",
      "       1.91317871e-04, 7.47981130e-06, 1.71451553e-04, 2.60212488e-04,\n",
      "       1.06682368e-04, 1.88904756e-04, 1.49709682e-04, 2.36691907e-04,\n",
      "       1.79970928e-04, 1.65064950e-04, 1.28615808e-04, 1.57097224e-04,\n",
      "       1.39597207e-04, 2.72393023e-04, 1.27547988e-04, 9.43333798e-05,\n",
      "       1.00298632e-04, 1.41049328e-04, 1.12565016e-04, 1.62276570e-04,\n",
      "       1.15958384e-04, 3.40323277e-06, 1.76322734e-04, 1.18273070e-04,\n",
      "       1.55045040e-04, 5.88090506e-06, 1.32934380e-04, 2.69453926e-06,\n",
      "       1.02991515e-04, 1.52965586e-04, 1.35069393e-04, 1.85768877e-04,\n",
      "       1.21668912e-04, 1.06253829e-04, 1.69967374e-04, 1.08174070e-04,\n",
      "       2.51493359e-04, 9.90114349e-05, 1.50182444e-04, 1.63036791e-04,\n",
      "       1.70004001e-04, 1.03546714e-04, 1.64666955e-04, 1.39546886e-04,\n",
      "       1.36318966e-04, 1.69497551e-04, 1.65461868e-04, 1.23021950e-04,\n",
      "       1.59768533e-04, 1.54604058e-04, 1.85222452e-04, 1.13647380e-04,\n",
      "       1.46723687e-04, 1.55156027e-04, 1.35097129e-04, 1.05246967e-04,\n",
      "       1.38589370e-04, 1.96866429e-04, 1.55467467e-04, 2.17550434e-04,\n",
      "       1.58115145e-04, 1.45866419e-04, 1.29302236e-04, 2.37411325e-04,\n",
      "       2.25337732e-04, 1.39768017e-04, 2.36792446e-04, 1.25991995e-04,\n",
      "       1.43527752e-04, 1.17924341e-04, 1.01938931e-04, 1.31934954e-04,\n",
      "       5.58980810e-06, 1.72103042e-04, 1.89433165e-04, 1.63828241e-04,\n",
      "       1.42678318e-05, 2.09707228e-04, 1.69525592e-04, 2.44492985e-04,\n",
      "       1.83938944e-04, 1.38411080e-04, 2.22532821e-04, 2.38555891e-04,\n",
      "       1.56515671e-04, 1.43840676e-04, 1.27556690e-04, 2.25429729e-04,\n",
      "       1.63874487e-04, 1.17440752e-04, 9.23904809e-05, 2.31268772e-04,\n",
      "       2.61901208e-04, 1.70356288e-04, 2.04341472e-04, 1.31066656e-04,\n",
      "       1.59719522e-04, 1.57153030e-04, 9.24585838e-05, 6.47804563e-06,\n",
      "       1.61636068e-04, 9.26973298e-05, 1.08120461e-04, 1.61063130e-04,\n",
      "       1.58283277e-04, 1.00223886e-04, 1.18566393e-04, 1.34907037e-04,\n",
      "       1.50482490e-04, 1.99549278e-04, 1.32638277e-04, 2.25399592e-04,\n",
      "       1.67971273e-04, 1.17440504e-05, 7.69388789e-05, 1.51211076e-04,\n",
      "       3.44892919e-06, 1.37298004e-04, 2.53354287e-04, 1.50338092e-04,\n",
      "       1.43524652e-04, 2.24742951e-04, 1.74331362e-04, 1.37489595e-04,\n",
      "       2.15039865e-04, 1.34164671e-04, 1.11525856e-04, 1.67352482e-04,\n",
      "       9.76813026e-05, 1.12744478e-04, 1.45007012e-04, 1.13101785e-04,\n",
      "       2.13074221e-04, 2.01433329e-04, 1.89135069e-04, 1.40678676e-04,\n",
      "       1.24672675e-04, 1.47041079e-04, 1.33894820e-04, 3.83309052e-05,\n",
      "       1.37845447e-04, 1.74678178e-04, 2.05105986e-04, 1.07254695e-04,\n",
      "       1.11588357e-04, 1.60225653e-04, 1.20358651e-04, 1.12132875e-04,\n",
      "       1.26745246e-04, 1.11110085e-05, 1.47952727e-04, 3.78294004e-04,\n",
      "       1.53733810e-04, 1.10174238e-04, 2.57003150e-04, 1.86461344e-04,\n",
      "       1.97871981e-04, 8.97519058e-05, 1.13847609e-05, 1.57855684e-04,\n",
      "       1.15611059e-04, 1.42270597e-04, 2.68945882e-06, 1.39053853e-04,\n",
      "       1.84830264e-04, 1.33962472e-04, 1.84093282e-04, 1.95024186e-04,\n",
      "       1.11635527e-04, 1.18855869e-05, 1.07196676e-04, 1.18364180e-04,\n",
      "       1.46001170e-04, 1.48277686e-04, 1.03556682e-04, 1.24507133e-05,\n",
      "       1.10390065e-04, 1.04187333e-04, 1.30976667e-04, 1.11402944e-04,\n",
      "       1.19666714e-04, 1.78871094e-04, 1.27836582e-04, 1.65889185e-04,\n",
      "       1.17406955e-04, 1.89315382e-04, 1.90248538e-04, 1.22920799e-04,\n",
      "       1.73777822e-04, 1.15264251e-04, 4.51066035e-06, 1.75245194e-04,\n",
      "       2.06651253e-04, 6.92199501e-06, 1.18767901e-04, 1.61876495e-04,\n",
      "       1.54671783e-04, 1.59495699e-04, 1.21875710e-04, 1.09541201e-04,\n",
      "       1.45884769e-04, 1.38528092e-04, 2.39263609e-04, 1.22229103e-04,\n",
      "       1.36024712e-04, 1.66329584e-04, 1.17754949e-04, 1.50166685e-04,\n",
      "       1.82445554e-04, 2.18406931e-04, 1.50229185e-04, 2.23312381e-04,\n",
      "       1.61449629e-04, 1.95275672e-04, 1.59528048e-04, 1.64440426e-04,\n",
      "       1.19425218e-04, 5.47197214e-06, 1.54178793e-04, 1.11566296e-04,\n",
      "       7.64523065e-06, 1.04177154e-04, 2.04830925e-04, 1.34130518e-04,\n",
      "       1.47568033e-04, 1.38671254e-04, 1.65166362e-04, 1.42945457e-04,\n",
      "       1.39728829e-04, 1.20026147e-04, 2.72801990e-04, 1.87093770e-04,\n",
      "       1.75863752e-04, 1.32812580e-04, 1.69644394e-04, 1.03399063e-04,\n",
      "       2.20287155e-04, 1.24902246e-04, 1.45598096e-04, 1.02397338e-04,\n",
      "       1.25706705e-04, 7.59867589e-06, 2.01046729e-04, 2.10323386e-04,\n",
      "       1.21631027e-04, 1.10090645e-04, 1.34811358e-04, 1.57173898e-04,\n",
      "       1.85820725e-04, 1.16680880e-04, 4.91796618e-06, 3.25837550e-06,\n",
      "       1.63062214e-04, 1.16803349e-04, 1.43204728e-04, 2.00864393e-04,\n",
      "       1.21953613e-04, 8.20427613e-06, 1.26135652e-04, 3.52323855e-06,\n",
      "       1.35476046e-04, 2.80913897e-04, 1.54377311e-04, 1.25144055e-04,\n",
      "       2.19523718e-04, 1.95778295e-04, 1.25612365e-04, 1.02164420e-04,\n",
      "       1.52137480e-04, 1.85943616e-04, 1.16184179e-04, 2.22295610e-04,\n",
      "       1.38029965e-04, 1.68322920e-04, 1.50350621e-04, 1.92765103e-04,\n",
      "       1.01706093e-04, 1.20878594e-05, 2.05722448e-04, 9.72755515e-06,\n",
      "       2.14121392e-04, 2.16119544e-04, 7.72152198e-05, 1.02767648e-04,\n",
      "       1.35466413e-04, 7.55076690e-06, 8.62132583e-05, 1.51747241e-04,\n",
      "       1.37988551e-04, 1.31935594e-04, 1.99007845e-04, 8.61679146e-05,\n",
      "       1.63103759e-04, 2.04630851e-04, 2.70290752e-06, 1.57659248e-04,\n",
      "       1.15220151e-04, 2.77112599e-06, 1.51631059e-04, 2.37227912e-04,\n",
      "       1.44894264e-04, 2.12946543e-04, 1.32189962e-04, 8.03625153e-05,\n",
      "       2.22208881e-04, 1.86442412e-04, 1.52399662e-04, 1.69330044e-04,\n",
      "       1.03226303e-04, 1.54225520e-04, 2.00878945e-04, 2.59820081e-04,\n",
      "       1.09377012e-04, 1.94336171e-04, 1.32563306e-04, 1.81455776e-04,\n",
      "       1.72111351e-04, 1.74725152e-04, 1.47537459e-04, 5.10263544e-06,\n",
      "       2.85974995e-04, 2.85844755e-04, 2.44824594e-04, 1.64152385e-04,\n",
      "       1.18430857e-04, 1.37012918e-04, 2.35288986e-04, 1.25210223e-04,\n",
      "       1.52030480e-04, 1.07673819e-04, 1.10004403e-04, 1.25212260e-04,\n",
      "       1.16416406e-04, 1.34027039e-04, 1.50227381e-04, 1.50891094e-04],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer22/sepconv/Relu6;tower0/network/layer22/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer22/sepconv/depthwise,\n",
      "index: 98,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer23/conv/Conv2D,\n",
      "index: 99,\n",
      "shape: [512   1   1 512],\n",
      "shape_signature: [512   1   1 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.0005841 , 0.00071908, 0.00077794, 0.00044743, 0.0012201 ,\n",
      "       0.00092518, 0.00045374, 0.00068107, 0.00069315, 0.00079804,\n",
      "       0.00090984, 0.0007312 , 0.00072833, 0.00083763, 0.00107472,\n",
      "       0.00069622, 0.00102515, 0.00059242, 0.00101693, 0.00096753,\n",
      "       0.00085014, 0.00063349, 0.00127514, 0.00087473, 0.00081765,\n",
      "       0.00133307, 0.00080502, 0.00072361, 0.00082575, 0.00055282,\n",
      "       0.00067052, 0.00073793, 0.0008644 , 0.00067543, 0.00059192,\n",
      "       0.00105312, 0.00075296, 0.00082424, 0.00066609, 0.0013037 ,\n",
      "       0.00075813, 0.00115195, 0.00071287, 0.00058458, 0.00134846,\n",
      "       0.00050511, 0.00082646, 0.00072739, 0.00041435, 0.00088447,\n",
      "       0.0008479 , 0.00131451, 0.00076262, 0.00082805, 0.00059158,\n",
      "       0.00098084, 0.00065894, 0.00070911, 0.00075575, 0.00095045,\n",
      "       0.00098557, 0.00048479, 0.00046081, 0.00115935, 0.00076318,\n",
      "       0.00037995, 0.00080776, 0.00103351, 0.00057479, 0.0010045 ,\n",
      "       0.00037069, 0.00095434, 0.00123099, 0.00083729, 0.00080582,\n",
      "       0.00049574, 0.00070594, 0.00096695, 0.00067375, 0.00107387,\n",
      "       0.00095558, 0.00108703, 0.00139049, 0.00062184, 0.00063391,\n",
      "       0.00105897, 0.00180972, 0.00104361, 0.00087599, 0.00092893,\n",
      "       0.00057729, 0.0011483 , 0.00064176, 0.00113025, 0.0003707 ,\n",
      "       0.00034232, 0.00072234, 0.00081758, 0.00110356, 0.00123029,\n",
      "       0.0004125 , 0.00123321, 0.00046204, 0.00052307, 0.0007169 ,\n",
      "       0.00074812, 0.00077618, 0.00080375, 0.00063959, 0.00058871,\n",
      "       0.00047156, 0.00056651, 0.00067355, 0.00108027, 0.00068096,\n",
      "       0.0013244 , 0.00078361, 0.00067118, 0.00085163, 0.00095335,\n",
      "       0.00080804, 0.00069614, 0.00116335, 0.00060283, 0.00071529,\n",
      "       0.00087361, 0.00061376, 0.00067296, 0.00076281, 0.00066271,\n",
      "       0.00105444, 0.00075293, 0.00052695, 0.00051702, 0.00080263,\n",
      "       0.00057139, 0.00043224, 0.00086301, 0.00101499, 0.00072798,\n",
      "       0.00077028, 0.00065333, 0.0010406 , 0.00049443, 0.00054468,\n",
      "       0.0008759 , 0.00114371, 0.00095035, 0.00099229, 0.00059091,\n",
      "       0.00033539, 0.00116045, 0.00075595, 0.00066933, 0.00037956,\n",
      "       0.00038624, 0.00084988, 0.00094276, 0.00170292, 0.00054985,\n",
      "       0.00091799, 0.00091314, 0.00122875, 0.00065949, 0.00073911,\n",
      "       0.00043419, 0.00085967, 0.00078531, 0.00040178, 0.00099145,\n",
      "       0.00086899, 0.00035488, 0.00067733, 0.00130454, 0.00050453,\n",
      "       0.00055957, 0.00076595, 0.0005877 , 0.00092568, 0.00075234,\n",
      "       0.00079258, 0.00086691, 0.0012855 , 0.00039726, 0.00090154,\n",
      "       0.00154266, 0.00047309, 0.00044261, 0.0010799 , 0.00089578,\n",
      "       0.00062637, 0.00077431, 0.00056939, 0.00039421, 0.00092552,\n",
      "       0.00092263, 0.00115222, 0.00119992, 0.00093433, 0.00103526,\n",
      "       0.00052215, 0.00106823, 0.00061695, 0.00104405, 0.00048093,\n",
      "       0.00110974, 0.00237123, 0.00050759, 0.00067414, 0.00049354,\n",
      "       0.00107118, 0.00078436, 0.00064641, 0.00124443, 0.00050926,\n",
      "       0.00042798, 0.00099729, 0.00063066, 0.00081817, 0.00038996,\n",
      "       0.0009511 , 0.00046034, 0.0007626 , 0.00151879, 0.00095828,\n",
      "       0.00106898, 0.00063746, 0.00035204, 0.00108266, 0.00209431,\n",
      "       0.00112923, 0.00081146, 0.00040417, 0.00151891, 0.00121444,\n",
      "       0.00072907, 0.00051145, 0.00089205, 0.00051469, 0.00128146,\n",
      "       0.0006536 , 0.00079259, 0.00083773, 0.00119802, 0.0007837 ,\n",
      "       0.00107549, 0.00085147, 0.00037679, 0.0004092 , 0.00082804,\n",
      "       0.00050586, 0.00037681, 0.00056134, 0.00118213, 0.00054337,\n",
      "       0.00094249, 0.00076906, 0.00081736, 0.00065695, 0.00109058,\n",
      "       0.00125233, 0.00033539, 0.00098972, 0.00093087, 0.00111702,\n",
      "       0.00044073, 0.00106977, 0.00077252, 0.00123215, 0.00098322,\n",
      "       0.00095081, 0.00172056, 0.00071976, 0.0003522 , 0.00058882,\n",
      "       0.00095413, 0.00088321, 0.00090245, 0.00038235, 0.00100143,\n",
      "       0.00092662, 0.000759  , 0.00135541, 0.00069247, 0.0004282 ,\n",
      "       0.00092683, 0.0009446 , 0.00077106, 0.00141462, 0.00056474,\n",
      "       0.00094739, 0.00060104, 0.00076837, 0.0009422 , 0.00047273,\n",
      "       0.00113893, 0.00126767, 0.00058166, 0.00099577, 0.00094974,\n",
      "       0.00047088, 0.00053747, 0.00065677, 0.00144442, 0.00083375,\n",
      "       0.00034406, 0.00040316, 0.00129059, 0.00111213, 0.00082139,\n",
      "       0.00095159, 0.00116432, 0.00048064, 0.0005791 , 0.00126529,\n",
      "       0.00084677, 0.00064723, 0.00073341, 0.00085566, 0.00045301,\n",
      "       0.00086378, 0.00040834, 0.00066225, 0.00084729, 0.00065428,\n",
      "       0.00086466, 0.00061511, 0.00122694, 0.00063877, 0.000994  ,\n",
      "       0.00085478, 0.00083669, 0.00069597, 0.00037746, 0.00077067,\n",
      "       0.00096757, 0.00077577, 0.00093275, 0.00107958, 0.0003848 ,\n",
      "       0.00072621, 0.00043576, 0.00041877, 0.00086728, 0.00070053,\n",
      "       0.00062616, 0.00144842, 0.00067573, 0.00079196, 0.00070278,\n",
      "       0.00048585, 0.00096765, 0.00122332, 0.00079492, 0.00044817,\n",
      "       0.00074474, 0.00095307, 0.00069486, 0.00118772, 0.00071335,\n",
      "       0.00085423, 0.00082867, 0.00037872, 0.0003658 , 0.00072083,\n",
      "       0.00093992, 0.00042184, 0.00109723, 0.00150025, 0.00091721,\n",
      "       0.00065465, 0.00118073, 0.00059068, 0.00096667, 0.00039549,\n",
      "       0.00120967, 0.00060827, 0.00093608, 0.00032833, 0.00101785,\n",
      "       0.00072652, 0.00126868, 0.00167363, 0.00139661, 0.00090844,\n",
      "       0.00053263, 0.00065412, 0.00067296, 0.00093974, 0.00105243,\n",
      "       0.00093995, 0.00040358, 0.00042459, 0.00140485, 0.00100325,\n",
      "       0.00057456, 0.00079726, 0.00056143, 0.0009888 , 0.00070903,\n",
      "       0.000375  , 0.00083927, 0.00093838, 0.00068052, 0.0006515 ,\n",
      "       0.00095813, 0.00048195, 0.00099835, 0.00061106, 0.00090598,\n",
      "       0.00086241, 0.00110573, 0.00091998, 0.00065139, 0.00111518,\n",
      "       0.00058895, 0.00043691, 0.00057294, 0.0010262 , 0.00126111,\n",
      "       0.0005086 , 0.00075602, 0.00077279, 0.00076472, 0.00101816,\n",
      "       0.0005678 , 0.00072115, 0.00062607, 0.00056381, 0.00086488,\n",
      "       0.00130541, 0.00049784, 0.00063124, 0.00094018, 0.00053038,\n",
      "       0.00119291, 0.00052992, 0.00108977, 0.00061272, 0.00157684,\n",
      "       0.00071351, 0.00056172, 0.00135301, 0.0008518 , 0.00085862,\n",
      "       0.00079254, 0.00064031, 0.00099627, 0.00075343, 0.00090821,\n",
      "       0.0009249 , 0.00075319, 0.00085223, 0.00046668, 0.00100982,\n",
      "       0.00094775, 0.00115556, 0.00086477, 0.00064659, 0.00106906,\n",
      "       0.00048325, 0.00107462, 0.00049486, 0.0012954 , 0.00075848,\n",
      "       0.00053018, 0.00107556, 0.00054661, 0.00060447, 0.00101392,\n",
      "       0.0006823 , 0.00091291, 0.00107017, 0.00045383, 0.00030489,\n",
      "       0.00075622, 0.00111917, 0.00069871, 0.00099217, 0.00099094,\n",
      "       0.00062078, 0.00180129, 0.00049732, 0.00095676, 0.00089558,\n",
      "       0.00056622, 0.00107748, 0.00114516, 0.00054899, 0.00099956,\n",
      "       0.00082071, 0.00079722, 0.00115192, 0.00117475, 0.0011182 ,\n",
      "       0.00090887, 0.00103002, 0.00084582, 0.00033125, 0.00070801,\n",
      "       0.00058805, 0.00074614, 0.00059949, 0.00068804, 0.00092652,\n",
      "       0.00120266, 0.00037485, 0.00045903, 0.00122609, 0.0006878 ,\n",
      "       0.00092441, 0.0005125 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer23/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 100,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.37434918e-05, 1.69195555e-05, 1.83045231e-05, 1.05278141e-05,\n",
      "       2.87082057e-05, 2.17690049e-05, 1.06761654e-05, 1.60251529e-05,\n",
      "       1.63094755e-05, 1.87775240e-05, 2.14080137e-05, 1.72045984e-05,\n",
      "       1.71372521e-05, 1.97090194e-05, 2.52875689e-05, 1.63815839e-05,\n",
      "       2.41212201e-05, 1.39393624e-05, 2.39278052e-05, 2.27652981e-05,\n",
      "       2.00033719e-05, 1.49055404e-05, 3.00032589e-05, 2.05819033e-05,\n",
      "       1.92387306e-05, 3.13664423e-05, 1.89417478e-05, 1.70260719e-05,\n",
      "       1.94293971e-05, 1.30075305e-05, 1.57768463e-05, 1.73630779e-05,\n",
      "       2.03387481e-05, 1.58925250e-05, 1.39275280e-05, 2.47793523e-05,\n",
      "       1.77166858e-05, 1.93939868e-05, 1.56727456e-05, 3.06752299e-05,\n",
      "       1.78382779e-05, 2.71047065e-05, 1.67735016e-05, 1.37547386e-05,\n",
      "       3.17283702e-05, 1.18848939e-05, 1.94461591e-05, 1.71150896e-05,\n",
      "       9.74931481e-06, 2.08110796e-05, 1.99505903e-05, 3.09297538e-05,\n",
      "       1.79440412e-05, 1.94834138e-05, 1.39194135e-05, 2.30785736e-05,\n",
      "       1.55045072e-05, 1.66849295e-05, 1.77823040e-05, 2.23636143e-05,\n",
      "       2.31897920e-05, 1.14067216e-05, 1.08424974e-05, 2.72787256e-05,\n",
      "       1.79571289e-05, 8.94007371e-06, 1.90061619e-05, 2.43179857e-05,\n",
      "       1.35245682e-05, 2.36353080e-05, 8.72204146e-06, 2.24551259e-05,\n",
      "       2.89644340e-05, 1.97008376e-05, 1.89605507e-05, 1.16644069e-05,\n",
      "       1.66103910e-05, 2.27517885e-05, 1.58530020e-05, 2.52676255e-05,\n",
      "       2.24841933e-05, 2.55772466e-05, 3.27174530e-05, 1.46315451e-05,\n",
      "       1.49154930e-05, 2.49170371e-05, 4.25816615e-05, 2.45555257e-05,\n",
      "       2.06116183e-05, 2.18570876e-05, 1.35832361e-05, 2.70187811e-05,\n",
      "       1.51001741e-05, 2.65941526e-05, 8.72223973e-06, 8.05465061e-06,\n",
      "       1.69961240e-05, 1.92370826e-05, 2.59661774e-05, 2.89479740e-05,\n",
      "       9.70582278e-06, 2.90166263e-05, 1.08715167e-05, 1.23076161e-05,\n",
      "       1.68681836e-05, 1.76027643e-05, 1.82630174e-05, 1.89118127e-05,\n",
      "       1.50491360e-05, 1.38518844e-05, 1.10954716e-05, 1.33296053e-05,\n",
      "       1.58482253e-05, 2.54182178e-05, 1.60225281e-05, 3.11624171e-05,\n",
      "       1.84379096e-05, 1.57924842e-05, 2.00383020e-05, 2.24318574e-05,\n",
      "       1.90126557e-05, 1.63797977e-05, 2.73730275e-05, 1.41841829e-05,\n",
      "       1.68303595e-05, 2.05556062e-05, 1.44413061e-05, 1.58342391e-05,\n",
      "       1.79483632e-05, 1.55931830e-05, 2.48103552e-05, 1.77159836e-05,\n",
      "       1.23988648e-05, 1.21651901e-05, 1.88854447e-05, 1.34444035e-05,\n",
      "       1.01704391e-05, 2.03061645e-05, 2.38821194e-05, 1.71289394e-05,\n",
      "       1.81242740e-05, 1.53724413e-05, 2.44845887e-05, 1.16337242e-05,\n",
      "       1.28159654e-05, 2.06094337e-05, 2.69107804e-05, 2.23611860e-05,\n",
      "       2.33480569e-05, 1.39038139e-05, 7.89156456e-06, 2.73046880e-05,\n",
      "       1.77869460e-05, 1.57488794e-05, 8.93083507e-06, 9.08798756e-06,\n",
      "       1.99972692e-05, 2.21826340e-05, 4.00686440e-05, 1.29377131e-05,\n",
      "       2.15998643e-05, 2.14855845e-05, 2.89116797e-05, 1.55174293e-05,\n",
      "       1.73908811e-05, 1.02162976e-05, 2.02276024e-05, 1.84778655e-05,\n",
      "       9.45354805e-06, 2.33283045e-05, 2.04467869e-05, 8.35003812e-06,\n",
      "       1.59371066e-05, 3.06949951e-05, 1.18711914e-05, 1.31662591e-05,\n",
      "       1.80223069e-05, 1.38281985e-05, 2.17805900e-05, 1.77021484e-05,\n",
      "       1.86488433e-05, 2.03978652e-05, 3.02471126e-05, 9.34723448e-06,\n",
      "       2.12127179e-05, 3.62979517e-05, 1.11314439e-05, 1.04143337e-05,\n",
      "       2.54093502e-05, 2.10770777e-05, 1.47381297e-05, 1.82190106e-05,\n",
      "       1.33973881e-05, 9.27541350e-06, 2.17768684e-05, 2.17090255e-05,\n",
      "       2.71109675e-05, 2.82333040e-05, 2.19842332e-05, 2.43590912e-05,\n",
      "       1.22859719e-05, 2.51347756e-05, 1.45164895e-05, 2.45658084e-05,\n",
      "       1.13159876e-05, 2.61115601e-05, 5.57935418e-05, 1.19433989e-05,\n",
      "       1.58621697e-05, 1.16126766e-05, 2.52042209e-05, 1.84556266e-05,\n",
      "       1.52096836e-05, 2.92807435e-05, 1.19826309e-05, 1.00701591e-05,\n",
      "       2.34657018e-05, 1.48390955e-05, 1.92511052e-05, 9.17543002e-06,\n",
      "       2.23788629e-05, 1.08316299e-05, 1.79434428e-05, 3.57362915e-05,\n",
      "       2.25477761e-05, 2.51523670e-05, 1.49989792e-05, 8.28329394e-06,\n",
      "       2.54742663e-05, 4.92778963e-05, 2.65700801e-05, 1.90931114e-05,\n",
      "       9.50990034e-06, 3.57390527e-05, 2.85749575e-05, 1.71546781e-05,\n",
      "       1.20342174e-05, 2.09895206e-05, 1.21104358e-05, 3.01519631e-05,\n",
      "       1.53787623e-05, 1.86492762e-05, 1.97113823e-05, 2.81886041e-05,\n",
      "       1.84399178e-05, 2.53056915e-05, 2.00344857e-05, 8.86559974e-06,\n",
      "       9.62820650e-06, 1.94833392e-05, 1.19025153e-05, 8.86622183e-06,\n",
      "       1.32079949e-05, 2.78147709e-05, 1.27850662e-05, 2.21762639e-05,\n",
      "       1.80954848e-05, 1.92319840e-05, 1.54577428e-05, 2.56607800e-05,\n",
      "       2.94664715e-05, 7.89148453e-06, 2.32874827e-05, 2.19027334e-05,\n",
      "       2.62827089e-05, 1.03701614e-05, 2.51710808e-05, 1.81769756e-05,\n",
      "       2.89916807e-05, 2.31346403e-05, 2.23719562e-05, 4.04838174e-05,\n",
      "       1.69354917e-05, 8.28702014e-06, 1.38546820e-05, 2.24500891e-05,\n",
      "       2.07813991e-05, 2.12341438e-05, 8.99640600e-06, 2.35630450e-05,\n",
      "       2.18028217e-05, 1.78588871e-05, 3.18919774e-05, 1.62933156e-05,\n",
      "       1.00751822e-05, 2.18076839e-05, 2.22259350e-05, 1.81426167e-05,\n",
      "       3.32852433e-05, 1.32879550e-05, 2.22914823e-05, 1.41421606e-05,\n",
      "       1.80793377e-05, 2.21693554e-05, 1.11231166e-05, 2.67982414e-05,\n",
      "       2.98275172e-05, 1.36861099e-05, 2.34299077e-05, 2.23468069e-05,\n",
      "       1.10795927e-05, 1.26462555e-05, 1.54533282e-05, 3.39864418e-05,\n",
      "       1.96177389e-05, 8.09549783e-06, 9.48608886e-06, 3.03667148e-05,\n",
      "       2.61677214e-05, 1.93268279e-05, 2.23902516e-05, 2.73956866e-05,\n",
      "       1.13091828e-05, 1.36259978e-05, 2.97715269e-05, 1.99240421e-05,\n",
      "       1.52289294e-05, 1.72567889e-05, 2.01332587e-05, 1.06590669e-05,\n",
      "       2.03243198e-05, 9.60796115e-06, 1.55824600e-05, 1.99363258e-05,\n",
      "       1.53949059e-05, 2.03449654e-05, 1.44732858e-05, 2.88692336e-05,\n",
      "       1.50298674e-05, 2.33882365e-05, 2.01125149e-05, 1.96867313e-05,\n",
      "       1.63756777e-05, 8.88132854e-06, 1.81334472e-05, 2.27663677e-05,\n",
      "       1.82534695e-05, 2.19470294e-05, 2.54019997e-05, 9.05401521e-06,\n",
      "       1.70871990e-05, 1.02532413e-05, 9.85342012e-06, 2.04064781e-05,\n",
      "       1.64830599e-05, 1.47332548e-05, 3.40803927e-05, 1.58995699e-05,\n",
      "       1.86342895e-05, 1.65359525e-05, 1.14318082e-05, 2.27683449e-05,\n",
      "       2.87840940e-05, 1.87038877e-05, 1.05452182e-05, 1.75233090e-05,\n",
      "       2.24251762e-05, 1.63497316e-05, 2.79464512e-05, 1.67847593e-05,\n",
      "       2.00995473e-05, 1.94981822e-05, 8.91114360e-06, 8.60706768e-06,\n",
      "       1.69607811e-05, 2.21157443e-05, 9.92560945e-06, 2.58172859e-05,\n",
      "       3.53000578e-05, 2.15814835e-05, 1.54036297e-05, 2.77819108e-05,\n",
      "       1.38983478e-05, 2.27450964e-05, 9.30562874e-06, 2.84627586e-05,\n",
      "       1.43121260e-05, 2.20254351e-05, 7.72532894e-06, 2.39495239e-05,\n",
      "       1.70945586e-05, 2.98512259e-05, 3.93794398e-05, 3.28612987e-05,\n",
      "       2.13750700e-05, 1.25325178e-05, 1.53910878e-05, 1.58344246e-05,\n",
      "       2.21115133e-05, 2.47629887e-05, 2.21165028e-05, 9.49601963e-06,\n",
      "       9.99032363e-06, 3.30553521e-05, 2.36059950e-05, 1.35190348e-05,\n",
      "       1.87589540e-05, 1.32101313e-05, 2.32659495e-05, 1.66831087e-05,\n",
      "       8.82347013e-06, 1.97475438e-05, 2.20794773e-05, 1.60121435e-05,\n",
      "       1.53293076e-05, 2.25443255e-05, 1.13399119e-05, 2.34906256e-05,\n",
      "       1.43778761e-05, 2.13171461e-05, 2.02920164e-05, 2.60171782e-05,\n",
      "       2.16466178e-05, 1.53268302e-05, 2.62394915e-05, 1.38576788e-05,\n",
      "       1.02801641e-05, 1.34809452e-05, 2.41457892e-05, 2.96732142e-05,\n",
      "       1.19671395e-05, 1.77887250e-05, 1.81831801e-05, 1.79935014e-05,\n",
      "       2.39567762e-05, 1.33600761e-05, 1.69682335e-05, 1.47311075e-05,\n",
      "       1.32660562e-05, 2.03501841e-05, 3.07156370e-05, 1.17139689e-05,\n",
      "       1.48526178e-05, 2.21219143e-05, 1.24795533e-05, 2.80685563e-05,\n",
      "       1.24688140e-05, 2.56416879e-05, 1.44168953e-05, 3.71020215e-05,\n",
      "       1.67884609e-05, 1.32170453e-05, 3.18356251e-05, 2.00423510e-05,\n",
      "       2.02027240e-05, 1.86479210e-05, 1.50662245e-05, 2.34416930e-05,\n",
      "       1.77276543e-05, 2.13696949e-05, 2.17622619e-05, 1.77220445e-05,\n",
      "       2.00525883e-05, 1.09806442e-05, 2.37604108e-05, 2.23000770e-05,\n",
      "       2.71896588e-05, 2.03474847e-05, 1.52138309e-05, 2.51544097e-05,\n",
      "       1.13705701e-05, 2.52852005e-05, 1.16437632e-05, 3.04799287e-05,\n",
      "       1.78465380e-05, 1.24748249e-05, 2.53071848e-05, 1.28614838e-05,\n",
      "       1.42229255e-05, 2.38568718e-05, 1.60540312e-05, 2.14803222e-05,\n",
      "       2.51803904e-05, 1.06782563e-05, 7.17387093e-06, 1.77934980e-05,\n",
      "       2.63334605e-05, 1.64402882e-05, 2.33452884e-05, 2.33162591e-05,\n",
      "       1.46066077e-05, 4.23832571e-05, 1.17016180e-05, 2.25121057e-05,\n",
      "       2.10724938e-05, 1.33228450e-05, 2.53524195e-05, 2.69448610e-05,\n",
      "       1.29173359e-05, 2.35191255e-05, 1.93108426e-05, 1.87580827e-05,\n",
      "       2.71039808e-05, 2.76411756e-05, 2.63106322e-05, 2.13850781e-05,\n",
      "       2.42358328e-05, 1.99016977e-05, 7.79405673e-06, 1.66590871e-05,\n",
      "       1.38364421e-05, 1.75562709e-05, 1.41056589e-05, 1.61892076e-05,\n",
      "       2.18004279e-05, 2.82977981e-05, 8.81999313e-06, 1.08007216e-05,\n",
      "       2.88492356e-05, 1.61836160e-05, 2.17507695e-05, 1.20587674e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer23/conv/Relu6;tower0/network/layer23/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise;tower0/network/layer23/conv/Conv2D,\n",
      "index: 101,\n",
      "shape: [  1   6   4 512],\n",
      "shape_signature: [  1   6   4 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.020902719348669052, -128),\n",
      "quantization_parameters: {'scales': array([0.02090272], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 102,\n",
      "shape: [  1   3   3 512],\n",
      "shape_signature: [  1   3   3 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00914893, 0.01197219, 0.02314813, 0.00115296, 0.00575574,\n",
      "       0.05484023, 0.00257619, 0.00078196, 0.01682565, 0.01945727,\n",
      "       0.00449676, 0.00817494, 0.01383279, 0.01405568, 0.01198889,\n",
      "       0.0387713 , 0.01570973, 0.01957552, 0.01667678, 0.0165859 ,\n",
      "       0.02333124, 0.02772476, 0.01242545, 0.0164392 , 0.00913102,\n",
      "       0.00815969, 0.00990424, 0.02059172, 0.02240305, 0.00176027,\n",
      "       0.02733976, 0.04646437, 0.00965887, 0.00674904, 0.01611556,\n",
      "       0.00652308, 0.01902524, 0.01291432, 0.02325865, 0.0055726 ,\n",
      "       0.02001386, 0.00501745, 0.01639237, 0.00061335, 0.00051809,\n",
      "       0.00183688, 0.00893937, 0.01581006, 0.00134784, 0.0193014 ,\n",
      "       0.01486721, 0.00820874, 0.01072912, 0.02088743, 0.00090843,\n",
      "       0.01438931, 0.04014864, 0.06026381, 0.02122396, 0.00042377,\n",
      "       0.01034613, 0.00060984, 0.00064149, 0.00530388, 0.00824802,\n",
      "       0.00170184, 0.01319438, 0.02458802, 0.0009355 , 0.02399961,\n",
      "       0.00131093, 0.00514042, 0.00999029, 0.00706753, 0.00431302,\n",
      "       0.02383528, 0.04157723, 0.00908178, 0.02948198, 0.01035814,\n",
      "       0.01119817, 0.0065098 , 0.00347752, 0.01574682, 0.05957317,\n",
      "       0.00654126, 0.00515794, 0.00763259, 0.02072314, 0.01525325,\n",
      "       0.01483599, 0.01024141, 0.02105053, 0.01988916, 0.0015657 ,\n",
      "       0.00150928, 0.00696962, 0.02857095, 0.05849372, 0.00636803,\n",
      "       0.00144224, 0.00501365, 0.00041181, 0.00099385, 0.04290225,\n",
      "       0.00696797, 0.00830916, 0.03347738, 0.02307537, 0.03007111,\n",
      "       0.00220558, 0.00035032, 0.00058446, 0.00681586, 0.00031843,\n",
      "       0.0049049 , 0.01232691, 0.01742058, 0.0194554 , 0.00901762,\n",
      "       0.01036588, 0.04361567, 0.00720209, 0.01241618, 0.02594697,\n",
      "       0.01382474, 0.03075801, 0.01052222, 0.01596945, 0.02745712,\n",
      "       0.00419665, 0.02060246, 0.02743832, 0.02980773, 0.0245239 ,\n",
      "       0.00096386, 0.00269255, 0.00019751, 0.00652053, 0.04041937,\n",
      "       0.01261632, 0.04051685, 0.00141921, 0.01277815, 0.00066836,\n",
      "       0.01858336, 0.0107118 , 0.01505938, 0.01285687, 0.00084168,\n",
      "       0.00142992, 0.00679887, 0.01949318, 0.00742497, 0.00238939,\n",
      "       0.00081491, 0.02050005, 0.0045894 , 0.00658862, 0.01780885,\n",
      "       0.0142797 , 0.01516227, 0.004716  , 0.01855794, 0.00088278,\n",
      "       0.00132083, 0.02185103, 0.02554476, 0.00144836, 0.00691883,\n",
      "       0.01879064, 0.00220326, 0.03683597, 0.01494273, 0.00110503,\n",
      "       0.02248879, 0.01655832, 0.01574307, 0.00661783, 0.1130973 ,\n",
      "       0.01971469, 0.01118932, 0.00843331, 0.00082045, 0.00995135,\n",
      "       0.00656275, 0.00095336, 0.00092891, 0.00828886, 0.00615956,\n",
      "       0.01025962, 0.01037977, 0.05049421, 0.00039747, 0.01062577,\n",
      "       0.01825901, 0.01220404, 0.00618587, 0.00893853, 0.01326737,\n",
      "       0.01568766, 0.00771907, 0.03176139, 0.00732348, 0.00080948,\n",
      "       0.01816899, 0.00526388, 0.0424701 , 0.02310431, 0.01578191,\n",
      "       0.00052229, 0.02537652, 0.01387001, 0.00569275, 0.00025518,\n",
      "       0.00268094, 0.00428852, 0.01120172, 0.02838822, 0.00174097,\n",
      "       0.01688919, 0.0017273 , 0.02012957, 0.00648921, 0.01643659,\n",
      "       0.00540141, 0.02749904, 0.00163242, 0.0057223 , 0.00899046,\n",
      "       0.00383087, 0.01958383, 0.0017517 , 0.00696665, 0.01312954,\n",
      "       0.02045632, 0.00197938, 0.01799289, 0.00119515, 0.00576087,\n",
      "       0.00064454, 0.00856728, 0.01703313, 0.00456561, 0.00811097,\n",
      "       0.00571635, 0.00795806, 0.0025579 , 0.00206757, 0.01246418,\n",
      "       0.0008852 , 0.00256237, 0.00163145, 0.00538153, 0.0109424 ,\n",
      "       0.01085121, 0.0177534 , 0.00642553, 0.0550613 , 0.00739997,\n",
      "       0.0043644 , 0.00221857, 0.05149159, 0.04572177, 0.00917421,\n",
      "       0.00097767, 0.02602297, 0.02379844, 0.01317999, 0.02277966,\n",
      "       0.03093241, 0.00630953, 0.0180943 , 0.00150712, 0.00069746,\n",
      "       0.00630872, 0.00666224, 0.0155807 , 0.00148901, 0.00550234,\n",
      "       0.01585153, 0.00790654, 0.01747821, 0.00891263, 0.00176808,\n",
      "       0.0098945 , 0.00802001, 0.00632642, 0.00710197, 0.01187982,\n",
      "       0.00675821, 0.03207659, 0.00062612, 0.00991048, 0.00095974,\n",
      "       0.0073152 , 0.00457482, 0.0016216 , 0.00898359, 0.0072073 ,\n",
      "       0.00259618, 0.0008422 , 0.03712662, 0.00812345, 0.02236605,\n",
      "       0.00275536, 0.00087929, 0.05594714, 0.01211792, 0.0162073 ,\n",
      "       0.01113952, 0.00755451, 0.00189776, 0.00135557, 0.00433216,\n",
      "       0.0362533 , 0.01840259, 0.00043219, 0.0086904 , 0.00302099,\n",
      "       0.03486043, 0.00112245, 0.00711476, 0.00730509, 0.01383548,\n",
      "       0.00167051, 0.00064874, 0.01189432, 0.02017768, 0.00713173,\n",
      "       0.00094932, 0.01540727, 0.04051766, 0.00097496, 0.02315717,\n",
      "       0.02132441, 0.02410432, 0.01348179, 0.01374173, 0.00088558,\n",
      "       0.01331817, 0.00101824, 0.00084223, 0.01112673, 0.00997829,\n",
      "       0.03348959, 0.00605007, 0.01533647, 0.02563181, 0.01984534,\n",
      "       0.00239556, 0.02074672, 0.01301016, 0.01127051, 0.001407  ,\n",
      "       0.00097501, 0.01530942, 0.00717742, 0.00832964, 0.01877638,\n",
      "       0.01585248, 0.01871795, 0.00273774, 0.00043493, 0.01240819,\n",
      "       0.01058083, 0.00073162, 0.01383202, 0.00713249, 0.00935808,\n",
      "       0.00026077, 0.00481353, 0.02240627, 0.01199925, 0.00178132,\n",
      "       0.00755721, 0.00076496, 0.01250332, 0.0008663 , 0.0093235 ,\n",
      "       0.007748  , 0.00676714, 0.01087004, 0.01097335, 0.00492631,\n",
      "       0.00351361, 0.03366528, 0.01938407, 0.01322433, 0.01079804,\n",
      "       0.0073122 , 0.00199356, 0.00173938, 0.00776682, 0.01060444,\n",
      "       0.01894757, 0.01380842, 0.03193601, 0.01029865, 0.00056888,\n",
      "       0.00126615, 0.04949719, 0.0098897 , 0.01658033, 0.00955313,\n",
      "       0.01523146, 0.00083749, 0.00626917, 0.05886763, 0.01268019,\n",
      "       0.01853826, 0.04187753, 0.04864976, 0.03063009, 0.00473292,\n",
      "       0.01071625, 0.00096914, 0.01932573, 0.01553729, 0.01084131,\n",
      "       0.00153027, 0.0365673 , 0.04210472, 0.00076404, 0.01656613,\n",
      "       0.02839396, 0.0102478 , 0.00178574, 0.00051677, 0.00654504,\n",
      "       0.01324976, 0.02661292, 0.03164862, 0.00944768, 0.00302548,\n",
      "       0.01208669, 0.00075761, 0.01397664, 0.01354395, 0.00733674,\n",
      "       0.02109793, 0.0426918 , 0.00796758, 0.02802086, 0.0504023 ,\n",
      "       0.01435407, 0.03175302, 0.01192335, 0.00779276, 0.03967286,\n",
      "       0.02756325, 0.00107945, 0.00963846, 0.00125871, 0.0063243 ,\n",
      "       0.02868859, 0.0071083 , 0.00112435, 0.00030254, 0.0197373 ,\n",
      "       0.0021358 , 0.00026319, 0.00165731, 0.00480818, 0.00716022,\n",
      "       0.00193793, 0.02057529, 0.00114377, 0.00090934, 0.00662875,\n",
      "       0.02142681, 0.00098479, 0.00837545, 0.00100778, 0.00133957,\n",
      "       0.04922204, 0.00721942, 0.04370801, 0.00750282, 0.01080283,\n",
      "       0.02980192, 0.00609096, 0.00021607, 0.02718766, 0.00491326,\n",
      "       0.00157832, 0.00846967, 0.0053766 , 0.00273026, 0.02067574,\n",
      "       0.01247094, 0.02533855, 0.00500946, 0.00471333, 0.02271755,\n",
      "       0.03346631, 0.0010184 , 0.01216545, 0.00272415, 0.02191978,\n",
      "       0.00025802, 0.01600831, 0.00088553, 0.01936126, 0.00630923,\n",
      "       0.01288608, 0.00150349, 0.0260801 , 0.00417488, 0.01045066,\n",
      "       0.00605108, 0.00460099], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 103,\n",
      "shape: [512],\n",
      "shape_signature: [512],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([1.91237559e-04, 2.50251353e-04, 4.83858952e-04, 2.40999652e-05,\n",
      "       1.20310622e-04, 1.14630989e-03, 5.38494460e-05, 1.63451095e-05,\n",
      "       3.51701805e-04, 4.06709791e-04, 9.39944875e-05, 1.70878498e-04,\n",
      "       2.89142976e-04, 2.93802004e-04, 2.50600337e-04, 8.10425612e-04,\n",
      "       3.28376162e-04, 4.09181637e-04, 3.48590082e-04, 3.46690445e-04,\n",
      "       4.87686426e-04, 5.79522864e-04, 2.59725755e-04, 3.43623979e-04,\n",
      "       1.90863226e-04, 1.70559622e-04, 2.07025500e-04, 4.30422835e-04,\n",
      "       4.68284677e-04, 3.67944049e-05, 5.71475306e-04, 9.71231668e-04,\n",
      "       2.01896633e-04, 1.41073207e-04, 3.36859026e-04, 1.36350165e-04,\n",
      "       3.97679163e-04, 2.69944401e-04, 4.86168981e-04, 1.16482443e-04,\n",
      "       4.18344163e-04, 1.04878309e-04, 3.42645159e-04, 1.28206939e-05,\n",
      "       1.08293971e-05, 3.83957049e-05, 1.86857069e-04, 3.30473151e-04,\n",
      "       2.81735829e-05, 4.03451675e-04, 3.10765114e-04, 1.71584907e-04,\n",
      "       2.24267744e-04, 4.36604052e-04, 1.89886123e-05, 3.00775777e-04,\n",
      "       8.39215703e-04, 1.25967758e-03, 4.43638448e-04, 8.85787085e-06,\n",
      "       2.16262313e-04, 1.27473195e-05, 1.34088459e-05, 1.10865520e-04,\n",
      "       1.72405969e-04, 3.55731645e-05, 2.75798346e-04, 5.13956475e-04,\n",
      "       1.95545381e-05, 5.01657196e-04, 2.74020585e-05, 1.07448672e-04,\n",
      "       2.08824262e-04, 1.47730665e-04, 9.01539461e-05, 4.98222129e-04,\n",
      "       8.69077223e-04, 1.89833794e-04, 6.16253586e-04, 2.16513276e-04,\n",
      "       2.34072111e-04, 1.36072529e-04, 7.26896978e-05, 3.29151284e-04,\n",
      "       1.24524138e-03, 1.36730043e-04, 1.07815031e-04, 1.59541974e-04,\n",
      "       4.33170062e-04, 3.18834413e-04, 3.10112431e-04, 2.14073269e-04,\n",
      "       4.40013304e-04, 4.15737508e-04, 3.27273519e-05, 3.15480829e-05,\n",
      "       1.45683967e-04, 5.97210485e-04, 1.22267776e-03, 1.33109206e-04,\n",
      "       3.01466553e-05, 1.04798928e-04, 8.60801265e-06, 2.07741468e-05,\n",
      "       8.96773592e-04, 1.45649537e-04, 1.73684122e-04, 6.99768367e-04,\n",
      "       4.82337899e-04, 6.28567941e-04, 4.61025847e-05, 7.32271155e-06,\n",
      "       1.22168531e-05, 1.42470031e-04, 6.65614198e-06, 1.02525672e-04,\n",
      "       2.57665874e-04, 3.64137464e-04, 4.06670879e-04, 1.88492806e-04,\n",
      "       2.16675107e-04, 9.11686104e-04, 1.50543347e-04, 2.59531982e-04,\n",
      "       5.42362162e-04, 2.88974639e-04, 6.42926141e-04, 2.19942973e-04,\n",
      "       3.33805016e-04, 5.73928468e-04, 8.77213752e-05, 4.30647342e-04,\n",
      "       5.73535450e-04, 6.23062660e-04, 5.12616243e-04, 2.01472649e-05,\n",
      "       5.62816604e-05, 4.12849568e-06, 1.36296803e-04, 8.44874827e-04,\n",
      "       2.63715367e-04, 8.46912269e-04, 2.96653379e-05, 2.67098105e-04,\n",
      "       1.39705317e-05, 3.88442830e-04, 2.23905838e-04, 3.14781937e-04,\n",
      "       2.68743461e-04, 1.75934965e-05, 2.98891518e-05, 1.42114965e-04,\n",
      "       4.07460378e-04, 1.55202069e-04, 4.99447306e-05, 1.70339190e-05,\n",
      "       4.28506843e-04, 9.59310419e-05, 1.37720082e-04, 3.72253417e-04,\n",
      "       2.98484461e-04, 3.16932652e-04, 9.85771476e-05, 3.87911452e-04,\n",
      "       1.84525215e-05, 2.76089213e-05, 4.56745969e-04, 5.33954939e-04,\n",
      "       3.02747194e-05, 1.44622274e-04, 3.92775546e-04, 4.60542105e-05,\n",
      "       7.69971986e-04, 3.12343589e-04, 2.30981095e-05, 4.70076891e-04,\n",
      "       3.46113986e-04, 3.29072966e-04, 1.38330608e-04, 2.36404128e-03,\n",
      "       4.12090740e-04, 2.33887127e-04, 1.76279078e-04, 1.71497068e-05,\n",
      "       2.08010344e-04, 1.37179348e-04, 1.99277474e-05, 1.94167842e-05,\n",
      "       1.73259745e-04, 1.28751577e-04, 2.14454019e-04, 2.16965433e-04,\n",
      "       1.05546624e-03, 8.30823046e-06, 2.22107599e-04, 3.81663034e-04,\n",
      "       2.55097548e-04, 1.29301436e-04, 1.86839592e-04, 2.77324172e-04,\n",
      "       3.27914691e-04, 1.61349628e-04, 6.63899351e-04, 1.53080575e-04,\n",
      "       1.69204286e-05, 3.79781239e-04, 1.10029447e-04, 8.87740520e-04,\n",
      "       4.82942822e-04, 3.29884730e-04, 1.09172033e-05, 5.30438323e-04,\n",
      "       2.89920863e-04, 1.18993943e-04, 5.33393904e-06, 5.60388835e-05,\n",
      "       8.96417332e-05, 2.34146326e-04, 5.93390956e-04, 3.63909858e-05,\n",
      "       3.53029929e-04, 3.61052880e-05, 4.20762663e-04, 1.35642200e-04,\n",
      "       3.43569496e-04, 1.12904090e-04, 5.74804784e-04, 3.41220148e-05,\n",
      "       1.19611563e-04, 1.87925063e-04, 8.00755952e-05, 4.09355242e-04,\n",
      "       3.66153217e-05, 1.45622034e-04, 2.74443097e-04, 4.27592662e-04,\n",
      "       4.13743946e-05, 3.76100332e-04, 2.49819059e-05, 1.20417753e-04,\n",
      "       1.34726160e-05, 1.79079507e-04, 3.56038683e-04, 9.54336647e-05,\n",
      "       1.69541338e-04, 1.19487355e-04, 1.66345199e-04, 5.34671235e-05,\n",
      "       4.32179295e-05, 2.60535191e-04, 1.85031422e-05, 5.35605286e-05,\n",
      "       3.41017621e-05, 1.12488684e-04, 2.28725883e-04, 2.26819859e-04,\n",
      "       3.71094386e-04, 1.34311049e-04, 1.15093088e-03, 1.54679467e-04,\n",
      "       9.12277901e-05, 4.63740762e-05, 1.07631425e-03, 9.55709256e-04,\n",
      "       1.91765997e-04, 2.04358930e-05, 5.43950708e-04, 4.97452158e-04,\n",
      "       2.75497645e-04, 4.76156885e-04, 6.46571396e-04, 1.31886394e-04,\n",
      "       3.78220051e-04, 3.15029756e-05, 1.45788217e-05, 1.31869354e-04,\n",
      "       1.39259006e-04, 3.25679022e-04, 3.11243020e-05, 1.15013841e-04,\n",
      "       3.31340067e-04, 1.65268197e-04, 3.65342072e-04, 1.86298290e-04,\n",
      "       3.69577610e-05, 2.06821933e-04, 1.67640057e-04, 1.32239482e-04,\n",
      "       1.48450461e-04, 2.48320634e-04, 1.41265016e-04, 6.70487876e-04,\n",
      "       1.30876706e-05, 2.07156088e-04, 2.00611285e-05, 1.52907582e-04,\n",
      "       9.56260774e-05, 3.38958780e-05, 1.87781421e-04, 1.50652224e-04,\n",
      "       5.42672205e-05, 1.76042176e-05, 7.76047294e-04, 1.69802152e-04,\n",
      "       4.67511330e-04, 5.75944396e-05, 1.83794509e-05, 1.16944732e-03,\n",
      "       2.53297447e-04, 3.38776561e-04, 2.32846171e-04, 1.57909832e-04,\n",
      "       3.96682444e-05, 2.83349982e-05, 9.05539928e-05, 7.57792615e-04,\n",
      "       3.84664134e-04, 9.03386263e-06, 1.81653057e-04, 6.31469447e-05,\n",
      "       7.28677725e-04, 2.34622275e-05, 1.48717823e-04, 1.52696171e-04,\n",
      "       2.89199088e-04, 3.49181391e-05, 1.35604541e-05, 2.48623546e-04,\n",
      "       4.21768491e-04, 1.49072497e-04, 1.98433427e-05, 3.22053733e-04,\n",
      "       8.46929208e-04, 2.03792351e-05, 4.84047865e-04, 4.45738056e-04,\n",
      "       5.03845804e-04, 2.81806162e-04, 2.87239527e-04, 1.85110821e-05,\n",
      "       2.78385938e-04, 2.12839095e-05, 1.76049871e-05, 2.32579012e-04,\n",
      "       2.08573358e-04, 7.00023549e-04, 1.26462997e-04, 3.20573890e-04,\n",
      "       5.35774510e-04, 4.14821669e-04, 5.00736314e-05, 4.33662935e-04,\n",
      "       2.71947705e-04, 2.35584244e-04, 2.94100864e-05, 2.03803229e-05,\n",
      "       3.20008432e-04, 1.50027627e-04, 1.74112036e-04, 3.92477377e-04,\n",
      "       3.31359857e-04, 3.91256035e-04, 5.72262506e-05, 9.09130631e-06,\n",
      "       2.59365013e-04, 2.21168229e-04, 1.52927823e-05, 2.89126794e-04,\n",
      "       1.49088490e-04, 1.95609377e-04, 5.45074090e-06, 1.00615936e-04,\n",
      "       4.68351995e-04, 2.50817015e-04, 3.72345130e-05, 1.57966235e-04,\n",
      "       1.59897590e-05, 2.61353329e-04, 1.81080213e-05, 1.94886423e-04,\n",
      "       1.61954275e-04, 1.41451674e-04, 2.27213328e-04, 2.29372949e-04,\n",
      "       1.02973361e-04, 7.34439091e-05, 7.03695812e-04, 4.05179802e-04,\n",
      "       2.76424369e-04, 2.25708412e-04, 1.52844776e-04, 4.16708062e-05,\n",
      "       3.63577674e-05, 1.62347598e-04, 2.21661554e-04, 3.96055664e-04,\n",
      "       2.88633571e-04, 6.67549437e-04, 2.15269727e-04, 1.18911830e-05,\n",
      "       2.64659866e-05, 1.03462581e-03, 2.06721714e-04, 3.46574001e-04,\n",
      "       1.99686358e-04, 3.18378996e-04, 1.75058885e-05, 1.31042674e-04,\n",
      "       1.23049365e-03, 2.65050359e-04, 3.87499982e-04, 8.75354162e-04,\n",
      "       1.01691228e-03, 6.40252256e-04, 9.89307955e-05, 2.23998679e-04,\n",
      "       2.02575739e-05, 4.03960265e-04, 3.24771565e-04, 2.26612829e-04,\n",
      "       3.19868122e-05, 7.64356111e-04, 8.80103151e-04, 1.59705342e-05,\n",
      "       3.46277084e-04, 5.93510980e-04, 2.14206942e-04, 3.73267212e-05,\n",
      "       1.08018266e-05, 1.36809089e-04, 2.76956009e-04, 5.56282350e-04,\n",
      "       6.61542173e-04, 1.97482252e-04, 6.32406663e-05, 2.52644648e-04,\n",
      "       1.58360126e-05, 2.92149867e-04, 2.83105328e-04, 1.53357760e-04,\n",
      "       4.41004086e-04, 8.92374723e-04, 1.66544007e-04, 5.85712143e-04,\n",
      "       1.05354516e-03, 3.00039042e-04, 6.63724437e-04, 2.49230390e-04,\n",
      "       1.62889846e-04, 8.29270633e-04, 5.76146937e-04, 2.25635431e-05,\n",
      "       2.01470029e-04, 2.63105449e-05, 1.32195011e-04, 5.99669467e-04,\n",
      "       1.48582767e-04, 2.35018724e-05, 6.32380943e-06, 4.12563240e-04,\n",
      "       4.46440063e-05, 5.50146433e-06, 3.46422603e-05, 1.00504018e-04,\n",
      "       1.49668107e-04, 4.05079991e-05, 4.30079614e-04, 2.39079345e-05,\n",
      "       1.90077171e-05, 1.38558826e-04, 4.47878556e-04, 2.05846991e-05,\n",
      "       1.75069741e-04, 2.10653834e-05, 2.80007371e-05, 1.02887454e-03,\n",
      "       1.50905500e-04, 9.13616212e-04, 1.56829439e-04, 2.25808588e-04,\n",
      "       6.22941181e-04, 1.27317573e-04, 4.51638425e-06, 5.68296120e-04,\n",
      "       1.02700520e-04, 3.29912400e-05, 1.77039037e-04, 1.12385489e-04,\n",
      "       5.70699522e-05, 4.32179135e-04, 2.60676490e-04, 5.29644545e-04,\n",
      "       1.04711282e-04, 9.85213337e-05, 4.74858651e-04, 6.99536933e-04,\n",
      "       2.12874311e-05, 2.54290906e-04, 5.69421209e-05, 4.58183000e-04,\n",
      "       5.39326993e-06, 3.34617129e-04, 1.85100325e-05, 4.04702936e-04,\n",
      "       1.31880093e-04, 2.69354176e-04, 3.14270510e-05, 5.45145071e-04,\n",
      "       8.72663586e-05, 2.18447283e-04, 1.26484068e-04, 9.61731566e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer24/sepconv/Relu6;tower0/network/layer24/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer24/sepconv/depthwise,\n",
      "index: 104,\n",
      "shape: [  1   3   2 512],\n",
      "shape_signature: [  1   3   2 512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer25/conv/Conv2D,\n",
      "index: 105,\n",
      "shape: [1024    1    1  512],\n",
      "shape_signature: [1024    1    1  512],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.0012126 , 0.00098001, 0.00224642, ..., 0.00073498, 0.00077731,\n",
      "       0.00049828], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer25/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 106,\n",
      "shape: [1024],\n",
      "shape_signature: [1024],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.8531813e-05, 2.3059123e-05, 5.2857002e-05, ..., 1.7293660e-05,\n",
      "       1.8289560e-05, 1.1724235e-05], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer25/conv/Relu6;tower0/network/layer25/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/depthwise;tower0/network/layer27/conv/Conv2D;tower0/network/layer25/conv/Conv2D,\n",
      "index: 107,\n",
      "shape: [   1    3    2 1024],\n",
      "shape_signature: [   1    3    2 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer26/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/depthwise;tower0/network/layer27/conv/Conv2D,\n",
      "index: 108,\n",
      "shape: [   1    3    3 1024],\n",
      "shape_signature: [   1    3    3 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.0113379 , 0.02632317, 0.00500149, ..., 0.06521544, 0.07980882,\n",
      "       0.00073962], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 3},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer26/sepconv/BatchNorm/FusedBatchNormV3,\n",
      "index: 109,\n",
      "shape: [1024],\n",
      "shape_signature: [1024],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.6677418e-04, 6.1936869e-04, 1.1768213e-04, ..., 1.5344810e-03,\n",
      "       1.8778546e-03, 1.7402723e-05], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer26/sepconv/Relu6;tower0/network/layer26/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/depthwise;tower0/network/layer27/conv/Conv2D,\n",
      "index: 110,\n",
      "shape: [   1    3    2 1024],\n",
      "shape_signature: [   1    3    2 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer27/conv/Conv2D,\n",
      "index: 111,\n",
      "shape: [1024    1    1 1024],\n",
      "shape_signature: [1024    1    1 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([0.00100056, 0.00153568, 0.00263747, ..., 0.00346545, 0.00111769,\n",
      "       0.00213589], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer27/conv/BatchNorm/FusedBatchNormV3,\n",
      "index: 112,\n",
      "shape: [1024],\n",
      "shape_signature: [1024],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([2.3542496e-05, 3.6133701e-05, 6.2058025e-05, ..., 8.1539984e-05,\n",
      "       2.6298663e-05, 5.0256283e-05], dtype=float32), 'zero_points': array([0, 0, 0, ..., 0, 0, 0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer27/conv/Relu6;tower0/network/layer27/conv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/BatchNorm/FusedBatchNormV3;tower0/network/layer26/sepconv/depthwise;tower0/network/layer27/conv/Conv2D,\n",
      "index: 113,\n",
      "shape: [   1    3    2 1024],\n",
      "shape_signature: [   1    3    2 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0235294122248888, -128),\n",
      "quantization_parameters: {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer28/reduce_mean/reduction_indices,\n",
      "index: 114,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer28/reduce_mean,\n",
      "index: 115,\n",
      "shape: [   1    1    1 1024],\n",
      "shape_signature: [   1    1    1 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.022328350692987442, -128),\n",
      "quantization_parameters: {'scales': array([0.02232835], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer29/fc/MatMul,\n",
      "index: 116,\n",
      "shape: [ 521 1024],\n",
      "shape_signature: [ 521 1024],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.02734142355620861, 0),\n",
      "quantization_parameters: {'scales': array([0.02734142], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: network/layer29/fc/biases,\n",
      "index: 117,\n",
      "shape: [521],\n",
      "shape_signature: [521],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0006104888743720949, 0),\n",
      "quantization_parameters: {'scales': array([0.00061049], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer29/fc/MatMul;tower0/network/layer29/fc/BiasAdd,\n",
      "index: 118,\n",
      "shape: [  1 521],\n",
      "shape_signature: [  1 521],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.3471774756908417, 100),\n",
      "quantization_parameters: {'scales': array([0.34717748], dtype=float32), 'zero_points': array([100]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer32/final_output1,\n",
      "index: 119,\n",
      "shape: [  1 521],\n",
      "shape_signature: [  1 521],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.00390625, -128),\n",
      "quantization_parameters: {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: tower0/network/layer32/final_output,\n",
      "index: 120,\n",
      "shape: [  1 521],\n",
      "shape_signature: [  1 521],\n",
      "dtype: <class 'numpy.float32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 127,\n",
      "shape: [4],\n",
      "shape_signature: [4],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 128,\n",
      "shape: [2],\n",
      "shape_signature: [2],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 129,\n",
      "shape: [1024],\n",
      "shape_signature: [1024],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 136,\n",
      "shape: [18],\n",
      "shape_signature: [18],\n",
      "dtype: <class 'numpy.int32'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 137,\n",
      "shape: [256],\n",
      "shape_signature: [256],\n",
      "dtype: <class 'numpy.int64'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n",
      "name: ,\n",
      "index: 138,\n",
      "shape: [ 1 48 32  9],\n",
      "shape_signature: [ 1 48 32  9],\n",
      "dtype: <class 'numpy.int8'>,\n",
      "quantization: (0.0, 0),\n",
      "quantization_parameters: {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0},\n",
      "sparsity_parameters: {},\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create interpreter, allocate tensors\n",
    "'''\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path='models/yamnet/tfhub/cpu.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "'''\n",
    "Check input/output details\n",
    "'''\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "\n",
    "'''\n",
    "Run prediction (optional), input_array has input's shape and dtype\n",
    "'''\n",
    "tflite_interpreter.set_tensor(input_details[0]['index'], frames[1])\n",
    "tflite_interpreter.invoke()\n",
    "output_array = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"\\n\")\n",
    "\n",
    "'''\n",
    "This gives a list of dictionaries. \n",
    "'''\n",
    "tensor_details = tflite_interpreter.get_tensor_details()\n",
    "\n",
    "for dict in tensor_details:\n",
    "    # index = dict['index']\n",
    "    # name = dict['name']\n",
    "    # shape = dict['shape']\n",
    "    # dtype = dict['dtype']\n",
    "    # qp = dict['quantization_parameters']\n",
    "    # scales = qp['scales']    \n",
    "    # zero_points = dict['quantization_parameters']['zero_points']\n",
    "    # tensor = tflite_interpreter.tensor(i)()\n",
    "\n",
    "    # print(i, type, name, scales.shape, zero_points.shape, tensor.shape)\n",
    "    # json.dumps(d, indent=4)\n",
    "\n",
    "    for key, value in dict.items():\n",
    "        print(f'{key}: {value},')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    '''\n",
    "    See note below\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcc6f3ac80864b41a09a5597412753a4223d9f68d2603bb7195a8422dc11dcbe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('audio2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
