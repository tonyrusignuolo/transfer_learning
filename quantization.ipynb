{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from functools import reduce\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import params as yamnet_params\n",
    "import yamnet as yamnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the yamnet model\n",
    "params = yamnet_params.Params()\n",
    "yamnet = yamnet_model.yamnet_frames_model(params)\n",
    "yamnet.load_weights('yamnet.h5')\n",
    "yamnet_classes = yamnet_model.class_names('yamnet_class_map.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build representative dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for loading audio files and making sure the sample rate is correct.\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "      \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio, and frame it to 15600 samples. \"\"\"\n",
    "      file_contents = tf.io.read_file(filename)\n",
    "      wav, sample_rate = tf.audio.decode_wav(\n",
    "            file_contents, \n",
    "            desired_channels=1\n",
    "      )\n",
    "      wav = tf.squeeze(wav, axis=-1)\n",
    "      sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "      wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "      return wav\n",
    "      # print(wav.shape)\n",
    "      frames = tf.signal.frame(wav, 15600, 15600)\n",
    "      # print(frames.shape)\n",
    "      return frames\n",
    "\n",
    "@tf.function\n",
    "def frame_16k_mono(filename):\n",
    "      wav = load_wav_16k_mono(filename)\n",
    "      frames = tf.signal.frame(wav, 15600, 15600)\n",
    "      return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in esc-50 descriptive data\n",
    "esc50_csv = './datasets/ESC-50-master/meta/esc50.csv'\n",
    "base_data_path = './datasets/ESC-50-master/audio/'\n",
    "\n",
    "pd_data = pd.read_csv(esc50_csv)\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-110389-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>110389</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-30226-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>30226</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-30344-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>30344</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-32318-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>32318</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-34094-A-5.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>False</td>\n",
       "      <td>34094</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-34094-B-5.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>False</td>\n",
       "      <td>34094</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-47819-A-5.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>False</td>\n",
       "      <td>47819</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-47819-B-5.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>False</td>\n",
       "      <td>47819</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>./datasets/ESC-50-master/audio/1-47819-C-5.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cat</td>\n",
       "      <td>False</td>\n",
       "      <td>47819</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  fold  target category  \\\n",
       "0    ./datasets/ESC-50-master/audio/1-100032-A-0.wav     1       0      dog   \n",
       "14   ./datasets/ESC-50-master/audio/1-110389-A-0.wav     1       0      dog   \n",
       "157   ./datasets/ESC-50-master/audio/1-30226-A-0.wav     1       0      dog   \n",
       "158   ./datasets/ESC-50-master/audio/1-30344-A-0.wav     1       0      dog   \n",
       "170   ./datasets/ESC-50-master/audio/1-32318-A-0.wav     1       0      dog   \n",
       "175   ./datasets/ESC-50-master/audio/1-34094-A-5.wav     1       1      cat   \n",
       "176   ./datasets/ESC-50-master/audio/1-34094-B-5.wav     1       1      cat   \n",
       "229   ./datasets/ESC-50-master/audio/1-47819-A-5.wav     1       1      cat   \n",
       "230   ./datasets/ESC-50-master/audio/1-47819-B-5.wav     1       1      cat   \n",
       "231   ./datasets/ESC-50-master/audio/1-47819-C-5.wav     1       1      cat   \n",
       "\n",
       "     esc10  src_file take  \n",
       "0     True    100032    A  \n",
       "14    True    110389    A  \n",
       "157   True     30226    A  \n",
       "158   True     30344    A  \n",
       "170   True     32318    A  \n",
       "175  False     34094    A  \n",
       "176  False     34094    B  \n",
       "229  False     47819    A  \n",
       "230  False     47819    B  \n",
       "231  False     47819    C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter descriptive data to cat and dog class\n",
    "my_classes = ['dog', 'cat']\n",
    "map_class_to_id = {'dog':0, 'cat':1}\n",
    "\n",
    "filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
    "class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_pd = filtered_pd.assign(target=class_id)\n",
    "full_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
    "filtered_pd = filtered_pd.assign(filename=full_path)\n",
    "filtered_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from the descriptive data\n",
    "filenames = filtered_pd['filename']\n",
    "targets = filtered_pd['target']\n",
    "folds = filtered_pd['fold']\n",
    "\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "# helper function to load audio data from descriptive data when mapped\n",
    "def load_frames_for_map(filename, label, fold):\n",
    "    frames = frame_16k_mono(filename)\n",
    "    return (\n",
    "        frames,\n",
    "        label,\n",
    "        fold\n",
    "    )\n",
    "\n",
    "# loads audio data in place of descriptive data\n",
    "main_ds = main_ds.map(load_frames_for_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbatch frames\n",
    "def unbatch_frames(frames, label, fold):\n",
    "    # num_frames = reduce((lambda x, y: x* y), frames.shape[0:-1])\n",
    "    num_frames = 5\n",
    "    frames = tf.reshape(frames,[num_frames, 15600])\n",
    "    return (\n",
    "        frames, \n",
    "        tf.repeat(label, num_frames),\n",
    "        tf.repeat(fold, num_frames)\n",
    "    )\n",
    "    \n",
    "main_ds = main_ds.map(unbatch_frames).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(frame, label, fold):\n",
    "    ''' run YAMNet to extract embedding from the wav data '''\n",
    "    scores, embeddings, spectrogram = yamnet(frame)\n",
    "    num_embeddings = tf.shape(embeddings)[0]\n",
    "    return (\n",
    "        embeddings,\n",
    "        tf.repeat(label, num_embeddings),\n",
    "        tf.repeat(fold, num_embeddings)\n",
    "    )\n",
    "\n",
    "# extract embedding\n",
    "main_ds = main_ds.map(extract_embedding).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "cached_ds = main_ds.cache()\n",
    "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 4)\n",
    "\n",
    "# remove folds column\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "train_ds = train_ds.map(remove_fold_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for frame, label in train_ds.take(100):\n",
    "        yield [frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) waveform_binary 0 with unsupported characters which will be renamed to placeholder in the SavedModel.\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n",
      "WARNING:absl:For model outputs containing unsupported operations which cannot be quantized, the `inference_output_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# convert the model to a quantized tflite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(yamnet)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('models\\me\\yamnet\\quant_test.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcc6f3ac80864b41a09a5597412753a4223d9f68d2603bb7195a8422dc11dcbe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('audio2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
